{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第2章: グラフの制御フロー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "\n",
    "以下のセルを順番に実行して、演習に必要な環境をセットアップします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインストール\n",
    "\n",
    "このセルは、LangGraphおよび関連するLangChainライブラリをインストールします。実行には数分かかる場合があります。\n",
    "ご利用になるLLMプロバイダーに応じて、コメントアウトを解除して必要なライブラリをインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ライブラリのインストール ===\n",
    "# 基本ライブラリ (LangGraphとLangChain Core)\n",
    "!pip install -qU langchain langgraph\n",
    "\n",
    "# --- LLMプロバイダー別ライブラリ ---\n",
    "# OpenAI (GPTシリーズ)\n",
    "# !pip install -qU langchain_openai\n",
    "\n",
    "# Azure OpenAI\n",
    "# !pip install -qU langchain_openai\n",
    "\n",
    "# Google Cloud Vertex AI (Gemini, PaLM等)\n",
    "# !pip install -qU langchain_google_vertexai\n",
    "\n",
    "# Google Gemini API\n",
    "# !pip install -qU langchain_google_genai\n",
    "\n",
    "# Anthropic (Claudeシリーズ)\n",
    "# !pip install -qU langchain_anthropic\n",
    "\n",
    "# Amazon Bedrock\n",
    "# !pip install -qU langchain_aws boto3\n",
    "\n",
    "# --- その他の推奨ライブラリ ---\n",
    "!pip install -qU python-dotenv pygraphviz pydotplus graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI APIキーの設定\n",
    "\n",
    "このノートブックでは、いくつかの問題でOpenAIのLLMを使用します。\n",
    "事前にOpenAIのAPIキーを取得し、環境変数 `OPENAI_API_KEY` に設定するか、Google Colabの場合はColabのシークレットマネージャーに `OPENAI_API_KEY` という名前でキーを登録してください。\n",
    "\n",
    "`.env` ファイルを使用する場合:\n",
    "1. リポジトリのルートにある `.env.sample` をコピーして `.env` という名前のファイルを作成します。\n",
    "2. `.env` ファイルを開き、`OPENAI_API_KEY=\"sk-...\"` のようにご自身のAPIキーを記述して保存します。\n",
    "\n",
    "以下のセルは、設定されたAPIキーをロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    if \"OPENAI_API_KEY\" in userdata.get_all():\n",
    "        os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    print(\"OpenAI APIキーをColabシークレットからロードしました。\")\n",
    "except ImportError:\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"OpenAI APIキーを.envファイルからロードしました。\")\n",
    "    else:\n",
    "        print(\"OpenAI APIキーが見つかりません。環境変数に設定するか、Colabシークレットに登録してください。\")\n",
    "\n",
    "# LLMの初期化 (この章では主にOpenAIのモデルを使用する想定)\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(f\"LLM ({llm.model_name}) の準備ができました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題001: 条件付きエッジによる分岐の導入\n",
    "\n",
    "### 課題\n",
    "LangGraphの強力な機能の一つである条件付きエッジを導入し、グラフの実行パスを動的に制御する方法を学びましょう。ここでは、入力された数値が偶数か奇数かによって、異なる処理を行うグラフを作成します。\n",
    "\n",
    "*   **学習内容:** `add_conditional_edges`を使用して、グラフの実行パスを動的に制御する方法を学びます。ルーター関数がどのように次のノードを決定するのか、そして状態が分岐間でどのように共有されるかを理解します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼▼▼▼▼▼▼▼▼▼ YOUR CODE HERE ▼▼▼▼▼▼▼▼▼▼\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class ConditionalGraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    number: int # 数値を保持する状態\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_number_node(state: ConditionalGraphState):\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    try:\n",
    "        num = int(last_message)\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        return {\"number\": 0, \"messages\": [AIMessage(content=\"無効な数値入力です。0として処理します。\")]}\n",
    "\n",
    "def even_node(state: ConditionalGraphState):\n",
    "    return {\"messages\": [AIMessage(content=f\"{state['number']} は偶数です。\")]}\n",
    "\n",
    "def odd_node(state: ConditionalGraphState):\n",
    "    return {\"messages\": [AIMessage(content=f\"{state['number']} は奇数です。\")]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def number_router(state: ConditionalGraphState):\n",
    "    if state[\"number\"] % 2 == 0:\n",
    "        return \"even_branch\"\n",
    "    else:\n",
    "        return \"odd_branch\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(ConditionalGraphState)\n",
    "workflow.add_node(\"input_node\", get_number_node)\n",
    "workflow.add_node(\"even_processor\", even_node)\n",
    "workflow.add_node(\"odd_processor\", odd_node)\n",
    "\n",
    "workflow.set_entry_point(\"input_node\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"input_node\",\n",
    "    number_router,\n",
    "    {\n",
    "        \"even_branch\": \"even_processor\",\n",
    "        \"odd_branch\": \"odd_processor\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"even_processor\", END)\n",
    "workflow.add_edge(\"odd_processor\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- 実行 --- \n",
    "print(\"--- 偶数のテスト ---\")\n",
    "inputs_even = {\"messages\": [HumanMessage(content=\"42\")]}\n",
    "final_state_even = graph.invoke(inputs_even)\n",
    "print(f\"最終応答: {final_state_even['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- 奇数のテスト ---\")\n",
    "inputs_odd = {\"messages\": [HumanMessage(content=\"77\")]}\n",
    "final_state_odd = graph.invoke(inputs_odd)\n",
    "print(f\"最終応答: {final_state_odd['messages'][-1].content}\")\n",
    "# ▲▲▲▲▲▲▲▲▲▲ YOUR CODE HERE ▲▲▲▲▲▲▲▲▲▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答例を見る</summary>\n",
    "\n",
    "``````python\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class ConditionalGraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    number: int # 数値を保持する状態\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_number_node(state: ConditionalGraphState):\n",
    "    # ユーザーからのメッセージ（数値と期待）を抽出し、状態にセット\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    print(f\"get_number_node: 入力文字列 '{last_message}'\")\n",
    "    try:\n",
    "        num = int(last_message)\n",
    "        print(f\"  -> 抽出された数値: {num}\")\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        print(f\"  -> 数値への変換失敗。デフォルト値0を使用します。\")\n",
    "        # エラーメッセージをmessagesに追加しても良い\n",
    "        return {\"number\": 0, \"messages\": [AIMessage(content=\"無効な数値が入力されました。0として処理を続けます。\")]}\n",
    "\n",
    "def even_node(state: ConditionalGraphState):\n",
    "    # 数値が偶数の場合の処理\n",
    "    num = state[\"number\"]\n",
    "    result_message = f\"入力された数値 {num} は偶数です。\"\n",
    "    print(f\"even_node: {result_message}\")\n",
    "    return {\"messages\": [AIMessage(content=result_message)]}\n",
    "\n",
    "def odd_node(state: ConditionalGraphState):\n",
    "    # 数値が奇数の場合の処理\n",
    "    num = state[\"number\"]\n",
    "    result_message = f\"入力された数値 {num} は奇数です。\"\n",
    "    print(f\"odd_node: {result_message}\")\n",
    "    return {\"messages\": [AIMessage(content=result_message)]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def number_router(state: ConditionalGraphState):\n",
    "    # numberキーの値に基づいて次に遷移するノード名を返す\n",
    "    num = state[\"number\"]\n",
    "    print(f\"number_router: 数値 {num} でルーティング判断\")\n",
    "    if num % 2 == 0:\n",
    "        print(\"  -> even_branch へ\")\n",
    "        return \"even_branch\" # add_conditional_edgesのマッピングキーと一致させる\n",
    "    else:\n",
    "        print(\"  -> odd_branch へ\")\n",
    "        return \"odd_branch\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(ConditionalGraphState)\n",
    "\n",
    "# ノードを追加\n",
    "workflow.add_node(\"input_node\", get_number_node)\n",
    "workflow.add_node(\"even_processor\", even_node)\n",
    "workflow.add_node(\"odd_processor\", odd_node)\n",
    "\n",
    "# エントリポイントを設定\n",
    "workflow.set_entry_point(\"input_node\")\n",
    "\n",
    "# 条件付きエッジを設定\n",
    "# input_node の後に number_router を実行し、その戻り値に応じて分岐\n",
    "workflow.add_conditional_edges(\n",
    "    \"input_node\",\n",
    "    number_router,\n",
    "    {\n",
    "        \"even_branch\": \"even_processor\", # routerが \"even_branch\" を返したら even_processor へ\n",
    "        \"odd_branch\": \"odd_processor\"   # routerが \"odd_branch\" を返したら odd_processor へ\n",
    "    }\n",
    ")\n",
    "\n",
    "# 各分岐の終点からENDへ\n",
    "workflow.add_edge(\"even_processor\", END)\n",
    "workflow.add_edge(\"odd_processor\", END)\n",
    "\n",
    "# グラフをコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗: {e}. Graphvizがインストールされているか確認してください。\")\n",
    "\n",
    "# --- 実行と結果確認 ---\n",
    "print(\"\\n--- 偶数のテスト (入力: 42) ---\")\n",
    "inputs_even = {\"messages\": [HumanMessage(content=\"42\")]}\n",
    "final_state_even = graph.invoke(inputs_even)\n",
    "print(f\"最終的な応答: {final_state_even['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- 奇数のテスト (入力: 77) ---\")\n",
    "inputs_odd = {\"messages\": [HumanMessage(content=\"77\")]}\n",
    "final_state_odd = graph.invoke(inputs_odd)\n",
    "print(f\"最終的な応答: {final_state_odd['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- 無効な入力のテスト (入力: abc) ---\")\n",
    "inputs_invalid = {\"messages\": [HumanMessage(content=\"abc\")]}\n",
    "final_state_invalid = graph.invoke(inputs_invalid)\n",
    "print(f\"最終的な応答 (エラー処理後): {final_state_invalid['messages'][-1].content}\") # 最後のメッセージは偶数/奇数の結果\n",
    "print(f\"  中間メッセージ (エラー通知): {final_state_invalid['messages'][-2].content}\") # エラー通知メッセージ\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題002: 状態を使ったループ（シンプルなカウンター制御）\n",
    "\n",
    "### 課題\n",
    "グラフ内で特定の条件が満たされるまで処理を繰り返す「ループ」構造を、状態と条件付きエッジを使って実現する方法を学びましょう。ここでは、カウンターが指定した上限値に達するまで、カウンターを増やし続けるシンプルなループ処理を持つグラフを作成します。これは、より複雑な自己修正ループや反復処理の基礎となります。\n",
    "\n",
    "*   **学習内容:** 状態(`State`)と条件付きエッジ(`add_conditional_edges`)を組み合わせて、グラフ内にループ構造（繰り返し処理）を実装する方法を学びます。具体的には、カウンターが上限に達するまで特定のノードを繰り返し実行し、条件を満たしたら別のノードに遷移して終了します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼▼▼▼▼▼▼▼▼▼ YOUR CODE HERE ▼▼▼▼▼▼▼▼▼▼\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class LoopState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    current_count: int\n",
    "    max_count: int\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def increment_node(state: LoopState):\n",
    "    count = state.get(\"current_count\", 0) + 1\n",
    "    return {\"current_count\": count, \"messages\": [AIMessage(content=f\"カウント: {count}\")]}\n",
    "\n",
    "def end_loop_node(state: LoopState):\n",
    "    return {\"messages\": [AIMessage(content=f\"ループ終了。最終カウント: {state['current_count']}\")]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def loop_router(state: LoopState):\n",
    "    if state[\"current_count\"] < state[\"max_count\"]:\n",
    "        return \"continue_loop\"\n",
    "    else:\n",
    "        return \"exit_loop\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(LoopState)\n",
    "workflow.add_node(\"incrementer\", increment_node)\n",
    "workflow.add_node(\"loop_ender\", end_loop_node)\n",
    "\n",
    "workflow.set_entry_point(\"incrementer\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"incrementer\",\n",
    "    loop_router,\n",
    "    {\n",
    "        \"continue_loop\": \"incrementer\",\n",
    "        \"exit_loop\": \"loop_ender\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"loop_ender\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- 実行 --- \n",
    "inputs = {\"messages\": [HumanMessage(content=\"ループ開始\")], \"current_count\": 0, \"max_count\": 3}\n",
    "for event in graph.stream(inputs, {\"recursion_limit\": 10}):\n",
    "    print(event)\n",
    "# ▲▲▲▲▲▲▲▲▲▲ YOUR CODE HERE ▲▲▲▲▲▲▲▲▲▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答例を見る</summary>\n",
    "\n",
    "``````python\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class LoopState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    current_count: int # 現在のカウンター値\n",
    "    max_count: int     # ループを終了するカウンターの上限値\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def increment_and_log_node(state: LoopState):\n",
    "    #カウンターを1増やし、メッセージをログに記録する\n",
    "    # current_count が未定義(初回など)の場合、0として扱う\n",
    "    count = state.get(\"current_count\", 0) + 1\n",
    "    log_message = f\"カウンターが {count} に増加しました。\"\n",
    "    print(f\"increment_and_log_node: {log_message}\")\n",
    "    return {\"current_count\": count, \"messages\": [AIMessage(content=log_message)]}\n",
    "\n",
    "def final_log_node(state: LoopState):\n",
    "    # ループ終了後に最終メッセージをログに記録する\n",
    "    log_message = f\"ループが終了しました。最終カウントは {state['current_count']} です。(上限: {state['max_count']})\"\n",
    "    print(f\"final_log_node: {log_message}\")\n",
    "    return {\"messages\": [AIMessage(content=log_message)]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def should_continue_loop_router(state: LoopState):\n",
    "    # current_countがmax_count未満ならループを継続、そうでなければ終了\n",
    "    current = state.get(\"current_count\", 0)\n",
    "    max_c = state.get(\"max_count\", 0)\n",
    "    print(f\"should_continue_loop_router: 現在カウント {current}, 上限カウント {max_c}\")\n",
    "    if current < max_c:\n",
    "        print(\"  -> ループ継続 (increment_and_log_nodeへ)\")\n",
    "        return \"continue_loop\" # add_conditional_edgesのマッピングキーと一致\n",
    "    else:\n",
    "        print(\"  -> ループ終了 (final_log_nodeへ)\")\n",
    "        return \"exit_loop\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(LoopState)\n",
    "\n",
    "workflow.add_node(\"incrementer\", increment_and_log_node)\n",
    "workflow.add_node(\"final_logger\", final_log_node)\n",
    "\n",
    "# エントリポイントはカウンター増加ノード\n",
    "# 初回実行時 current_count は入力で0に設定される想定\n",
    "workflow.set_entry_point(\"incrementer\")\n",
    "\n",
    "# 条件付きエッジでループを制御\n",
    "# incrementer ノードの後に should_continue_loop_router を実行\n",
    "workflow.add_conditional_edges(\n",
    "    \"incrementer\",\n",
    "    should_continue_loop_router,\n",
    "    {\n",
    "        \"continue_loop\": \"incrementer\",  # \"continue_loop\"なら再度incrementerへ (ループバック)\n",
    "        \"exit_loop\": \"final_logger\"    # \"exit_loop\"ならfinal_loggerへ\n",
    "    }\n",
    ")\n",
    "\n",
    "# final_loggerノードからENDへ\n",
    "workflow.add_edge(\"final_logger\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗: {e}. Graphvizがインストールされているか確認してください。\")\n",
    "\n",
    "# --- 実行と結果確認 ---\n",
    "loop_max_count = 3\n",
    "print(f\"\\n--- ループテスト (max_count = {loop_max_count}) ---\")\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=f\"カウンターを{loop_max_count}回まで実行するループを開始\")],\n",
    "    \"current_count\": 0, # 初期カウントを0に設定\n",
    "    \"max_count\": loop_max_count\n",
    "}\n",
    "\n",
    "print(\"\\nストリーム出力:\")\n",
    "for event in graph.stream(inputs, {\"recursion_limit\": 10}): # ループがあるのでrecursion_limitに注意\n",
    "    print(event)\n",
    "\n",
    "print(\"\\n最終状態の確認:\")\n",
    "final_state = graph.invoke(inputs, {\"recursion_limit\": 10})\n",
    "print(f\"  最終current_count: {final_state['current_count']}\")\n",
    "print(f\"  最後のメッセージ: {final_state['messages'][-1].content}\")\n",
    "assert final_state['current_count'] == loop_max_count\n",
    "assert f\"最終カウントは {loop_max_count} です\" in final_state['messages'][-1].content\n",
    "print(\"アサーション成功！\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題003: LLM によるループ継続判断（自己反省ループ）\n",
    "\n",
    "### 課題\n",
    "問題002のカウンターループをより発展させ、LLMの判断に基づいてループを継続するかどうかを決定する「自己反省ループ」の基本的な形を実装します。ユーザーからの質問に対し、LLMが一度回答を生成し、その回答が十分かどうかを別のLLM（または同じLLMに異なるプロンプトで）が判断し、不十分なら改善を試みる（再度回答生成に戻る）という流れを作ります。ここでは、最大試行回数も設けます。\n",
    "\n",
    "*   **学習内容:** LLMの出力を評価し、その評価結果に基づいて処理をループさせる方法を学びます。これは、ReAct（Reasoning and Acting）エージェントや、より複雑な反復的改善プロセスの基礎となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼▼▼▼▼▼▼▼▼▼ YOUR CODE HERE ▼▼▼▼▼▼▼▼▼▼\n",
    "from typing import TypedDict, Annotated, List, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class SelfReflectionState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    original_question: str\n",
    "    current_answer: Optional[str]\n",
    "    is_sufficient: Optional[bool]\n",
    "    attempt_count: int\n",
    "    max_attempts: int\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def generate_answer_node(state: SelfReflectionState):\n",
    "    question = state[\"original_question\"]\n",
    "    attempt = state[\"attempt_count\"] + 1\n",
    "    print(f\"generate_answer_node (Attempt {attempt}): Answering '{question}'\")\n",
    "    # 実際にはLLMで回答生成\n",
    "    # response = llm.invoke([HumanMessage(content=question)])\n",
    "    # generated_ans = response.content\n",
    "    generated_ans = f\"これが'{question}'に対する答えです。(試行{attempt}回目)\"\n",
    "    if attempt > 1: # 2回目以降は少し変えるデモ\n",
    "        generated_ans += \" 前回の回答を改善しました。\"\n",
    "    return {\"current_answer\": generated_ans, \"attempt_count\": attempt, \"messages\": [AIMessage(content=generated_ans)]}\n",
    "\n",
    "def evaluate_answer_node(state: SelfReflectionState):\n",
    "    answer = state[\"current_answer\"]\n",
    "    print(f\"evaluate_answer_node: Evaluating '{answer}'\")\n",
    "    # 実際にはLLMで評価 (ここではダミー評価)\n",
    "    # sufficient = llm.invoke(\"この回答は十分ですか？Yes/No: \" + answer).content.startswith(\"Yes\")\n",
    "    sufficient = \"改善しました\" in answer or state[\"attempt_count\"] >= state[\"max_attempts\"] # ダミー: 改善したか最大試行回数なら十分\n",
    "    return {\"is_sufficient\": sufficient, \"messages\": [AIMessage(content=f\"評価結果: {'十分' if sufficient else '不十分'}\")]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def reflection_router(state: SelfReflectionState):\n",
    "    if state.get(\"is_sufficient\") or state[\"attempt_count\"] >= state[\"max_attempts\"]:\n",
    "        return \"end_loop\"\n",
    "    else:\n",
    "        return \"regenerate_answer\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(SelfReflectionState)\n",
    "workflow.add_node(\"answer_generator\", generate_answer_node)\n",
    "workflow.add_node(\"answer_evaluator\", evaluate_answer_node)\n",
    "\n",
    "workflow.set_entry_point(\"answer_generator\")\n",
    "workflow.add_edge(\"answer_generator\", \"answer_evaluator\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"answer_evaluator\",\n",
    "    reflection_router,\n",
    "    {\n",
    "        \"regenerate_answer\": \"answer_generator\",\n",
    "        \"end_loop\": END\n",
    "    }\n",
    ")\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- 実行 --- \n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"LangGraphとは何ですか？\")],\n",
    "    \"original_question\": \"LangGraphとは何ですか？\",\n",
    "    \"attempt_count\": 0,\n",
    "    \"max_attempts\": 2\n",
    "}\n",
    "for event in graph.stream(inputs, {\"recursion_limit\": 10}):\n",
    "    print(event)\n",
    "# ▲▲▲▲▲▲▲▲▲▲ YOUR CODE HERE ▲▲▲▲▲▲▲▲▲▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答例を見る</summary>\n",
    "\n",
    "``````python\n",
    "from typing import TypedDict, Annotated, List, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class SelfReflectionState(TypedDict):\n",
    "    messages: Annotated[list, add_messages] # 会話履歴\n",
    "    original_question: str                 # ユーザーの最初の質問\n",
    "    current_answer: Optional[str]          # 現在生成されている回答\n",
    "    is_sufficient: Optional[bool]          # 回答が十分かどうかの評価結果\n",
    "    attempt_count: int                     # 回答生成の試行回数\n",
    "    max_attempts: int                      # 最大試行回数\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def initialize_state_node(state: SelfReflectionState):\n",
    "    # 最初のユーザーメッセージを original_question にセット\n",
    "    # attempt_count を初期化\n",
    "    user_question = state[\"messages\"][-1].content\n",
    "    print(f\"initialize_state_node: 初期質問 '{user_question}' を設定。試行回数0。\")\n",
    "    return {\n",
    "        \"original_question\": user_question,\n",
    "        \"attempt_count\": 0,\n",
    "        \"current_answer\": None,\n",
    "        \"is_sufficient\": None\n",
    "    }\n",
    "\n",
    "def generate_answer_node(state: SelfReflectionState):\n",
    "    question = state[\"original_question\"]\n",
    "    attempt = state.get(\"attempt_count\", 0) + 1 # 試行回数をインクリメント\n",
    "    print(f\"generate_answer_node (試行 {attempt}/{state['max_attempts']}): 質問 '{question}' に回答生成中...\")\n",
    "\n",
    "    # LLMプロンプトの準備\n",
    "    prompt_messages = [SystemMessage(content=\"あなたは質問応答AIです。簡潔かつ正確に答えてください。\")]\n",
    "    if attempt > 1 and state.get(\"current_answer\"):\n",
    "        prompt_messages.append(AIMessage(content=f\"前回のあなたの回答: {state['current_answer']}\"))\n",
    "        prompt_messages.append(HumanMessage(content=f\"その回答は不十分でした。より良い回答を生成してください。質問: {question}\"))\n",
    "    else:\n",
    "        prompt_messages.append(HumanMessage(content=question))\n",
    "    \n",
    "    response = llm.invoke(prompt_messages) # llmはノートブック冒頭で初期化済み\n",
    "    generated_ans = response.content.strip()\n",
    "    print(f\"  -> 生成された回答: '{generated_ans}'\")\n",
    "    \n",
    "    return {\n",
    "        \"current_answer\": generated_ans,\n",
    "        \"attempt_count\": attempt,\n",
    "        \"messages\": [AIMessage(content=generated_ans)] # 生成された回答を履歴に追加\n",
    "    }\n",
    "\n",
    "def evaluate_answer_node(state: SelfReflectionState):\n",
    "    answer = state[\"current_answer\"]\n",
    "    question = state[\"original_question\"]\n",
    "    print(f\"evaluate_answer_node: 回答 '{answer}' を評価中...\")\n",
    "\n",
    "    # 評価用LLMプロンプト (ここではダミー評価ロジックで代替)\n",
    "    # 実際には、「この回答は質問に十分答えていますか？ Yes/No/Maybe と理由を述べてください」のようなプロンプトでLLMに評価させる\n",
    "    # sufficient_eval = llm.invoke(eval_prompt).content\n",
    "\n",
    "    # ダミー評価ロジック: 試行回数が少ないうちは「不十分」とし、改善を促す\n",
    "    sufficient = False\n",
    "    if state[\"attempt_count\"] >= state[\"max_attempts\"]:\n",
    "        sufficient = True # 最大試行回数に達したら強制的に「十分」とする\n",
    "        eval_message = \"最大試行回数に達したため、これで十分とします。\"\n",
    "    elif \"langgraph\" in answer.lower() and \"graph\" in answer.lower(): # 簡単なキーワードチェック\n",
    "        sufficient = True\n",
    "        eval_message = \"回答は質問に関連しており、十分と判断します。\"\n",
    "    else:\n",
    "        eval_message = \"回答はまだ不十分です。改善の余地があります。\"\n",
    "        \n",
    "    print(f\"  -> 評価結果: {'十分' if sufficient else '不十分'}. {eval_message}\")\n",
    "    return {\"is_sufficient\": sufficient, \"messages\": [AIMessage(content=f\"評価コメント: {eval_message}\")]}\n",
    "\n",
    "def final_result_node(state: SelfReflectionState):\n",
    "    final_answer = state[\"current_answer\"]\n",
    "    print(f\"final_result_node: 最終的な回答は '{final_answer}' です。\")\n",
    "    # 最終回答をmessagesに追加する（既に追加されているかもしれないが、念のため）\n",
    "    # 実際には、generate_answer_nodeで既に追加されているので、ここでは不要かもしれない\n",
    "    # return {\"messages\": [AIMessage(content=f\"最終決定された回答: {final_answer}\")]}\n",
    "    return {}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def reflection_router(state: SelfReflectionState):\n",
    "    print(f\"reflection_router: 試行回数 {state['attempt_count']}/{state['max_attempts']}, 回答は十分か？ {state.get('is_sufficient')}\")\n",
    "    if state.get(\"is_sufficient\") or state[\"attempt_count\"] >= state[\"max_attempts\"]:\n",
    "        print(\"  -> ループ終了 (final_result_nodeへ)\")\n",
    "        return \"end_reflection_loop\"\n",
    "    else:\n",
    "        print(\"  -> 回答再生成 (generate_answer_nodeへ)\")\n",
    "        return \"regenerate_answer\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(SelfReflectionState)\n",
    "\n",
    "workflow.add_node(\"initializer\", initialize_state_node)\n",
    "workflow.add_node(\"answer_generator\", generate_answer_node)\n",
    "workflow.add_node(\"answer_evaluator\", evaluate_answer_node)\n",
    "workflow.add_node(\"final_result\", final_result_node)\n",
    "\n",
    "workflow.set_entry_point(\"initializer\")\n",
    "workflow.add_edge(\"initializer\", \"answer_generator\") # 初期化後、最初の回答生成へ\n",
    "workflow.add_edge(\"answer_generator\", \"answer_evaluator\") # 回答生成後、評価へ\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"answer_evaluator\", # 評価ノードの後で分岐\n",
    "    reflection_router,    # ルーター関数\n",
    "    {\n",
    "        \"regenerate_answer\": \"answer_generator\", # 不十分なら再度回答生成へ (ループ)\n",
    "        \"end_reflection_loop\": \"final_result\"      # 十分なら最終結果ノードへ\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"final_result\", END) # 最終結果の後、終了\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗: {e}. Graphvizがインストールされているか確認してください。\")\n",
    "\n",
    "# --- 実行と結果確認 ---\n",
    "user_query = \"LangGraphとは何ですか？簡単に教えてください。\"\n",
    "max_reflection_attempts = 2 # 最大試行回数 (最初の1回 + 改善1回)\n",
    "\n",
    "print(f\"\\n--- 自己反省ループテスト (質問: '{user_query}', 最大試行: {max_reflection_attempts}) ---\")\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=user_query)],\n",
    "    \"max_attempts\": max_reflection_attempts\n",
    "    # original_question, attempt_count などは initializer ノードで設定される\n",
    "}\n",
    "\n",
    "print(\"\\nストリーム出力:\")\n",
    "for event in graph.stream(inputs, {\"recursion_limit\": 15}): # ループ回数に応じてrecursion_limit調整\n",
    "    print(event)\n",
    "\n",
    "print(\"\\n最終状態の確認 (invoke):\")\n",
    "final_state = graph.invoke(inputs, {\"recursion_limit\": 15})\n",
    "print(f\"  元の質問: {final_state['original_question']}\")\n",
    "print(f\"  最終的な回答: {final_state['current_answer']}\")\n",
    "print(f\"  試行回数: {final_state['attempt_count']}\")\n",
    "print(f\"  回答は十分か: {final_state['is_sufficient']}\")\n",
    "print(f\"  最後のメッセージ(AI): {final_state['messages'][-1].content if final_state['messages'] and isinstance(final_state['messages'][-1], AIMessage) else 'N/A'}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題004: 並列処理（ファンアウト・ファンイン）による複数タスクの同時実行\n",
    "\n",
    "### 課題\n",
    "あるタスク（例えば文章の入力）の後、後続する複数の異なるタスクを同時に実行したい場合があります。LangGraphでは、**1つのノードから、並列で実行したい複数の後続ノードへ個別にエッジを接続する**ことで、処理を分岐させ、複数のタスクを並列で実行（ファンアウト）できます。\n",
    "\n",
    "さらに、並列実行したすべてのタスクが完了するのを待ってから結果を1つに統合（ファンイン）するには、`add_edge`メソッドの**第1引数**にノード名のリストを渡します。\n",
    "\n",
    "この問題では、与えられた文章に対して『要約作成』と『キーワード抽出』という2つの処理を並列で行い、最後に両方の結果が揃ってから統合する、という一連のグラフを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼▼▼▼▼▼▼▼▼▼ YOUR CODE HERE ▼▼▼▼▼▼▼▼▼▼\n",
    "from typing import TypedDict, List, Optional, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages # メッセージログ用に\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class FanOutFanInState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    original_text: str\n",
    "    summary: Optional[str]\n",
    "    keywords: Optional[List[str]]\n",
    "    final_report: Optional[str]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_text_node(state: FanOutFanInState):\n",
    "    text = state[\"messages\"][-1].content\n",
    "    return {\"original_text\": text}\n",
    "\n",
    "def summarize_node(state: FanOutFanInState):\n",
    "    text = state[\"original_text\"]\n",
    "    # result = llm.invoke(f\"要約してください: {text}\").content\n",
    "    result = f\"「{text[:10]}...」の要約です。\"\n",
    "    return {\"summary\": result, \"messages\": [AIMessage(content=f\"要約完了: {result}\")]}\n",
    "\n",
    "def extract_keywords_node(state: FanOutFanInState):\n",
    "    text = state[\"original_text\"]\n",
    "    # kws = llm.invoke(f\"キーワードを抽出: {text}\").content.split(',')\n",
    "    kws = [f\"キーワード{i+1}\" for i in range(min(3, len(text.split())))]\n",
    "    return {\"keywords\": kws, \"messages\": [AIMessage(content=f\"キーワード抽出完了: {kws}\")]}\n",
    "\n",
    "def aggregate_node(state: FanOutFanInState):\n",
    "    report = f\"要約: {state['summary']}\\nキーワード: {state['keywords']}\"\n",
    "    return {\"final_report\": report, \"messages\": [AIMessage(content=f\"最終レポート生成完了。\\n{report}\")]}\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(FanOutFanInState)\n",
    "workflow.add_node(\"input_text_getter\", get_text_node)\n",
    "workflow.add_node(\"summarizer\", summarize_node)\n",
    "workflow.add_node(\"keyword_extractor\", extract_keywords_node)\n",
    "workflow.add_node(\"aggregator\", aggregate_node)\n",
    "\n",
    "workflow.set_entry_point(\"input_text_getter\")\n",
    "workflow.add_edge(\"input_text_getter\", \"summarizer\")\n",
    "workflow.add_edge(\"input_text_getter\", \"keyword_extractor\") # ファンアウト\n",
    "workflow.add_edge([\"summarizer\", \"keyword_extractor\"], \"aggregator\") # ファンイン\n",
    "workflow.add_edge(\"aggregator\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- 実行 --- \n",
    "inputs = {\"messages\": [HumanMessage(content=\"LangGraphはグラフベースの処理フローを簡単に作れます。\")]}\n",
    "for event in graph.stream(inputs):\n",
    "    print(event)\n",
    "# ▲▲▲▲▲▲▲▲▲▲ YOUR CODE HERE ▲▲▲▲▲▲▲▲▲▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答例を見る</summary>\n",
    "\n",
    "``````python\n",
    "from typing import TypedDict, List, Optional, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages # メッセージログ用に\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class FanOutFanInState(TypedDict):\n",
    "    messages: Annotated[list, add_messages] # 処理のログやデバッグ情報用\n",
    "    original_text: str                   # 入力される元のテキスト\n",
    "    summary: Optional[str]                 # 要約結果を格納\n",
    "    keywords: Optional[List[str]]          # キーワードリストを格納\n",
    "    final_report: Optional[str]            # 最終的な統合レポート\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_text_node(state: FanOutFanInState):\n",
    "    # messagesから最新のユーザー入力をoriginal_textに設定\n",
    "    # このノードがエントリポイントで、最初の入力はmessages経由で渡される想定\n",
    "    text_input = state[\"messages\"][-1].content\n",
    "    print(f\"get_text_node: 入力テキスト '{text_input}' を取得しました。\")\n",
    "    return {\"original_text\": text_input}\n",
    "\n",
    "def summarize_node(state: FanOutFanInState):\n",
    "    text_to_summarize = state[\"original_text\"]\n",
    "    print(f\"summarize_node: テキスト '{text_to_summarize[:20]}...' の要約を開始します。\")\n",
    "    # ここではダミーの要約処理（実際にはLLMなどを使用）\n",
    "    # summary_result = llm.invoke(f\"この文章を要約してください: {text_to_summarize}\").content\n",
    "    summary_result = f\"これは「{text_to_summarize[:15]}...」に関する要約です。\"\n",
    "    print(f\"  -> 要約結果: '{summary_result}'\")\n",
    "    return {\"summary\": summary_result, \"messages\": [AIMessage(content=f\"要約処理完了: {summary_result}\")]}\n",
    "\n",
    "def extract_keywords_node(state: FanOutFanInState):\n",
    "    text_to_extract = state[\"original_text\"]\n",
    "    print(f\"extract_keywords_node: テキスト '{text_to_extract[:20]}...' のキーワード抽出を開始します。\")\n",
    "    # ここではダミーのキーワード抽出処理\n",
    "    # keywords_result = llm.invoke(f\"この文章からキーワードを3つ抽出してください: {text_to_extract}\").content.split(',')\n",
    "    keywords_result = [f\"キーワード{i+1}\" for i in range(min(3, len(text_to_extract.split())))] # ダミー\n",
    "    print(f\"  -> 抽出キーワード: {keywords_result}\")\n",
    "    return {\"keywords\": keywords_result, \"messages\": [AIMessage(content=f\"キーワード抽出完了: {keywords_result}\")]}\n",
    "\n",
    "def aggregate_results_node(state: FanOutFanInState):\n",
    "    summary = state.get(\"summary\", \"(要約なし)\")\n",
    "    keywords = state.get(\"keywords\", [])\n",
    "    print(f\"\\naggregate_results_node: 要約とキーワードを統合します...\")\n",
    "    print(f\"  取得した要約: {summary}\")\n",
    "    print(f\"  取得したキーワード: {keywords}\")\n",
    "    \n",
    "    report = f\"## 分析レポート\\n\\n### 要約\\n{summary}\\n\\n### 主要キーワード\\n- {'\\n- '.join(keywords)}\"\n",
    "    print(f\"  -> 生成されたレポート:\\n{report}\")\n",
    "    return {\"final_report\": report, \"messages\": [AIMessage(content=f\"最終レポート生成完了。\\n{report}\")]}\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(FanOutFanInState)\n",
    "\n",
    "workflow.add_node(\"input_text_getter\", get_text_node)\n",
    "workflow.add_node(\"summarizer\", summarize_node)\n",
    "workflow.add_node(\"keyword_extractor\", extract_keywords_node)\n",
    "workflow.add_node(\"aggregator\", aggregate_results_node)\n",
    "\n",
    "workflow.set_entry_point(\"input_text_getter\")\n",
    "\n",
    "# ファンアウト: input_text_getter から summarizer と keyword_extractor へ並列実行\n",
    "workflow.add_edge(\"input_text_getter\", \"summarizer\")\n",
    "workflow.add_edge(\"input_text_getter\", \"keyword_extractor\")\n",
    "\n",
    "# ファンイン: summarizer と keyword_extractor の両方が完了したら aggregator へ\n",
    "workflow.add_edge([\"summarizer\", \"keyword_extractor\"], \"aggregator\")\n",
    "\n",
    "workflow.add_edge(\"aggregator\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗: {e}. Graphvizがインストールされているか確認してください。\")\n",
    "\n",
    "# --- 実行と結果確認 ---\n",
    "input_sentence = \"LangGraphは、LLMアプリケーション構築のためのライブラリです。状態を持つグラフとして複雑な処理フローを定義できます。並列処理やループ、条件分岐など、高度な制御が可能です。\"\n",
    "print(f\"\\n--- 並列処理（ファンアウト・ファンイン）テスト (入力: '{input_sentence}') ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=input_sentence)]}\n",
    "\n",
    "print(\"\\nストリーム出力:\")\n",
    "for event in graph.stream(inputs, {\"recursion_limit\": 10}):\n",
    "    print(event)\n",
    "\n",
    "print(\"\\n最終状態の確認 (invoke):\")\n",
    "final_state = graph.invoke(inputs, {\"recursion_limit\": 10})\n",
    "print(f\"  元のテキスト: {final_state['original_text']}\")\n",
    "print(f\"  要約: {final_state['summary']}\")\n",
    "print(f\"  キーワード: {final_state['keywords']}\")\n",
    "print(f\"  最終レポート:\\n{final_state['final_report']}\")\n",
    "assert final_state['summary'] is not None\n",
    "assert final_state['keywords'] is not None\n",
    "assert final_state['final_report'] is not None\n",
    "print(\"アサーション成功！\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題005: Human-in-the-Loop (人間による介在と承認)\n",
    "\n",
    "### 課題\n",
    "自動処理の途中で人間の判断や承認を挟む「Human-in-the-Loop」は、AIシステムの信頼性や安全性を高める上で重要です。LangGraphでは、特定のノードで処理を一時停止し、ユーザーからの入力を待ってから再開する仕組みを構築できます。ここでは、LLMが生成した文章をユーザーが確認・承認し、承認されれば次の処理へ、されなければ修正を促す（または終了する）というフローを作成します。\n",
    "\n",
    "*   **学習内容:** `graph.update_state()` や `graph.get_state()` を利用して、外部（この場合はユーザーの`input()`）からグラフの状態を更新し、処理を再開する方法を学びます。中断と再開の制御には、`Interrupt` 例外と `compile(checkpointer=...)` が関連しますが、この問題ではより基本的な `input()` による同期的な待機と状態更新で概念を理解します。（非同期な中断・再開は第5章で扱います）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼▼▼▼▼▼▼▼▼▼ YOUR CODE HERE ▼▼▼▼▼▼▼▼▼▼\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class HumanApprovalState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    generated_text: Optional[str]\n",
    "    user_approval: Optional[bool] # True: 承認, False: 拒否, None: 未確認\n",
    "    feedback: Optional[str] # ユーザーからのフィードバック\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def generate_text_node(state: HumanApprovalState):\n",
    "    # ユーザーメッセージからトピックを取得して文章生成（ダミー）\n",
    "    topic = state[\"messages\"][-1].content if state[\"messages\"] and isinstance(state[\"messages\"][-1], HumanMessage) else \"何か\"\n",
    "    text = f\"「{topic}」に関する重要な提案書です。ご確認ください。\"\n",
    "    print(f\"generate_text_node: 生成されたテキスト: '{text}'\")\n",
    "    return {\"generated_text\": text, \"user_approval\": None, \"feedback\": None, \"messages\":[AIMessage(content=text)]}\n",
    "\n",
    "def human_approval_node(state: HumanApprovalState):\n",
    "    generated_text = state[\"generated_text\"]\n",
    "    print(\"\\n--- 人間による確認 --- \")\n",
    "    print(f\"生成されたテキスト: {generated_text}\")\n",
    "    \n",
    "    approval_input = input(\"この内容で承認しますか？ (yes/no): \").lower()\n",
    "    user_approved = approval_input == \"yes\"\n",
    "    \n",
    "    user_feedback = None\n",
    "    if not user_approved:\n",
    "        user_feedback = input(\"修正点やフィードバックがあれば入力してください: \")\n",
    "        \n",
    "    return {\"user_approval\": user_approved, \"feedback\": user_feedback, \"messages\": [HumanMessage(content=f\"承認状態: {'承認' if user_approved else '拒否'}. フィードバック: {user_feedback or 'なし'}\")]}\n",
    "\n",
    "def process_approved_node(state: HumanApprovalState):\n",
    "    print(\"process_approved_node: 承認されたため、次の処理を実行します。\")\n",
    "    return {\"messages\":[AIMessage(content=\"承認されました。処理を継続します。\")]}\n",
    "\n",
    "def process_rejected_node(state: HumanApprovalState):\n",
    "    feedback = state.get(\"feedback\")\n",
    "    print(f\"process_rejected_node: 拒否されました。フィードバック: '{feedback}'\")\n",
    "    # ここで修正プロセスに入るか、終了するかなどを実装できる\n",
    "    return {\"messages\":[AIMessage(content=f\"拒否されました。フィードバックに基づいて修正が必要です: {feedback}\")]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def approval_router(state: HumanApprovalState):\n",
    "    if state.get(\"user_approval\") is True:\n",
    "        return \"approved\"\n",
    "    else: # False または None (ありえないが念のため)\n",
    "        return \"rejected\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(HumanApprovalState)\n",
    "workflow.add_node(\"text_generator\", generate_text_node)\n",
    "workflow.add_node(\"human_validator\", human_approval_node)\n",
    "workflow.add_node(\"approved_handler\", process_approved_node)\n",
    "workflow.add_node(\"rejected_handler\", process_rejected_node)\n",
    "\n",
    "workflow.set_entry_point(\"text_generator\")\n",
    "workflow.add_edge(\"text_generator\", \"human_validator\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_validator\",\n",
    "    approval_router,\n",
    "    {\n",
    "        \"approved\": \"approved_handler\",\n",
    "        \"rejected\": \"rejected_handler\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"approved_handler\", END)\n",
    "workflow.add_edge(\"rejected_handler\", END) # この例では拒否後も終了\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- 実行 --- \n",
    "print(\"--- Human-in-the-Loop テスト (承認ケース) ---\")\n",
    "# ユーザー入力 'yes' を想定\n",
    "inputs_approve = {\"messages\": [HumanMessage(content=\"新製品のローンチ計画\")]}\n",
    "final_state_approve = graph.invoke(inputs_approve)\n",
    "print(f\"最終メッセージ (承認): {final_state_approve['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- Human-in-the-Loop テスト (拒否ケース) ---\")\n",
    "# ユーザー入力 'no', フィードバック '予算が不足しています' を想定\n",
    "inputs_reject = {\"messages\": [HumanMessage(content=\"マーケティング戦略\")]}\n",
    "final_state_reject = graph.invoke(inputs_reject)\n",
    "print(f\"最終メッセージ (拒否): {final_state_reject['messages'][-1].content}\")\n",
    "# ▲▲▲▲▲▲▲▲▲▲ YOUR CODE HERE ▲▲▲▲▲▲▲▲▲▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答例を見る</summary>\n",
    "\n",
    "``````python\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class HumanApprovalState(TypedDict):\n",
    "    messages: Annotated[list, add_messages] # 会話履歴や処理ログ\n",
    "    generated_text: Optional[str]          # AIが生成したテキスト\n",
    "    user_approval: Optional[bool]          # True: 承認, False: 拒否, None: 未確認\n",
    "    feedback: Optional[str]                # ユーザーからのフィードバック（拒否の場合など）\n",
    "    task_description: Optional[str]        # 元のタスク記述\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def generate_text_node(state: HumanApprovalState):\n",
    "    # ユーザーからの最新のメッセージをタスク記述として取得\n",
    "    task_desc = state[\"messages\"][-1].content if state[\"messages\"] and isinstance(state[\"messages\"][-1], HumanMessage) else \"デフォルトタスク\"\n",
    "    print(f\"generate_text_node: タスク記述 '{task_desc}' に基づいてテキストを生成します。\")\n",
    "    \n",
    "    # ダミーのテキスト生成（実際にはLLM呼び出し）\n",
    "    # generated_content = llm.invoke(f\"以下のタスク記述に基づいて提案書を作成してください: {task_desc}\").content\n",
    "    generated_content = f\"これは「{task_desc}」に関する提案書（案）です。ご確認をお願いいたします。\"\n",
    "    print(f\"  -> 生成されたテキスト: '{generated_content}'\")\n",
    "    \n",
    "    return {\n",
    "        \"generated_text\": generated_content,\n",
    "        \"task_description\": task_desc,\n",
    "        \"user_approval\": None, # 承認状態をリセット\n",
    "        \"feedback\": None,      # フィードバックをリセット\n",
    "        \"messages\": [AIMessage(content=f\"生成された提案書案: {generated_content}\")]\n",
    "    }\n",
    "\n",
    "def human_approval_node(state: HumanApprovalState):\n",
    "    generated_text = state.get(\"generated_text\", \"(テキストが生成されていません)\")\n",
    "    print(\"\\n--- 人間による確認ステップ --- \")\n",
    "    print(f\"タスク: {state.get('task_description')}\")\n",
    "    print(f\"生成されたテキスト案:\\n{'-'*30}\\n{generated_text}\\n{'-'*30}\")\n",
    "    \n",
    "    approval_input = \"\"\n",
    "    while approval_input not in [\"yes\", \"no\"]:\n",
    "        approval_input = input(\"この内容で承認しますか？ (yes/no): \").strip().lower()\n",
    "    \n",
    "    user_approved = (approval_input == \"yes\")\n",
    "    user_feedback_text = None\n",
    "    \n",
    "    if user_approved:\n",
    "        print(\"  -> 承認されました。\")\n",
    "        approval_message = \"ユーザーによって承認されました。\"\n",
    "    else:\n",
    "        print(\"  -> 拒否されました。\")\n",
    "        user_feedback_text = input(\"修正のためのフィードバックを入力してください (任意): \").strip()\n",
    "        if not user_feedback_text:\n",
    "            user_feedback_text = \"(フィードバックなし)\"\n",
    "        print(f\"  -> 受け取ったフィードバック: '{user_feedback_text}'\")\n",
    "        approval_message = f\"ユーザーによって拒否されました。フィードバック: {user_feedback_text}\"\n",
    "        \n",
    "    return {\n",
    "        \"user_approval\": user_approved,\n",
    "        \"feedback\": user_feedback_text,\n",
    "        \"messages\": [HumanMessage(content=approval_message)] # 人間のアクションを履歴に追加\n",
    "    }\n",
    "\n",
    "def process_approved_text_node(state: HumanApprovalState):\n",
    "    approved_text = state[\"generated_text\"]\n",
    "    print(f\"process_approved_text_node: 承認されたテキスト '{approved_text[:30]}...' を使って最終処理を実行します。\")\n",
    "    # ここで承認後の処理（例: 保存、送信など）を行う\n",
    "    final_message = f\"テキスト「{approved_text[:20]}...」は承認され、処理が完了しました。\"\n",
    "    return {\"messages\":[AIMessage(content=final_message)]}\n",
    "\n",
    "def handle_rejected_text_node(state: HumanApprovalState):\n",
    "    feedback = state.get(\"feedback\", \"(フィードバックなし)\")\n",
    "    rejected_text = state.get(\"generated_text\", \"(不明なテキスト)\")\n",
    "    print(f\"handle_rejected_text_node: テキスト '{rejected_text[:30]}...' は拒否されました。フィードバック: '{feedback}'\")\n",
    "    # この例では、拒否されたら修正プロセスには戻らずに終了する\n",
    "    # より高度なフローでは、ここから再度 generate_text_node に戻るループを組むことも可能\n",
    "    rejection_message = f\"テキスト「{rejected_text[:20]}...」は拒否されました。フィードバック: 「{feedback}」。処理を終了します。\"\n",
    "    return {\"messages\":[AIMessage(content=rejection_message)]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def route_after_approval(state: HumanApprovalState):\n",
    "    print(f\"route_after_approval: ユーザー承認状態 -> {state.get('user_approval')}\")\n",
    "    if state.get(\"user_approval\") is True:\n",
    "        print(\"  -> approved_handler へ\")\n",
    "        return \"was_approved\"\n",
    "    else: # False または None (エラーケースだが分岐は明確に)\n",
    "        print(\"  -> rejected_handler へ\")\n",
    "        return \"was_rejected\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(HumanApprovalState)\n",
    "\n",
    "workflow.add_node(\"text_generator\", generate_text_node)\n",
    "workflow.add_node(\"human_validator\", human_approval_node)\n",
    "workflow.add_node(\"approved_handler\", process_approved_text_node)\n",
    "workflow.add_node(\"rejected_handler\", handle_rejected_text_node)\n",
    "\n",
    "workflow.set_entry_point(\"text_generator\")\n",
    "workflow.add_edge(\"text_generator\", \"human_validator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_validator\",\n",
    "    route_after_approval,\n",
    "    {\n",
    "        \"was_approved\": \"approved_handler\",\n",
    "        \"was_rejected\": \"rejected_handler\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"approved_handler\", END)\n",
    "workflow.add_edge(\"rejected_handler\", END) # この例では拒否された場合も終了\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗: {e}. Graphvizがインストールされているか確認してください。\")\n",
    "\n",
    "# --- 実行と結果確認 ---\n",
    "print(\"\\n--- Human-in-the-Loop テスト (ユーザーが 'yes' と入力する想定) ---\")\n",
    "inputs_for_approval = {\"messages\": [HumanMessage(content=\"新製品のキャッチコピー案作成\")]}\n",
    "final_state_approved = graph.invoke(inputs_for_approval)\n",
    "print(f\"最終メッセージ (承認時): {final_state_approved['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- Human-in-the-Loop テスト (ユーザーが 'no' と入力し、フィードバックする想定) ---\")\n",
    "inputs_for_rejection = {\"messages\": [HumanMessage(content=\"顧客向け謝罪文案作成\")]}\n",
    "final_state_rejected = graph.invoke(inputs_for_rejection)\n",
    "print(f\"最終メッセージ (拒否時): {final_state_rejected['messages'][-1].content}\")\n",
    "\n",
    "assert \"承認されました\" in final_state_approved['messages'][-1].content \n",
    "assert \"拒否されました\" in final_state_rejected['messages'][-1].content\n",
    "print(\"\\nアサーション成功！\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題006: エラーハンドリングとリトライ処理\n",
    "\n",
    "### 課題\n",
    "グラフ内のノード処理（特に外部API呼び出しなど）では、一時的なエラーが発生することがあります。このような場合、即座に処理を失敗させるのではなく、数回リトライ（再試行）するメカニズムを組み込むことが有効です。この問題では、エラーが発生した場合に最大N回まで処理をリトライし、それでも成功しない場合にエラーとして処理を終了するグラフを作成します。\n",
    "\n",
    "*   **学習内容:** ノード内でエラーを捕捉し、状態にリトライ回数を記録します。条件付きエッジを使って、リトライ回数が上限未満であれば再度同じノードを実行（リトライ）し、上限に達したら別のエラー処理ノードへ分岐する方法を学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼▼▼▼▼▼▼▼▼▼ YOUR CODE HERE ▼▼▼▼▼▼▼▼▼▼\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "import random # リトライ成功をシミュレートするため\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class RetryState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task_input: str\n",
    "    result: Optional[str]\n",
    "    error_message: Optional[str]\n",
    "    retry_count: int\n",
    "    max_retries: int\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def unreliable_task_node(state: RetryState):\n",
    "    current_retry = state.get(\"retry_count\", 0)\n",
    "    print(f\"unreliable_task_node (試行 {current_retry + 1}/{state['max_retries']}): タスク '{state['task_input']}' を実行中...\")\n",
    "    # 確率的に成功/失敗をシミュレート (例: 50%の確率で失敗)\n",
    "    if random.random() < 0.5 and current_retry < state['max_retries'] -1 : # 最初の方は失敗しやすくする\n",
    "        err_msg = \"一時的なネットワークエラーが発生しました。\"\n",
    "        print(f\"  -> 失敗: {err_msg}\")\n",
    "        return {\"error_message\": err_msg, \"retry_count\": current_retry + 1, \"messages\":[AIMessage(content=f\"試行失敗: {err_msg}\")]}\n",
    "    else:\n",
    "        res = f\"タスク '{state['task_input']}' の処理成功。(試行 {current_retry + 1}回目)\"\n",
    "        print(f\"  -> 成功: {res}\")\n",
    "        return {\"result\": res, \"error_message\": None, \"retry_count\": current_retry + 1, \"messages\":[AIMessage(content=res)]}\n",
    "\n",
    "def handle_failure_node(state: RetryState):\n",
    "    final_err_msg = f\"タスク '{state['task_input']}' は最大リトライ回数 ({state['max_retries']}) を超えても成功しませんでした。最終エラー: {state.get('error_message')}\"\n",
    "    print(f\"handle_failure_node: {final_err_msg}\")\n",
    "    return {\"messages\":[AIMessage(content=final_err_msg)]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def retry_router(state: RetryState):\n",
    "    if state.get(\"result\") is not None: # 成功時\n",
    "        print(\"retry_router: タスク成功。終了します。\")\n",
    "        return \"task_succeeded\"\n",
    "    elif state.get(\"retry_count\", 0) < state.get(\"max_retries\", 0):\n",
    "        print(f\"retry_router: リトライ可能 (現在 {state['retry_count']}/{state['max_retries']})。再試行します。\")\n",
    "        return \"retry_task\"\n",
    "    else: # リトライ上限超え\n",
    "        print(\"retry_router: リトライ上限超過。エラー処理へ。\")\n",
    "        return \"max_retries_exceeded\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(RetryState)\n",
    "workflow.add_node(\"flaky_task_runner\", unreliable_task_node)\n",
    "workflow.add_node(\"failure_handler\", handle_failure_node)\n",
    "\n",
    "workflow.set_entry_point(\"flaky_task_runner\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"flaky_task_runner\",\n",
    "    retry_router,\n",
    "    {\n",
    "        \"task_succeeded\": END,\n",
    "        \"retry_task\": \"flaky_task_runner\", # 自分自身に戻ってリトライ\n",
    "        \"max_retries_exceeded\": \"failure_handler\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"failure_handler\", END)\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- 実行 --- \n",
    "print(\"--- エラーハンドリングとリトライテスト (3回リトライ) ---\")\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"不安定なAPIを呼び出すタスク\")],\n",
    "    \"task_input\": \"不安定なAPI呼び出し\",\n",
    "    \"retry_count\": 0,\n",
    "    \"max_retries\": 3\n",
    "}\n",
    "for event in graph.stream(inputs, {\"recursion_limit\": 15}):\n",
    "    print(event)\n",
    "\n",
    "final_state = graph.invoke(inputs, {\"recursion_limit\": 15})\n",
    "print(f\"\\n最終結果メッセージ: {final_state['messages'][-1].content}\")\n",
    "# ▲▲▲▲▲▲▲▲▲▲ YOUR CODE HERE ▲▲▲▲▲▲▲▲▲▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答例を見る</summary>\n",
    "\n",
    "``````python\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "import random # リトライ成功をシミュレートするため\n",
    "import time   # リトライ間の待機時間のため\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class RetryState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    task_input: str                  # 処理対象の入力\n",
    "    result: Optional[str]            # 処理成功時の結果\n",
    "    error_message: Optional[str]     # 直近のエラーメッセージ\n",
    "    attempt_count: int               # 現在の試行回数 (0から開始)\n",
    "    max_attempts: int                # 最大試行回数\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def initialize_retry_state_node(state: RetryState):\n",
    "    # messagesから最初のユーザー入力をtask_inputに設定\n",
    "    # attempt_countを初期化\n",
    "    user_input_content = state[\"messages\"][-1].content\n",
    "    print(f\"initialize_retry_state_node: タスク入力 '{user_input_content}' を設定。試行回数0。\")\n",
    "    return {\n",
    "        \"task_input\": user_input_content,\n",
    "        \"attempt_count\": 0,\n",
    "        \"result\": None,\n",
    "        \"error_message\": None\n",
    "    }\n",
    "\n",
    "def unreliable_task_node(state: RetryState):\n",
    "    current_attempt = state.get(\"attempt_count\", 0) + 1 # この試行が何回目か\n",
    "    max_attempts_val = state.get(\"max_attempts\", 1)\n",
    "    task_data = state[\"task_input\"]\n",
    "    \n",
    "    print(f\"unreliable_task_node (試行 {current_attempt}/{max_attempts_val}): タスク '{task_data}' を実行中...\")\n",
    "    \n",
    "    # 確率的に成功/失敗をシミュレート\n",
    "    # 例: 試行回数が少ないほど失敗しやすく、回数が増えると成功しやすくなる（またはランダム）\n",
    "    # ここでは、最後の試行以外は失敗するかもしれない、というシナリオを簡単に作る\n",
    "    if current_attempt < max_attempts_val and random.random() < 0.7: # 70%の確率で失敗 (最後の試行でなければ)\n",
    "        err_msg = f\"一時的なエラーが発生しました (例: タイムアウト)。試行 {current_attempt}\"\n",
    "        print(f\"  -> 失敗: {err_msg}\")\n",
    "        # time.sleep(1) # 実際のリトライでは待機時間を挟むことが多い\n",
    "        return {\"error_message\": err_msg, \"attempt_count\": current_attempt, \"messages\":[AIMessage(content=f\"タスク試行 {current_attempt} 失敗: {err_msg}\")]}\n",
    "    else:\n",
    "        # 成功ケース\n",
    "        res = f\"タスク '{task_data}' の処理成功。(試行 {current_attempt}回目)\"\n",
    "        print(f\"  -> 成功: {res}\")\n",
    "        return {\"result\": res, \"error_message\": None, \"attempt_count\": current_attempt, \"messages\":[AIMessage(content=res)]}\n",
    "\n",
    "def handle_permanent_failure_node(state: RetryState):\n",
    "    final_err_msg = (\n",
    "        f\"タスク '{state['task_input']}' は最大試行回数 ({state['max_attempts']}) を超えても成功しませんでした。\\n\"\n",
    "        f\"最終エラー: {state.get('error_message', '(不明なエラー)')}\"\n",
    "    )\n",
    "    print(f\"handle_permanent_failure_node: {final_err_msg}\")\n",
    "    # ここで、エラーをログに記録したり、ユーザーに通知したりする処理を追加できる\n",
    "    return {\"messages\":[AIMessage(content=final_err_msg)]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def retry_or_fail_router(state: RetryState):\n",
    "    current_attempt = state.get(\"attempt_count\", 0)\n",
    "    max_attempts_val = state.get(\"max_attempts\", 1)\n",
    "    \n",
    "    print(f\"retry_or_fail_router: 試行 {current_attempt}/{max_attempts_val}. 結果存在: {state.get('result') is not None}\")\n",
    "    \n",
    "    if state.get(\"result\") is not None: # resultキーに何か値があれば成功とみなす\n",
    "        print(\"  -> タスク成功。ENDへ\")\n",
    "        return \"task_succeeded_end\"\n",
    "    elif current_attempt < max_attempts_val:\n",
    "        print(f\"  -> リトライ可能。unreliable_task_nodeへ戻る\")\n",
    "        return \"needs_retry\"\n",
    "    else: # リトライ上限超過\n",
    "        print(\"  -> リトライ上限超過。handle_permanent_failure_nodeへ\")\n",
    "        return \"max_retries_exceeded_fail\"\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(RetryState)\n",
    "\n",
    "workflow.add_node(\"initializer\", initialize_retry_state_node)\n",
    "workflow.add_node(\"flaky_task_runner\", unreliable_task_node)\n",
    "workflow.add_node(\"failure_handler\", handle_permanent_failure_node)\n",
    "\n",
    "workflow.set_entry_point(\"initializer\")\n",
    "workflow.add_edge(\"initializer\", \"flaky_task_runner\") # 初期化後、タスク実行へ\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"flaky_task_runner\", # このノードの後に分岐\n",
    "    retry_or_fail_router,  # ルーター関数\n",
    "    {\n",
    "        \"task_succeeded_end\": END,              # 成功したら終了\n",
    "        \"needs_retry\": \"flaky_task_runner\",   # リトライが必要なら再度同じタスクへ (ループ)\n",
    "        \"max_retries_exceeded_fail\": \"failure_handler\" # 上限超えならエラーハンドラへ\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"failure_handler\", END) # エラーハンドラの後も終了\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗: {e}. Graphvizがインストールされているか確認してください。\")\n",
    "\n",
    "# --- 実行と結果確認 ---\n",
    "max_retries_setting = 3\n",
    "print(f\"\\n--- エラーハンドリングとリトライテスト (最大リトライ: {max_retries_setting}回) ---\")\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"外部APIへのデータ送信タスク\")],\n",
    "    \"max_attempts\": max_retries_setting\n",
    "    # task_input, attempt_count などは initializer ノードで設定\n",
    "}\n",
    "\n",
    "print(\"\\nストリーム出力:\")\n",
    "for event in graph.stream(inputs, {\"recursion_limit\": max_retries_setting * 2 + 5 }): # リトライ回数に応じて調整\n",
    "    print(event)\n",
    "\n",
    "print(\"\\n最終状態の確認 (invoke):\")\n",
    "final_state = graph.invoke(inputs, {\"recursion_limit\": max_retries_setting * 2 + 5 })\n",
    "print(f\"  タスク入力: {final_state['task_input']}\")\n",
    "print(f\"  最終試行回数: {final_state['attempt_count']}\")\n",
    "if final_state.get('result'):\n",
    "    print(f\"  結果: {final_state['result']}\")\n",
    "else:\n",
    "    print(f\"  エラーメッセージ: {final_state.get('error_message')}\")\n",
    "print(f\"  最後のAIメッセージ: {final_state['messages'][-1].content if final_state['messages'] else 'N/A'}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題007: 第2章のまとめ - 反復的な改善と最終承認フローの構築\n",
    "\n",
    "### 課題\n",
    "第2章で学んだ制御フローの要素（条件分岐、ループ、人間による介在、エラーハンドリングとリトライ）を組み合わせて、より複雑なワークフローを構築します。具体的には、以下のステップを含む「反復的な改善と最終承認フロー」を作成します。\n",
    "1.  **初期提案生成:** ユーザーからの指示に基づき、LLMが初期提案（例: 文章案、計画案など）を生成します。\n",
    "2.  **自己評価と改善ループ:** 生成された提案をLLM自身が（または別の評価用LLMが）評価します。評価基準を満たさなければ、最大N回まで改善を試みます（ループ）。\n",
    "3.  **人間による最終承認:** 自己改善ループを経た提案を人間が確認し、承認または差し戻し（フィードバック付き）を決定します。\n",
    "4.  **処理完了または修正へ:** 承認されれば処理完了。差し戻された場合は、フィードバックを元に再度提案生成からやり直すか、あるいはエラーとして終了します（この問題では簡略化のため、差し戻し後はエラー終了とします）。\n",
    "途中で予期せぬエラーが発生した場合は、リトライ処理も挟みます（簡易的なもの）。\n",
    "\n",
    "*   **学習内容:** これまでに学んだ制御フローの知識を総動員し、複数の条件分岐、ネストされた可能性のあるループ（自己改善ループとリトライ）、人間による判断の組み込みを組み合わせた、実践的な多段ワークフローを構築する経験を積みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼▼▼▼▼▼▼▼▼▼ YOUR CODE HERE ▼▼▼▼▼▼▼▼▼▼\n",
    "from typing import TypedDict, Annotated, Optional, List\n",
    "import random\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class IterativeApprovalState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_request: str\n",
    "    current_proposal: Optional[str]\n",
    "    self_eval_score: Optional[int] # 自己評価スコア (例: 1-5)\n",
    "    improvement_attempts: int\n",
    "    max_improvement_attempts: int\n",
    "    human_approved: Optional[bool]\n",
    "    human_feedback: Optional[str]\n",
    "    error_message: Optional[str]\n",
    "    task_retry_count: int\n",
    "    max_task_retries: int\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def generate_initial_proposal_node(state: IterativeApprovalState):\n",
    "    req = state[\"user_request\"]\n",
    "    retry = state.get(\"task_retry_count\", 0)\n",
    "    print(f\"generate_initial_proposal_node (Retry {retry}): Generating for '{req}'\")\n",
    "    if random.random() < 0.3 and retry < state[\"max_task_retries\"]: # たまに失敗するダミー\n",
    "        return {\"error_message\": \"Proposal generation API failed\", \"task_retry_count\": retry + 1}\n",
    "    proposal = f\"「{req}」の初期提案です。バージョン1。\"\n",
    "    return {\"current_proposal\": proposal, \"improvement_attempts\": 0, \"error_message\": None, \"task_retry_count\": 0, \"messages\":[AIMessage(content=f\"初期提案: {proposal}\")]}\n",
    "\n",
    "def self_evaluate_proposal_node(state: IterativeApprovalState):\n",
    "    proposal = state[\"current_proposal\"]\n",
    "    # ダミー評価: バージョンが上がるほど高スコア\n",
    "    score = state.get(\"improvement_attempts\", 0) + 1 \n",
    "    print(f\"self_evaluate_proposal_node: Proposal '{proposal}' scored {score}\")\n",
    "    return {\"self_eval_score\": score, \"messages\":[AIMessage(content=f\"自己評価スコア: {score}\")]}\n",
    "\n",
    "def improve_proposal_node(state: IterativeApprovalState):\n",
    "    old_proposal = state[\"current_proposal\"]\n",
    "    attempts = state.get(\"improvement_attempts\", 0) + 1\n",
    "    new_proposal = f\"{old_proposal.split('。')[0]}。改善版バージョン{attempts+1}。\"\n",
    "    print(f\"improve_proposal_node (Attempt {attempts}): Improved to '{new_proposal}'\")\n",
    "    return {\"current_proposal\": new_proposal, \"improvement_attempts\": attempts, \"self_eval_score\": None, \"messages\":[AIMessage(content=f\"改善提案: {new_proposal}\")]}\n",
    "\n",
    "def human_final_approval_node(state: IterativeApprovalState):\n",
    "    print(f\"\\n---人間による最終承認--- \\n提案: {state['current_proposal']}\")\n",
    "    approved = input(\"承認しますか? (yes/no): \").lower() == \"yes\"\n",
    "    feedback = input(\"フィードバック (任意): \") if not approved else None\n",
    "    return {\"human_approved\": approved, \"human_feedback\": feedback, \"messages\":[HumanMessage(content=f\"人間承認: {'承認' if approved else '拒否'}, FB: {feedback}\")]}\n",
    "\n",
    "def process_final_result_node(state: IterativeApprovalState):\n",
    "    msg = f\"最終結果: {'承認されました。' if state['human_approved'] else '差し戻されました。フィードバック: ' + str(state['human_feedback'])}\"\n",
    "    print(f\"process_final_result_node: {msg}\")\n",
    "    return {\"messages\":[AIMessage(content=msg)]}\n",
    "\n",
    "def task_error_handler_node(state: IterativeApprovalState):\n",
    "    err = state.get(\"error_message\", \"不明なタスクエラー\")\n",
    "    print(f\"task_error_handler_node: タスクエラー発生 - {err}\")\n",
    "    return {\"messages\":[AIMessage(content=f\"タスクエラー: {err}\")]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def route_after_generation(state: IterativeApprovalState):\n",
    "    if state.get(\"error_message\") and state.get(\"task_retry_count\",0) < state.get(\"max_task_retries\",1):\n",
    "        return \"retry_generation\"\n",
    "    elif state.get(\"error_message\"):\n",
    "        return \"handle_generation_error\"\n",
    "    return \"evaluate_self\"\n",
    "\n",
    "def route_after_self_eval(state: IterativeApprovalState):\n",
    "    if state.get(\"self_eval_score\", 0) < 3 and state.get(\"improvement_attempts\", 0) < state.get(\"max_improvement_attempts\", 1):\n",
    "        return \"improve_proposal\"\n",
    "    return \"request_human_approval\"\n",
    "\n",
    "def route_after_human_approval(state: IterativeApprovalState):\n",
    "    return \"process_result\" # 承認でも差し戻しでも同じ最終処理ノードへ\n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(IterativeApprovalState)\n",
    "nodes = [generate_initial_proposal_node, self_evaluate_proposal_node, improve_proposal_node, \n",
    "           human_final_approval_node, process_final_result_node, task_error_handler_node]\n",
    "node_names = [\"generator\", \"self_evaluator\", \"improver\", \"human_approver\", \"result_processor\", \"task_error_handler\"]\n",
    "for name, node_func in zip(node_names, nodes):\n",
    "    workflow.add_node(name, node_func)\n",
    "\n",
    "workflow.set_entry_point(\"generator\")\n",
    "workflow.add_conditional_edges(\"generator\", route_after_generation, \n",
    "                               {\"retry_generation\":\"generator\", \"handle_generation_error\":\"task_error_handler\", \"evaluate_self\":\"self_evaluator\"})\n",
    "workflow.add_conditional_edges(\"self_evaluator\", route_after_self_eval,\n",
    "                               {\"improve_proposal\":\"improver\", \"request_human_approval\":\"human_approver\"})\n",
    "workflow.add_edge(\"improver\", \"self_evaluator\") # 改善後、再度自己評価へ\n",
    "workflow.add_conditional_edges(\"human_approver\", route_after_human_approval, {\"process_result\":\"result_processor\"})\n",
    "workflow.add_edge(\"result_processor\", END)\n",
    "workflow.add_edge(\"task_error_handler\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- 実行 (承認ケース) ---\n",
    "print(\"--- 承認ケースのテスト --- (途中でyesと入力)\")\n",
    "inputs_approve = {\n",
    "    \"messages\": [HumanMessage(content=\"新しいマーケティングスローガンを考えてください\")],\n",
    "    \"user_request\": \"新しいマーケティングスローガン\", \n",
    "    \"max_improvement_attempts\": 1, \"max_task_retries\": 1\n",
    "}\n",
    "for event in graph.stream(inputs_approve, {\"recursion_limit\": 20}): print(event)\n",
    "# ▲▲▲▲▲▲▲▲▲▲ YOUR CODE HERE ▲▲▲▲▲▲▲▲▲▲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答例を見る</summary>\n",
    "\n",
    "``````python\n",
    "from typing import TypedDict, Annotated, Optional, List\n",
    "import random\n",
    "import time\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class IterativeApprovalState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_request: str                 # ユーザーからの最初の指示\n",
    "    current_proposal: Optional[str]   # 現在の提案内容\n",
    "    self_eval_score: Optional[int]    # 自己評価スコア (例: 1-5、高いほど良い)\n",
    "    improvement_attempts: int         # 自己改善の試行回数\n",
    "    max_improvement_attempts: int     # 最大自己改善回数\n",
    "    human_approved: Optional[bool]    # 人間による最終承認 (True/False)\n",
    "    human_feedback: Optional[str]     # 人間からのフィードバック\n",
    "    error_message: Optional[str]      # 直近のタスクエラーメッセージ\n",
    "    task_retry_count: int            # タスク（提案生成など）のリトライ回数\n",
    "    max_task_retries: int            # タスクの最大リトライ回数\n",
    "    final_outcome: Optional[str]       # 最終的な結果メッセージ\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def initialize_workflow_node(state: IterativeApprovalState):\n",
    "    user_req = state[\"messages\"][-1].content\n",
    "    print(f\"initialize_workflow_node: ユーザーリクエスト '{user_req}' でワークフロー開始。\")\n",
    "    return {\n",
    "        \"user_request\": user_req,\n",
    "        \"current_proposal\": None,\n",
    "        \"self_eval_score\": None,\n",
    "        \"improvement_attempts\": 0,\n",
    "        \"human_approved\": None,\n",
    "        \"human_feedback\": None,\n",
    "        \"error_message\": None,\n",
    "        \"task_retry_count\": 0,\n",
    "        \"final_outcome\": None\n",
    "    }\n",
    "\n",
    "def generate_proposal_node(state: IterativeApprovalState):\n",
    "    req = state[\"user_request\"]\n",
    "    retry = state.get(\"task_retry_count\", 0)\n",
    "    max_retries_for_task = state.get(\"max_task_retries\", 1)\n",
    "    print(f\"generate_proposal_node (リトライ {retry+1}/{max_retries_for_task}): リクエスト '{req}' の提案を生成中...\")\n",
    "    \n",
    "    # ダミーのAPI呼び出し失敗シミュレーション\n",
    "    if retry < max_retries_for_task and random.random() < 0.4: # 40%の確率で初回リトライ可能時に失敗\n",
    "        err_msg = \"提案生成APIへの接続に一時的に失敗しました。\"\n",
    "        print(f\"  -> 失敗: {err_msg}\")\n",
    "        # time.sleep(1)\n",
    "        return {\"error_message\": err_msg, \"task_retry_count\": retry + 1, \"messages\":[AIMessage(content=f\"提案生成試行 {retry+1} 失敗: {err_msg}\")]}\n",
    "    \n",
    "    # 実際の提案生成 (LLM呼び出しなど)\n",
    "    # proposal = llm.invoke(f\"「{req}」に関する提案を作成してください。\").content\n",
    "    proposal = f\"これが「{req}」に関する素晴らしい提案です。バージョン{state.get('improvement_attempts',0)+1}。内容は完璧です。\"\n",
    "    print(f\"  -> 生成された提案: '{proposal}'\")\n",
    "    return {\"current_proposal\": proposal, \"error_message\": None, \"task_retry_count\": 0, \"messages\":[AIMessage(content=f\"生成された提案 (v{state.get('improvement_attempts',0)+1}): {proposal}\")]}\n",
    "\n",
    "def self_evaluate_proposal_node(state: IterativeApprovalState):\n",
    "    proposal = state.get(\"current_proposal\", \"(提案なし)\")\n",
    "    attempts = state.get(\"improvement_attempts\", 0)\n",
    "    print(f\"self_evaluate_proposal_node: 提案 '{proposal[:30]}...' を自己評価中 (改善試行: {attempts})...\")\n",
    "    \n",
    "    # ダミー評価ロジック: 試行回数が少ないうちは低いスコア\n",
    "    score = 2 + attempts * 2 # 試行ごとにスコアが2ずつ上がる (最大改善回数による)\n",
    "    if score > 5: score = 5\n",
    "    print(f\"  -> 自己評価スコア: {score}/5\")\n",
    "    return {\"self_eval_score\": score, \"messages\":[AIMessage(content=f\"自己評価スコア: {score}/5\")]}\n",
    "\n",
    "def improve_proposal_node(state: IterativeApprovalState):\n",
    "    old_proposal = state.get(\"current_proposal\", \"(元の提案なし)\")\n",
    "    attempts = state.get(\"improvement_attempts\", 0) + 1\n",
    "    print(f\"improve_proposal_node (改善試行 {attempts}/{state['max_improvement_attempts']}): 提案 '{old_proposal[:30]}...' を改善中...\")\n",
    "    \n",
    "    # 実際の改善処理 (LLM呼び出しなど)\n",
    "    # new_proposal = llm.invoke(f\"以下の提案を改善してください: {old_proposal}\").content\n",
    "    new_proposal = f\"{old_proposal.split('。')[0]}。さらに洗練されたバージョン{attempts+1}です。今度こそ完璧。\"\n",
    "    print(f\"  -> 改善された提案: '{new_proposal}'\")\n",
    "    return {\"current_proposal\": new_proposal, \"improvement_attempts\": attempts, \"self_eval_score\": None, \"messages\":[AIMessage(content=f\"改善された提案 (v{attempts+1}): {new_proposal}\")]}\n",
    "\n",
    "def human_final_approval_node(state: IterativeApprovalState):\n",
    "    proposal_to_approve = state.get(\"current_proposal\", \"(最終提案なし)\")\n",
    "    print(f\"\\n--- 人間による最終承認ステップ --- \")\n",
    "    print(f\"ユーザーリクエスト: {state['user_request']}\")\n",
    "    print(f\"最終提案:\\n{'-'*30}\\n{proposal_to_approve}\\n{'-'*30}\")\n",
    "    \n",
    "    approval_input = \"\"\n",
    "    while approval_input not in [\"yes\", \"no\"]:\n",
    "        approval_input = input(\"この最終提案を承認しますか？ (yes/no): \").strip().lower()\n",
    "    \n",
    "    approved = (approval_input == \"yes\")\n",
    "    feedback_text = None\n",
    "    human_action_message = \"\"\n",
    "    \n",
    "    if approved:\n",
    "        print(\"  -> 承認されました。\")\n",
    "        human_action_message = \"人間によって最終承認されました。\"\n",
    "    else:\n",
    "        print(\"  -> 差し戻し (拒否) となりました。\")\n",
    "        feedback_text = input(\"差し戻しの理由やフィードバックを入力してください (任意): \").strip()\n",
    "        if not feedback_text: feedback_text = \"(具体的フィードバックなし)\"\n",
    "        print(f\"  -> 受け取ったフィードバック: '{feedback_text}'\")\n",
    "        human_action_message = f\"人間によって差し戻されました。フィードバック: {feedback_text}\"\n",
    "        \n",
    "    return {\"human_approved\": approved, \"human_feedback\": feedback_text, \"messages\":[HumanMessage(content=human_action_message)]}\n",
    "\n",
    "def process_final_outcome_node(state: IterativeApprovalState):\n",
    "    if state.get(\"human_approved\") is True:\n",
    "        outcome_message = f\"最終提案「{state.get('current_proposal', '(不明な提案)')[:30]}...」は承認され、ワークフローは正常に完了しました。\"\n",
    "    else:\n",
    "        outcome_message = f\"最終提案は差し戻されました。フィードバック: 「{state.get('human_feedback', '(フィードバックなし)')}」。ワークフローはここで終了します。\"\n",
    "    print(f\"process_final_outcome_node: {outcome_message}\")\n",
    "    return {\"final_outcome\": outcome_message, \"messages\":[AIMessage(content=outcome_message)]}\n",
    "\n",
    "def task_error_handler_node(state: IterativeApprovalState):\n",
    "    err = state.get(\"error_message\", \"不明なタスクエラー\")\n",
    "    outcome_message = f\"タスク処理中に解決不能なエラーが発生しました: {err}。ワークフローを終了します。\"\n",
    "    print(f\"task_error_handler_node: {outcome_message}\")\n",
    "    return {\"final_outcome\": outcome_message, \"messages\":[AIMessage(content=outcome_message)]}\n",
    "\n",
    "# --- ルーター関数 ---\n",
    "def route_after_proposal_generation(state: IterativeApprovalState):\n",
    "    print(f\"route_after_proposal_generation: エラー '{state.get('error_message')}', リトライ回数 {state.get('task_retry_count',0)}/{state.get('max_task_retries',1)}\")\n",
    "    if state.get(\"error_message\") and state.get(\"task_retry_count\", 0) < state.get(\"max_task_retries\", 1):\n",
    "        print(\"  -> 提案生成リトライ (generatorへ)\")\n",
    "        return \"retry_proposal_generation\"\n",
    "    elif state.get(\"error_message\"):\n",
    "        print(\"  -> 提案生成エラー上限。エラーハンドラ (task_error_handlerへ)\")\n",
    "        return \"handle_generation_failure\"\n",
    "    print(\"  -> 提案生成成功。自己評価 (self_evaluatorへ)\")\n",
    "    return \"proceed_to_self_evaluation\"\n",
    "\n",
    "def route_after_self_evaluation(state: IterativeApprovalState):\n",
    "    score = state.get(\"self_eval_score\", 0)\n",
    "    attempts = state.get(\"improvement_attempts\", 0)\n",
    "    max_attempts = state.get(\"max_improvement_attempts\", 1)\n",
    "    print(f\"route_after_self_evaluation: 自己評価スコア {score}, 改善試行 {attempts}/{max_attempts}\")\n",
    "    if score < 4 and attempts < max_attempts: # スコア4未満、かつ改善上限未満なら改善へ\n",
    "        print(\"  -> スコア不十分。改善 (improverへ)\")\n",
    "        return \"needs_improvement\"\n",
    "    print(\"  -> スコア十分または改善上限。人間による承認 (human_approverへ)\")\n",
    "    return \"ready_for_human_approval\"\n",
    "\n",
    "def route_after_human_approval(state: IterativeApprovalState):\n",
    "    # このデモでは、承認でも差し戻しでも同じ最終結果処理ノードへ行く\n",
    "    # 実際には、差し戻されたら再度改善ループに戻るなどの分岐も考えられる\n",
    "    print(f\"route_after_human_approval: 人間の判断 -> {'承認' if state.get('human_approved') else '差し戻し'}。最終結果処理 (result_processorへ)\")\n",
    "    return \"proceed_to_final_outcome\" \n",
    "\n",
    "# --- グラフ構築 ---\n",
    "workflow = StateGraph(IterativeApprovalState)\n",
    "\n",
    "workflow.add_node(\"initializer\", initialize_workflow_node)\n",
    "workflow.add_node(\"generator\", generate_proposal_node)\n",
    "workflow.add_node(\"self_evaluator\", self_evaluate_proposal_node)\n",
    "workflow.add_node(\"improver\", improve_proposal_node)\n",
    "workflow.add_node(\"human_approver\", human_final_approval_node)\n",
    "workflow.add_node(\"result_processor\", process_final_outcome_node)\n",
    "workflow.add_node(\"task_error_handler\", task_error_handler_node)\n",
    "\n",
    "workflow.set_entry_point(\"initializer\")\n",
    "workflow.add_edge(\"initializer\", \"generator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generator\", \n",
    "    route_after_proposal_generation, \n",
    "    {\n",
    "        \"retry_proposal_generation\": \"generator\", \n",
    "        \"handle_generation_failure\": \"task_error_handler\", \n",
    "        \"proceed_to_self_evaluation\": \"self_evaluator\"\n",
    "    }\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"self_evaluator\", \n",
    "    route_after_self_evaluation,\n",
    "    {\n",
    "        \"needs_improvement\": \"improver\", \n",
    "        \"ready_for_human_approval\": \"human_approver\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"improver\", \"self_evaluator\") # 改善後、再度自己評価へループバック\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_approver\", \n",
    "    route_after_human_approval, \n",
    "    {\"proceed_to_final_outcome\": \"result_processor\"}\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"result_processor\", END)\n",
    "workflow.add_edge(\"task_error_handler\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗: {e}. Graphvizがインストールされているか確認してください。\")\n",
    "\n",
    "# --- 実行 (承認されるケースをシミュレート) ---\n",
    "print(\"\\n--- 第2章まとめテスト (ユーザーが 'yes' と入力して承認するケース) ---\")\n",
    "inputs_approve_case = {\n",
    "    \"messages\": [HumanMessage(content=\"新しい環境保護キャンペーンのスローガンを提案してください\")],\n",
    "    \"max_improvement_attempts\": 2, # 自己改善は最大2回まで\n",
    "    \"max_task_retries\": 1         # 提案生成タスクのリトライは1回まで\n",
    "}\n",
    "print(\"\\nストリーム出力 (承認ケース):\")\n",
    "for event in graph.stream(inputs_approve_case, {\"recursion_limit\": 25}): # ループがあるのでrecursion_limitに注意\n",
    "    print(event)\n",
    "\n",
    "print(\"\\n最終状態の確認 (承認ケース):\")\n",
    "final_state_approve = graph.invoke(inputs_approve_case, {\"recursion_limit\": 25})\n",
    "print(f\"  最終的な結果: {final_state_approve.get('final_outcome')}\")\n",
    "print(f\"  最終提案: {final_state_approve.get('current_proposal')}\")\n",
    "print(f\"  人間による承認: {final_state_approve.get('human_approved')}\")\n",
    "\n",
    "# --- 実行 (差し戻されるケースをシミュレート) ---\n",
    "print(\"\\n--- 第2章まとめテスト (ユーザーが 'no' と入力して差し戻すケース) ---\")\n",
    "inputs_reject_case = {\n",
    "    \"messages\": [HumanMessage(content=\"子供向けの新しい教育アプリのアイデアを出してください\")],\n",
    "    \"max_improvement_attempts\": 1, \n",
    "    \"max_task_retries\": 1\n",
    "}\n",
    "print(\"\\nストリーム出力 (差し戻しケース):\")\n",
    "# input() をモックするか、手動で入力する必要がある。\n",
    "# この自動テストでは、手動入力の代わりに固定値を想定して進めるのは難しい。\n",
    "# ここでは実行ログで人間の入力が求められることを確認するに留める。\n",
    "# 実際のテストでは、 `unittest.mock.patch('builtins.input', side_effect=['no', 'もっとインタラクティブに！'])` のようにする\n",
    "print(\"  (実行時、'no'と入力し、フィードバックを求められたら何か入力してください)\")\n",
    "for event in graph.stream(inputs_reject_case, {\"recursion_limit\": 25}):\n",
    "    print(event)\n",
    "\n",
    "print(\"\\n最終状態の確認 (差し戻しケース - 手動入力結果に依存):\")\n",
    "# final_state_reject = graph.invoke(inputs_reject_case, {\"recursion_limit\": 25})\n",
    "# print(f\"  最終的な結果: {final_state_reject.get('final_outcome')}\")\n",
    "# print(f\"  人間による承認: {final_state_reject.get('human_approved')}\")\n",
    "# print(f\"  人間からのFB: {final_state_reject.get('human_feedback')}\")\n",
    "print(\"  (上記は手動入力の結果に依存するため、コメントアウトしています)\")\n",
    "``````\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
