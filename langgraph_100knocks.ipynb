{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 100本ノック\n",
    "\n",
    "このJupyter Notebookは、LangGraphの基礎から応用までを体系的に学ぶための100問の演習問題とその解答、解説を提供します。LangGraphを用いた複雑なエージェントワークフローの構築スキルを習得しましょう。\n",
    "\n",
    "## 目次\n",
    "\n",
    "*   **第1章: グラフの基本要素 (問題 001-020):** `StateGraph`, `State`, ノード, エッジの定義。最もシンプルなグラフの構築と実行。\n",
    "*   **第2章: グラフの制御フロー (問題 021-040):** 条件付きエッジによる分岐、自己修正ループ、エラーハンドリング、人間による介入(`Interrupt`)。\n",
    "*   **第3章: ツールを使うシングルエージェント (問題 041-060):** `ToolNode`の活用、ReAct型エージェント、計画と実行(Plan-and-Execute)型エージェントの構築。\n",
    "*   **第4章: マルチエージェント・ワークフロー (問題 061-090):** スーパーバイザー型によるタスク割り振り、複数エージェントによる対話シミュレーション、階層型エージェント。\n",
    "*   **第5章: 発展的なグラフ技術 (問題 091-100):** Agent Swarm、永続化(`Checkpointer`)による状態保存と再開、ストリーミング、カスタムエージェント。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ライブラリのインストール ===\n",
    "# ご利用になるLLMプロバイダーに応じて、以下のコメントを解除して実行してください。\n",
    "# !%pip install -qU langchain langchain_openai langchain_google_vertexai langchain_google_genai langchain_anthropic langchain_aws boto3\n",
    "\n",
    "# === LLMプロバイダーの選択 ===\n",
    "# 利用したいLLMプロバイダーを以下の変数で指定してください。\n",
    "# \"openai\", \"azure\", \"google\" (Vertex AI), \"google_genai\" (Gemini API), \"anthropic\", \"bedrock\" のいずれかを選択できます。\n",
    "LLM_PROVIDER = \"openai\"  # 例: OpenAI を利用する場合\n",
    "\n",
    "# === APIキー/環境変数の設定 ===\n",
    "import os\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# --- OpenAI ---\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not OPENAI_API_KEY and IS_COLAB:\n",
    "        OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise ValueError(\"OpenAI APIキーが設定されていません。環境変数 OPENAI_API_KEY を設定するか、Colab環境の場合はシークレットに OPENAI_API_KEY を設定してください。\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# --- Azure OpenAI ---\n",
    "elif LLM_PROVIDER == \"azure\":\n",
    "    AZURE_OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "    AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "    AZURE_OPENAI_DEPLOYMENT_NAME = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "    if IS_COLAB:\n",
    "        if not AZURE_OPENAI_API_KEY: AZURE_OPENAI_API_KEY = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "        if not AZURE_OPENAI_ENDPOINT: AZURE_OPENAI_ENDPOINT = userdata.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        if not OPENAI_API_VERSION: OPENAI_API_VERSION = userdata.get(\"OPENAI_API_VERSION\") # 例: \"2023-07-01-preview\"\n",
    "        if not AZURE_OPENAI_DEPLOYMENT_NAME: AZURE_OPENAI_DEPLOYMENT_NAME = userdata.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "    if not AZURE_OPENAI_API_KEY: raise ValueError(\"Azure OpenAI APIキー (AZURE_OPENAI_API_KEY) が設定されていません。\")\n",
    "    if not AZURE_OPENAI_ENDPOINT: raise ValueError(\"Azure OpenAI エンドポイント (AZURE_OPENAI_ENDPOINT) が設定されていません。\")\n",
    "    if not OPENAI_API_VERSION: OPENAI_API_VERSION = \"2023-07-01-preview\" # デフォルトを設定することも可能\n",
    "    if not AZURE_OPENAI_DEPLOYMENT_NAME: raise ValueError(\"Azure OpenAI デプロイメント名 (AZURE_OPENAI_DEPLOYMENT_NAME) が設定されていません。\")\n",
    "\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "    os.environ[\"OPENAI_API_VERSION\"] = OPENAI_API_VERSION\n",
    "    # AZURE_OPENAI_DEPLOYMENT_NAME はクライアント初期化時に直接渡すため、ここでは環境変数設定は必須ではない\n",
    "\n",
    "# --- Google Cloud Vertex AI (Gemini) ---\n",
    "elif LLM_PROVIDER == \"google\":\n",
    "    PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
    "    LOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\")\n",
    "    # GOOGLE_APPLICATION_CREDENTIALS は通常環境変数で設定されるか、Colabでは自動認証\n",
    "\n",
    "    if IS_COLAB:\n",
    "        if not PROJECT_ID: PROJECT_ID = userdata.get(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
    "        if not LOCATION: LOCATION = userdata.get(\"GOOGLE_CLOUD_LOCATION\") # 例: \"us-central1\"\n",
    "        from google.colab import auth as google_auth\n",
    "        google_auth.authenticate_user() # Vertex AI を使う場合は Colab での認証を推奨\n",
    "\n",
    "    if not PROJECT_ID: raise ValueError(\"Google Cloud Project ID が設定されていません。\")\n",
    "    if not LOCATION: LOCATION = \"us-central1\" # デフォルトロケーション\n",
    "\n",
    "    # os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID # これは通常不要\n",
    "    # os.environ[\"GOOGLE_CLOUD_LOCATION\"] = LOCATION # これも通常不要\n",
    "\n",
    "# --- Google Gemini API (langchain-google-genai) ---\n",
    "elif LLM_PROVIDER == \"google_genai\":\n",
    "    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY and IS_COLAB:\n",
    "        GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY:\n",
    "        raise ValueError(\"Google APIキーが設定されていません。環境変数 GOOGLE_API_KEY を設定するか、Colab環境の場合はシークレットに GOOGLE_API_KEY を設定してください。\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# --- Anthropic (Claude) ---\n",
    "elif LLM_PROVIDER == \"anthropic\":\n",
    "    ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    if not ANTHROPIC_API_KEY and IS_COLAB:\n",
    "        ANTHROPIC_API_KEY = userdata.get(\"ANTHROPIC_API_KEY\")\n",
    "    if not ANTHROPIC_API_KEY:\n",
    "        raise ValueError(\"Anthropic APIキーが設定されていません。環境変数 ANTHROPIC_API_KEY を設定するか、Colab環境の場合はシークレットに ANTHROPIC_API_KEY を設定してください。\")\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "\n",
    "# --- Amazon Bedrock (Claude) ---\n",
    "elif LLM_PROVIDER == \"bedrock\":\n",
    "    AWS_ACCESS_KEY_ID = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "    AWS_SECRET_ACCESS_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    AWS_REGION_NAME = os.environ.get(\"AWS_REGION_NAME\")\n",
    "\n",
    "    if IS_COLAB: # Colabの場合、boto3が認証情報をうまく見つけられない場合があるので明示的な設定を推奨\n",
    "        if not AWS_ACCESS_KEY_ID: AWS_ACCESS_KEY_ID = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
    "        if not AWS_SECRET_ACCESS_KEY: AWS_SECRET_ACCESS_KEY = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "        if not AWS_REGION_NAME: AWS_REGION_NAME = userdata.get(\"AWS_REGION_NAME\")\n",
    "\n",
    "    # BedrockはIAMロールなど他の認証方法もあるため、キーがなくても動作する可能性はある。\n",
    "    # ただし、ここでは明示的な設定がない場合は警告またはエラーを出すことを検討できる。\n",
    "    # 今回は、キーがない場合でも初期化は試みるが、リージョンは必須とする。\n",
    "    if not AWS_REGION_NAME:\n",
    "         raise ValueError(\"AWSリージョン名 (AWS_REGION_NAME) が設定されていません。Bedrock利用にはリージョン指定が必要です。\")\n",
    "\n",
    "    if AWS_ACCESS_KEY_ID: os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "    if AWS_SECRET_ACCESS_KEY: os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "    os.environ[\"AWS_REGION_NAME\"] = AWS_REGION_NAME\n",
    "\n",
    "\n",
    "# === LLMクライアントの動的初期化 ===\n",
    "llm = None\n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "elif LLM_PROVIDER == \"azure\":\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME, # 上で取得・設定済み\n",
    "        openai_api_version=OPENAI_API_VERSION, # 上で取得・設定済み\n",
    "        temperature=0,\n",
    "    )\n",
    "elif LLM_PROVIDER == \"google\":\n",
    "    from langchain_google_vertexai import ChatVertexAI\n",
    "    llm = ChatVertexAI(model_name=\"gemini-1.5-flash-001\", temperature=0, project=PROJECT_ID, location=LOCATION)\n",
    "elif LLM_PROVIDER == \"google_genai\":\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    # 利用可能なモデル名の例: \"gemini-1.5-flash-latest\", \"gemini-1.5-pro-latest\", \"gemini-pro\"\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0, convert_system_message_to_human=True)\n",
    "elif LLM_PROVIDER == \"anthropic\":\n",
    "    from langchain_anthropic import ChatAnthropic\n",
    "    llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)\n",
    "elif LLM_PROVIDER == \"bedrock\":\n",
    "    from langchain_aws import ChatBedrock\n",
    "    llm = BedrockChat(\n",
    "        model_id=\"anthropic.claude-3-haiku-20240307-v1:0\", # Bedrockで利用するモデルID\n",
    "        region_name=AWS_REGION_NAME, # 上で取得・設定済み\n",
    "        model_kwargs={\"temperature\": 0},\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Unsupported LLM_PROVIDER: {LLM_PROVIDER}. \"\n",
    "        \"Please choose from 'openai', 'azure', 'google', 'google_genai', 'anthropic', or 'bedrock'.\"\n",
    "    )\n",
    "\n",
    "print(f\"LLM Provider: {LLM_PROVIDER}\")\n",
    "if llm:\n",
    "    print(f\"LLM Client Type: {type(llm)}\")\n",
    "    model_attr = getattr(llm, 'model', getattr(llm, 'model_name', getattr(llm, 'model_id', None)))\n",
    "    if model_attr:\n",
    "        print(f\"LLM Model: {model_attr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題001: 最小構成のLangGraphグラフの構築\n",
    "\n",
    "LangGraphの最も基本的な構成要素である`StateGraph`と`State`を理解し、シンプルなグラフを構築してみましょう。この問題では、入力された文字列をそのまま出力するだけの、単一のノードを持つグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    print(f\"simple_node: {state[\"messages\"][-1].content}\")\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答001</summary>\n",
    "\n",
    "``````python\n",
    "# 解答001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    # グラフの状態を保持する辞書\n",
    "    # ここでは、入力メッセージを保持する\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # 入力されたメッセージをそのまま返すノード\n",
    "    print(f\"simple_node: {state[\"messages\"][-1].content}\")\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説001</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** この問題では、`StateGraph`、`TypedDict`を用いた`State`の定義、`add_node`、`set_entry_point`、`add_edge`、`END`といったLangGraphの最も基本的なAPIを学びます。また、`Annotated`と`add_messages`を使ってメッセージ履歴を管理する方法も理解します。\n",
    "*   **コード解説:**\n",
    "    *   `GraphState`は、グラフ全体で共有される状態を定義します。`TypedDict`を使うことで、状態のスキーマを明確にできます。`messages: Annotated[list, add_messages]`は、LangChainのメッセージ形式のリストを状態として持ち、新しいメッセージが追加されるたびに自動的にリストの末尾に追加されるように設定しています。\n",
    "    *   `simple_node`関数は、グラフのノードとして機能します。`state`引数として現在のグラフの状態を受け取り、新しい状態を辞書として返します。ここでは、入力された最後のメッセージをそのまま返しています。\n",
    "    *   `StateGraph(GraphState)`でグラフのインスタンスを作成し、`GraphState`で定義した状態スキーマを渡します。\n",
    "    *   `workflow.add_node(\"simple_node\", simple_node)`で、`simple_node`関数を`simple_node`という名前のノードとしてグラフに追加します。\n",
    "    *   `workflow.set_entry_point(\"simple_node\")`は、グラフの実行が開始される最初のノードを指定します。\n",
    "    *   `workflow.add_edge(\"simple_node\", END)`は、`simple_node`の実行が完了したらグラフを終了することを示します。`END`はLangGraphが提供する特別な終了ノードです。\n",
    "    *   `app = workflow.compile()`で、定義したワークフローを実行可能なアプリケーションにコンパイルします。\n",
    "    *   `app.stream(inputs)`は、グラフの実行過程をストリーミングで受け取ることができます。`app.invoke(inputs)`は、グラフの実行が完了した最終状態を返します。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題002: 複数のノードを持つシーケンシャルグラフの構築\n",
    "\n",
    "前の問題で学んだ基本的なグラフ構築に加えて、複数のノードを直列に接続し、データがノード間をどのように流れるかを理解しましょう。ここでは、入力された文字列を加工する2つのノード（例：大文字化、逆順化）を持つグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄002\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"uppercase_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"reverse_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"uppercase\", uppercase_node)\n",
    "workflow.add_node(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"uppercase\")\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.add_edge(\"uppercase\", \"reverse\")\n",
    "workflow.add_edge(\"reverse\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello LangGraph\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答002</summary>\n",
    "\n",
    "``````python\n",
    "# 解答002\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    # 最新のメッセージを大文字に変換するノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"uppercase_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    # 最新のメッセージを逆順にするノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"reverse_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"uppercase\", uppercase_node)\n",
    "workflow.add_node(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"uppercase\")\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.add_edge(\"uppercase\", \"reverse\")\n",
    "workflow.add_edge(\"reverse\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello LangGraph\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説002</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** 複数のノードを`add_edge`で直列に接続する方法と、ノード間で状態がどのように引き継がれるかを学びます。`HumanMessage`と`AIMessage`を使って、メッセージの送信元を明示する方法も理解します。\n",
    "*   **コード解説:**\n",
    "    *   `uppercase_node`と`reverse_node`は、それぞれ入力メッセージを大文字化、逆順化する処理を行います。重要なのは、各ノードが新しい`AIMessage`を作成して状態に返す点です。これにより、次のノードは前のノードの処理結果を`state[\"messages\"][-1]`で取得できます。\n",
    "    *   `workflow.add_edge(\"uppercase\", \"reverse\")`は、`uppercase`ノードの実行が完了したら、次に`reverse`ノードを実行するように指示します。このようにして、処理の流れを定義します。\n",
    "    *   入力メッセージを`HumanMessage`として渡すことで、ユーザーからの入力であることを明示しています。ノードからの出力は`AIMessage`として返され、メッセージ履歴にAIの応答として記録されます。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題003: 条件付きエッジによる分岐の導入\n",
    "\n",
    "LangGraphの強力な機能の一つである条件付きエッジを導入し、グラフの実行パスを動的に制御する方法を学びましょう。ここでは、入力された数値が偶数か奇数かによって、異なる処理を行うグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄003\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    number: int # 新たに数値を保持する状態を追加\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def check_number(state: GraphState):\n",
    "    # 入力メッセージから数値を抽出し、状態に保存するノード\n",
    "    try:\n",
    "        num = int(state[\"messages\"][-1].content)\n",
    "        print(f\"check_number: Extracted number {num}\")\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        print(\"check_number: Invalid input, not a number.\")\n",
    "        return {\"number\": 0} # エラー時は0として扱うか、適切なエラーハンドリングを実装\n",
    "\n",
    "def even_node(state: GraphState):\n",
    "    # 偶数だった場合の処理ノード\n",
    "    print(f\"even_node: Number {state[\"number\"]} is even.\")\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is even.\")]}\n",
    "\n",
    "def odd_node(state: GraphState):\n",
    "    # 奇数だった場合の処理ノード\n",
    "    print(f\"odd_node: Number {state[\"number\"]} is odd.\")\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is odd.\")]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def route_number(state: GraphState):\n",
    "    # 数値の状態に基づいて次のノードを決定する\n",
    "    if state[\"number\"] % 2 == 0:\n",
    "        print(\"Routing to even_node\")\n",
    "        return \"even_node\"\n",
    "    else:\n",
    "        print(\"Routing to odd_node\")\n",
    "        return \"odd_node\"\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"check_number\", check_number)\n",
    "workflow.add_node(\"even_node\", even_node)\n",
    "workflow.add_node(\"odd_node\", odd_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"check_number\")\n",
    "\n",
    "# 条件付きエッジの追加\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_number\", # 遷移元のノード\n",
    "    route_number,   # ルーター関数\n",
    "    {\n",
    "        \"even_node\": \"even_node\", # ルーター関数の戻り値とノード名のマッピング\n",
    "        \"odd_node\": \"odd_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 各分岐からの終了エッジ\n",
    "workflow.add_edge(\"even_node\", END)\n",
    "workflow.add_edge(\"odd_node\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- 偶数のテスト ---\")\n",
    "inputs_even = {\"messages\": [HumanMessage(content=\"42\")]}\n",
    "for s in app.stream(inputs_even):\n",
    "    print(s)\n",
    "final_state_even = app.invoke(inputs_even)\n",
    "print(f\"Final State (Even): {final_state_even}\")\n",
    "\n",
    "print(\"\\n--- 奇数のテスト ---\")\n",
    "inputs_odd = {\"messages\": [HumanMessage(content=\"77\")]}\n",
    "for s in app.stream(inputs_odd):\n",
    "    print(s)\n",
    "final_state_odd = app.invoke(inputs_odd)\n",
    "print(f\"Final State (Odd): {final_state_odd}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説003</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** `add_conditional_edges`を使用して、グラフの実行パスを動的に制御する方法を学びます。ルーター関数がどのように次のノードを決定するのか、そして状態が分岐間でどのように共有されるかを理解します。\n",
    "*   **コード解説:**\n",
    "    *   `GraphState`に`number`という新しいキーを追加し、入力された数値を保持するようにしました。\n",
    "    *   `check_number`ノードは、入力メッセージから数値を抽出し、`number`状態を更新します。\n",
    "    *   `even_node`と`odd_node`は、それぞれ偶数と奇数だった場合の最終処理を行います。\n",
    "    *   `route_number`関数がルーターとして機能します。この関数は現在の`state`を受け取り、次に実行すべきノードの名前（文字列）を返します。LangGraphは、この戻り値に基づいて適切なエッジを辿ります。\n",
    "    *   `workflow.add_conditional_edges(\"check_number\", route_number, {\"even_node\": \"even_node\", \"odd_node\": \"odd_node\"})`は、`check_number`ノードの後に`route_number`関数を実行し、その戻り値が`\"even_node\"`なら`even_node`へ、`\"odd_node\"`なら`odd_node`へ遷移するように設定しています。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題004: グラフ内でのLLMの利用（シンプルなチャットボット）\n",
    "\n",
    "LangGraphのノード内で大規模言語モデル（LLM）を呼び出す方法を学び、シンプルなチャットボットを構築しましょう。ここでは、ユーザーからの入力に対してLLMが応答を生成し、その応答を返すグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄004\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "import os # osはAPIキー設定のコメントアウト部分で使われているので残しても良いが、直接は不要になる\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def llm_node(state: GraphState):\n",
    "    # LLMを呼び出し、応答を生成するノード\n",
    "    # ノートブック冒頭で初期化された共通の `llm` 変数を使用します。\n",
    "    print(f\"llm_node: Calling LLM with messages: {state['messages']}\")\n",
    "    response = llm.invoke(state[\"messages\"]) # 共通llmを使用\n",
    "    print(f\"llm_node: LLM response: {response.content}\")\n",
    "    return {\"messages\": [response]} # responseはAIMessageオブジェクトを期待\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"llm_responder\", llm_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"llm_responder\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"llm_responder\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- チャットボットのテスト ---\")\n",
    "# 最初のメッセージはHumanMessageであると想定\n",
    "inputs = {\"messages\": [HumanMessage(content=\"こんにちは、あなたの名前は何ですか？\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n",
    "\n",
    "print(\"\\n--- 別の質問 ---\")\n",
    "inputs2 = {\"messages\": [HumanMessage(content=\"今日の天気は？\")]}\n",
    "for s in app.stream(inputs2):\n",
    "    print(s)\n",
    "\n",
    "final_state2 = app.invoke(inputs2)\n",
    "print(f\"Final State: {final_state2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答004</summary>\n",
    "\n",
    "``````python\n",
    "# 解答004\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "import os # osはAPIキー設定のコメントアウト部分で使われているので残しても良いが、直接は不要になる\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def llm_node(state: GraphState):\n",
    "    # LLMを呼び出し、応答を生成するノード\n",
    "    # ノートブック冒頭で初期化された共通の `llm` 変数を使用します。\n",
    "    print(f\"llm_node: Calling LLM with messages: {state['messages']}\")\n",
    "    response = llm.invoke(state[\"messages\"]) # 共通llmを使用\n",
    "    print(f\"llm_node: LLM response: {response.content}\")\n",
    "    return {\"messages\": [response]} # responseはAIMessageオブジェクトを期待\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"llm_responder\", llm_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"llm_responder\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"llm_responder\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- チャットボットのテスト ---\")\n",
    "# 最初のメッセージはHumanMessageであると想定\n",
    "inputs = {\"messages\": [HumanMessage(content=\"こんにちは、あなたの名前は何ですか？\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n",
    "\n",
    "print(\"\\n--- 別の質問 ---\")\n",
    "inputs2 = {\"messages\": [HumanMessage(content=\"今日の天気は？\")]}\n",
    "for s in app.stream(inputs2):\n",
    "    print(s)\n",
    "\n",
    "final_state2 = app.invoke(inputs2)\n",
    "print(f\"Final State: {final_state2}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説004</summary>\n",
    "\n",
    "このノートブックでは、様々なLLMプラットフォーム（OpenAI, Azure OpenAI, Google Cloud Vertex AI, Google Gemini (Gemini API), Anthropic Claude, Amazon Bedrockなど）を簡単に切り替えて試せるように設計されています。\n",
    "ノートブックの冒頭にある `LLM_PROVIDER` 変数で使用したいLLMを選択し、対応するAPIキーや環境変数を設定するだけで、この問題を含む全てのLLM呼び出し箇所で選択したLLMが利用されます。\n",
    "選択した `LLM_PROVIDER` に応じて、必要なAPIキーが設定されているか（環境変数またはGoogle Colabのシークレット経由）、ノートブック起動時にチェックされます。\n",
    "\n",
    "ここでは、ノートブックの先頭で設定・初期化された共通の `llm` 変数を使用して、LLMに質問をしています。\n",
    "`llm.invoke()` という統一されたインターフェースで、どのLLMプロバイダーを利用しているかに関わらず、同じようにLLMを呼び出すことができます。\n",
    "これにより、特定のLLMサービスに依存しない、より汎用的なコードを作成するメリットを手軽に体験できます。\n",
    "\n",
    "もしエラーが発生した場合は、ノートブック冒頭の `LLM_PROVIDER` の設定、および選択したプロバイダーに応じたAPIキーや環境変数の設定（例: `OPENAI_API_KEY`, `GOOGLE_API_KEY`, `AZURE_OPENAI_ENDPOINT`など）が正しく行われているかを確認してください。\n",
    "各プロバイダー固有の設定項目（例えばVertex AIのProject ID、AzureのDeployment Name、Bedrockのリージョンなど）も見直してください。\n",
    "プロバイダーによっては、`pip install` コマンドで対応するライブラリ (例: `langchain-google-genai`) がインストールされているかも確認点です。\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題005: グラフの可視化とデバッグ\n",
    "\n",
    "構築したLangGraphグラフの構造を視覚的に確認し、デバッグに役立てる方法を学びましょう。ここでは、これまでに作成したグラフのいずれか（例：問題003の条件分岐グラフ）を可視化し、その構造を理解します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄005\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    number: int\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def check_number(state: GraphState):\n",
    "    try:\n",
    "        num = int(state[\"messages\"][-1].content)\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        return {\"number\": 0}\n",
    "\n",
    "def even_node(state: GraphState):\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is even.\")]}\n",
    "\n",
    "def odd_node(state: GraphState):\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is odd.\")]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def route_number(state: GraphState):\n",
    "    if state[\"number\"] % 2 == 0:\n",
    "        return \"even_node\"\n",
    "    else:\n",
    "        return \"odd_node\"\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"check_number\", check_number)\n",
    "workflow.add_node(\"even_node\", even_node)\n",
    "workflow.add_node(\"odd_node\", odd_node)\n",
    "\n",
    "workflow.set_entry_point(\"check_number\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_number\",\n",
    "    route_number,\n",
    "    {\n",
    "        \"even_node\": \"even_node\",\n",
    "        \"odd_node\": \"odd_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"even_node\", END)\n",
    "workflow.add_edge(\"odd_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "# グラフを画像として表示\n",
    "# graphvizがインストールされている必要があります: pip install pygraphviz pydotplus graphviz\n",
    "# また、システムにGraphvizがインストールされている必要があります。\n",
    "# Windows: https://graphviz.org/download/\n",
    "# Mac: brew install graphviz\n",
    "# Linux: sudo apt-get install graphviz\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_png()))\n",
    "    print(\"グラフが正常に可視化されました。\")\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n",
    "\n",
    "# --- グラフの実行と結果表示 (オプション) ---\n",
    "# 可視化したグラフが正しく動作するか確認するために、再度実行してみる\n",
    "print(\"\\n--- 偶数のテスト (可視化後の確認) ---\")\n",
    "inputs_even = {\"messages\": [HumanMessage(content=\"10\")]}\n",
    "for s in app.stream(inputs_even):\n",
    "    print(s)\n",
    "final_state_even = app.invoke(inputs_even)\n",
    "print(f\"Final State: {final_state_even}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説005</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** `app.get_graph().draw_png()`を使用してLangGraphのグラフ構造を画像として可視化する方法を学びます。これにより、複雑なグラフのデバッグや理解が容易になります。\n",
    "*   **コード解説:**\n",
    "    *   この問題では、問題003で作成した条件分岐グラフを再利用しています。これは、可視化の有用性を示すのに適した例だからです。\n",
    "    *   `app.get_graph()`は、コンパイルされたグラフの内部表現を取得します。\n",
    "    *   `.draw_png()`メソッドは、そのグラフ構造をPNG画像としてバイト列で返します。この機能を利用するには、システムにGraphvizがインストールされている必要があります。また、Pythonの`pygraphviz`や`pydotplus`といったライブラリも必要になる場合があります。\n",
    "    *   `IPython.display.Image`と`display`を使うことで、Jupyter Notebook内で直接画像をレンダリングして表示できます。\n",
    "    *   `try-except`ブロックでGraphvizのインストール状況によるエラーをハンドリングし、ユーザーに適切なメッセージを表示するようにしています。グラフが複雑になるにつれて、この可視化機能はデバッグや設計の確認に不可欠となります。\n",
    "---\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
