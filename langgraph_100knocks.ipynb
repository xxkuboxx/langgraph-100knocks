{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 100本ノック\n",
    "\n",
    "このJupyter Notebookは、LangGraphの基礎から応用までを体系的に学ぶための100問の演習問題とその解答、解説を提供します。LangGraphを用いた複雑なエージェントワークフローの構築スキルを習得しましょう。\n",
    "\n",
    "## 目次\n",
    "\n",
    "*   **第1章: グラフの基本要素 (問題 001-020):** `StateGraph`, `State`, ノード, エッジの定義。最もシンプルなグラフの構築と実行。\n",
    "*   **第2章: グラフの制御フロー (問題 021-040):** 条件付きエッジによる分岐、自己修正ループ、エラーハンドリング、人間による介入(`Interrupt`)。\n",
    "*   **第3章: ツールを使うシングルエージェント (問題 041-060):** `ToolNode`の活用、ReAct型エージェント、計画と実行(Plan-and-Execute)型エージェントの構築。\n",
    "*   **第4章: マルチエージェント・ワークフロー (問題 061-090):** スーパーバイザー型によるタスク割り振り、複数エージェントによる対話シミュレーション、階層型エージェント。\n",
    "*   **第5章: 発展的なグラフ技術 (問題 091-100):** Agent Swarm、永続化(`Checkpointer`)による状態保存と再開、ストリーミング、カスタムエージェント。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ライブラリのインストール ===\n",
    "# ご利用になるLLMプロバイダーに応じて、以下のコメントを解除して実行してください。\n",
    "# !%pip install -qU langchain langchain_openai langchain_google_vertexai langchain_anthropic langchain_aws boto3\n",
    "\n",
    "# === LLMプロバイダーの選択 ===\n",
    "# 利用したいLLMプロバイダーを以下の変数で指定してください。\n",
    "# \"openai\", \"azure\", \"google\", \"anthropic\", \"bedrock\" のいずれかを選択できます。\n",
    "LLM_PROVIDER = \"openai\"  # 例: OpenAI を利用する場合\n",
    "\n",
    "# === APIキー/環境変数の設定 ===\n",
    "import os\n",
    "from google.colab import userdata # Google Colab を利用する場合\n",
    "\n",
    "# --- OpenAI ---\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "# または Colab の場合\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# --- Azure OpenAI ---\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"YOUR_AZURE_OPENAI_API_KEY\"\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"YOUR_AZURE_OPENAI_ENDPOINT\"\n",
    "# os.environ[\"OPENAI_API_VERSION\"] = \"YOUR_OPENAI_API_VERSION\" # 例: \"2023-07-01-preview\"\n",
    "# または Colab の場合\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# os.environ[\"OPENAI_API_VERSION\"] = userdata.get(\"OPENAI_API_VERSION\")\n",
    "\n",
    "\n",
    "# --- Google Cloud Vertex AI (Gemini) ---\n",
    "# Google CloudプロジェクトIDを設定\n",
    "# PROJECT_ID = \"YOUR_GOOGLE_CLOUD_PROJECT_ID\"\n",
    "# LOCATION = \"YOUR_GOOGLE_CLOUD_LOCATION\" # 例: \"us-central1\"\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"PATH_TO_YOUR_SERVICE_ACCOUNT_KEY_JSON\"\n",
    "#\n",
    "# from google.colab import auth as google_auth # Google Colab を利用する場合\n",
    "# google_auth.authenticate_user()\n",
    "#\n",
    "# if LLM_PROVIDER == \"google\" and not os.getenv(\"GOOGLE_CLOUD_PROJECT\") and not PROJECT_ID: # PROJECT_IDが未定義の場合も考慮\n",
    "#     # Google Colab環境でPROJECT_IDが設定されていない場合、ユーザーに設定を促すか、デフォルトのプロジェクトを使用するなどの処理\n",
    "#     try:\n",
    "#         PROJECT_ID = userdata.get(\"GOOGLE_CLOUD_PROJECT_ID\") # Colabのシークレットから読み込む試み\n",
    "#         if not PROJECT_ID:\n",
    "#             print(\"警告: Google Cloud Project ID が設定されていません。Vertex AI を利用する場合は設定が必要です。\")\n",
    "#     except Exception:\n",
    "#          print(\"警告: Google Cloud Project ID が設定されていません。Vertex AI を利用する場合は設定が必要です。\")\n",
    "#\n",
    "# if LLM_PROVIDER == \"google\" and not PROJECT_ID and not os.getenv(\"GOOGLE_CLOUD_PROJECT\"):\n",
    "#     raise ValueError(\"Google Cloud Project ID is not set. Please set the PROJECT_ID variable or GOOGLE_CLOUD_PROJECT environment variable.\")\n",
    "\n",
    "\n",
    "# --- Anthropic (Claude) ---\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR_ANTHROPIC_API_KEY\"\n",
    "# または Colab の場合\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "# --- Amazon Bedrock (Claude) ---\n",
    "# AWS認証情報を設定 (環境変数、IAMロール、または ~/.aws/credentials で設定)\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = \"YOUR_AWS_ACCESS_KEY_ID\"\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"YOUR_AWS_SECRET_ACCESS_KEY\"\n",
    "# os.environ[\"AWS_REGION_NAME\"] = \"YOUR_AWS_REGION_NAME\" # 例: \"us-east-1\"\n",
    "# または Colab の場合\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "# os.environ[\"AWS_REGION_NAME\"] = userdata.get(\"AWS_REGION_NAME\")\n",
    "\n",
    "\n",
    "# === LLMクライアントの動的初期化 ===\n",
    "llm = None\n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    # 利用可能なモデル名の例: \"gpt-4o-mini\", \"gpt-4o\", \"gpt-3.5-turbo\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "elif LLM_PROVIDER == \"azure\":\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    # Azure OpenAI のデプロイ名を指定\n",
    "    # AZURE_OPENAI_DEPLOYMENT_NAME = \"YOUR_AZURE_OPENAI_DEPLOYMENT_NAME\"\n",
    "    # または環境変数 AZURE_OPENAI_DEPLOYMENT_NAME から取得\n",
    "    # または Colab の場合\n",
    "    # AZURE_OPENAI_DEPLOYMENT_NAME = userdata.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "    azure_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "    if not azure_deployment:\n",
    "        try:\n",
    "            azure_deployment = userdata.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "        except Exception:\n",
    "            pass # userdata が利用できない環境やキーが存在しない場合\n",
    "    if not azure_deployment:\n",
    "        raise ValueError(\"Azure OpenAI deployment name is not set. Please set the AZURE_OPENAI_DEPLOYMENT_NAME environment variable or define it in the notebook.\")\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=azure_deployment,\n",
    "        openai_api_version=os.environ.get(\"OPENAI_API_VERSION\", \"2023-07-01-preview\"),\n",
    "        temperature=0,\n",
    "    )\n",
    "elif LLM_PROVIDER == \"google\":\n",
    "    from langchain_google_vertexai import ChatVertexAI\n",
    "    # 利用可能なモデル名の例: \"gemini-1.5-flash-001\", \"gemini-1.5-pro-001\", \"gemini-1.0-pro\"\n",
    "    # PROJECT_ID と LOCATION が正しく設定されていることを確認\n",
    "    # LOCATION のデフォルト値を設定\n",
    "    resolved_project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\", PROJECT_ID if 'PROJECT_ID' in locals() else None)\n",
    "    resolved_location = os.getenv(\"GOOGLE_CLOUD_LOCATION\", LOCATION if 'LOCATION' in locals() else \"us-central1\")\n",
    "\n",
    "    if not resolved_project_id:\n",
    "        raise ValueError(\"Google Cloud Project ID is not set. Please set the PROJECT_ID variable or GOOGLE_CLOUD_PROJECT environment variable.\")\n",
    "\n",
    "    llm = ChatVertexAI(model_name=\"gemini-1.5-flash-001\", temperature=0, project=resolved_project_id, location=resolved_location)\n",
    "elif LLM_PROVIDER == \"anthropic\":\n",
    "    from langchain_anthropic import ChatAnthropic\n",
    "    # 利用可能なモデル名の例: \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"\n",
    "    llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)\n",
    "elif LLM_PROVIDER == \"bedrock\":\n",
    "    from langchain_aws import ChatBedrock\n",
    "    # 利用可能なモデルIDの例:\n",
    "    # Anthropic Claude: \"anthropic.claude-3-sonnet-20240229-v1:0\", \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    # Meta Llama 3: \"meta.llama3-8b-instruct-v1:0\"\n",
    "    # Mistral: \"mistral.mistral-large-2402-v1:0\"\n",
    "    # Cohere: \"cohere.command-r-v1:0\"\n",
    "    resolved_region_name = os.getenv(\"AWS_REGION_NAME\")\n",
    "    if not resolved_region_name:\n",
    "        try:\n",
    "            resolved_region_name = userdata.get(\"AWS_REGION_NAME\")\n",
    "        except Exception:\n",
    "            pass # userdata が利用できない環境やキーが存在しない場合\n",
    "    # BedrockChatはregion_nameがNoneでも動作する場合があるため、必須とはしないが、指定を推奨\n",
    "\n",
    "    llm = BedrockChat(\n",
    "        model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        region_name=resolved_region_name,\n",
    "        model_kwargs={\"temperature\": 0},\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Unsupported LLM_PROVIDER: {LLM_PROVIDER}. \"\n",
    "        \"Please choose from 'openai', 'azure', 'google', 'anthropic', or 'bedrock'.\"\n",
    "    )\n",
    "\n",
    "print(f\"LLM Provider: {LLM_PROVIDER}\")\n",
    "# print(f\"LLM Client: {llm}\") # 詳細なクライアント情報はデバッグ時以外は不要な場合もあるためコメントアウトも検討\n",
    "if llm:\n",
    "    print(f\"LLM Client Type: {type(llm)}\")\n",
    "    if hasattr(llm, 'model_name'):\n",
    "        print(f\"LLM Model: {llm.model_name}\")\n",
    "    elif hasattr(llm, 'model'):\n",
    "        print(f\"LLM Model: {llm.model}\")\n",
    "    elif hasattr(llm, 'model_id'):\n",
    "        print(f\"LLM Model: {llm.model_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題001: 最小構成のLangGraphグラフの構築\n",
    "\n",
    "LangGraphの最も基本的な構成要素である`StateGraph`と`State`を理解し、シンプルなグラフを構築してみましょう。この問題では、入力された文字列をそのまま出力するだけの、単一のノードを持つグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, ____]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    print(f\"simple_node: {state[\"messages\"][-1].content}\")\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.____(\"simple_node\", simple_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.____(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.____(\"simple_node\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.____()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "for s in app.____(inputs):\n",
    "    print(s)\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = app.____(inputs)\n",
    "print(f\"Final State: {final_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答001</summary>\n",
    "\n",
    "``````python\n",
    "# 解答001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    # グラフの状態を保持する辞書\n",
    "    # ここでは、入力メッセージを保持する\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # 入力されたメッセージをそのまま返すノード\n",
    "    print(f\"simple_node: {state[\"messages\"][-1].content}\")\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説001</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** この問題では、`StateGraph`、`TypedDict`を用いた`State`の定義、`add_node`、`set_entry_point`、`add_edge`、`END`といったLangGraphの最も基本的なAPIを学びます。また、`Annotated`と`add_messages`を使ってメッセージ履歴を管理する方法も理解します。\n",
    "*   **コード解説:**\n",
    "    *   `GraphState`は、グラフ全体で共有される状態を定義します。`TypedDict`を使うことで、状態のスキーマを明確にできます。`messages: Annotated[list, add_messages]`は、LangChainのメッセージ形式のリストを状態として持ち、新しいメッセージが追加されるたびに自動的にリストの末尾に追加されるように設定しています。\n",
    "    *   `simple_node`関数は、グラフのノードとして機能します。`state`引数として現在のグラフの状態を受け取り、新しい状態を辞書として返します。ここでは、入力された最後のメッセージをそのまま返しています。\n",
    "    *   `StateGraph(GraphState)`でグラフのインスタンスを作成し、`GraphState`で定義した状態スキーマを渡します。\n",
    "    *   `workflow.add_node(\"simple_node\", simple_node)`で、`simple_node`関数を`simple_node`という名前のノードとしてグラフに追加します。\n",
    "    *   `workflow.set_entry_point(\"simple_node\")`は、グラフの実行が開始される最初のノードを指定します。\n",
    "    *   `workflow.add_edge(\"simple_node\", END)`は、`simple_node`の実行が完了したらグラフを終了することを示します。`END`はLangGraphが提供する特別な終了ノードです。\n",
    "    *   `app = workflow.compile()`で、定義したワークフローを実行可能なアプリケーションにコンパイルします。\n",
    "    *   `app.stream(inputs)`は、グラフの実行過程をストリーミングで受け取ることができます。`app.invoke(inputs)`は、グラフの実行が完了した最終状態を返します。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題002: 複数のノードを持つシーケンシャルグラフの構築\n",
    "\n",
    "前の問題で学んだ基本的なグラフ構築に加えて、複数のノードを直列に接続し、データがノード間をどのように流れるかを理解しましょう。ここでは、入力された文字列を加工する2つのノード（例：大文字化、逆順化）を持つグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄002\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, ____]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"uppercase_node: {last_message_content}\")\n",
    "    return {\"messages\": [____(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"reverse_node: {last_message_content}\")\n",
    "    return {\"messages\": [____(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.____(\"uppercase\", uppercase_node)\n",
    "workflow.____(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.____(\"uppercase\")\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.____(\"uppercase\", \"reverse\")\n",
    "workflow.____(\"reverse\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.____()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [____(content=\"Hello LangGraph\")]}\n",
    "for s in app.____(inputs):\n",
    "    print(s)\n",
    "\n",
    "final_state = app.____(inputs)\n",
    "print(f\"Final State: {final_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答002</summary>\n",
    "\n",
    "``````python\n",
    "# 解答002\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    # 最新のメッセージを大文字に変換するノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"uppercase_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    # 最新のメッセージを逆順にするノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"reverse_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"uppercase\", uppercase_node)\n",
    "workflow.add_node(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"uppercase\")\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.add_edge(\"uppercase\", \"reverse\")\n",
    "workflow.add_edge(\"reverse\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello LangGraph\")]}\n",
    "for s in app.stream(inputs):\n",
    "    print(s)\n",
    "\n",
    "final_state = app.invoke(inputs)\n",
    "print(f\"Final State: {final_state}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説002</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** 複数のノードを`add_edge`で直列に接続する方法と、ノード間で状態がどのように引き継がれるかを学びます。`HumanMessage`と`AIMessage`を使って、メッセージの送信元を明示する方法も理解します。\n",
    "*   **コード解説:**\n",
    "    *   `uppercase_node`と`reverse_node`は、それぞれ入力メッセージを大文字化、逆順化する処理を行います。重要なのは、各ノードが新しい`AIMessage`を作成して状態に返す点です。これにより、次のノードは前のノードの処理結果を`state[\"messages\"][-1]`で取得できます。\n",
    "    *   `workflow.add_edge(\"uppercase\", \"reverse\")`は、`uppercase`ノードの実行が完了したら、次に`reverse`ノードを実行するように指示します。このようにして、処理の流れを定義します。\n",
    "    *   入力メッセージを`HumanMessage`として渡すことで、ユーザーからの入力であることを明示しています。ノードからの出力は`AIMessage`として返され、メッセージ履歴にAIの応答として記録されます。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題003: 条件付きエッジによる分岐の導入\n",
    "\n",
    "LangGraphの強力な機能の一つである条件付きエッジを導入し、グラフの実行パスを動的に制御する方法を学びましょう。ここでは、入力された数値が偶数か奇数かによって、異なる処理を行うグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄003\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, ____]\n",
    "    number: int # 新たに数値を保持する状態を追加\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def check_number(state: GraphState):\n",
    "    # 入力メッセージから数値を抽出し、状態に保存するノード\n",
    "    try:\n",
    "        num = int(state[\"messages\"][-1].content)\n",
    "        print(f\"check_number: Extracted number {num}\")\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        print(\"check_number: Invalid input, not a number.\")\n",
    "        return {\"number\": 0} # エラー時は0として扱うか、適切なエラーハンドリングを実装\n",
    "\n",
    "def even_node(state: GraphState):\n",
    "    # 偶数だった場合の処理ノード\n",
    "    print(f\"even_node: Number {state[\"number\"]} is even.\")\n",
    "    return {\"messages\": [____(content=f\"The number {state[\"number\"]} is even.\")]}\n",
    "\n",
    "def odd_node(state: GraphState):\n",
    "    # 奇数だった場合の処理ノード\n",
    "    print(f\"odd_node: Number {state[\"number\"]} is odd.\")\n",
    "    return {\"messages\": [____(content=f\"The number {state[\"number\"]} is odd.\")]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def route_number(state: GraphState):\n",
    "    # 数値の状態に基づいて次のノードを決定する\n",
    "    if state[\"number\"] % 2 == 0:\n",
    "        print(\"Routing to even_node\")\n",
    "        return \"even_node\"\n",
    "    else:\n",
    "        print(\"Routing to odd_node\")\n",
    "        return \"odd_node\"\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.____(\"check_number\", check_number)\n",
    "workflow.____(\"even_node\", even_node)\n",
    "workflow.____(\"odd_node\", odd_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.____(\"check_number\")\n",
    "\n",
    "# 条件付きエッジの追加\n",
    "workflow.____(\n",
    "    \"check_number\", # 遷移元のノード\n",
    "    ____,   # ルーター関数\n",
    "    {\n",
    "        \"even_node\": \"even_node\", # ルーター関数の戻り値とノード名のマッピング\n",
    "        \"odd_node\": \"odd_node\"\n",
    "    }\n",
    " )\n",
    "\n",
    "# 各分岐からの終了エッジ\n",
    "workflow.____(\"even_node\", ____)\n",
    "workflow.____(\"odd_node\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.____()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- 偶数のテスト ---\")\n",
    "inputs_even = {\"messages\": [____(content=\"42\")]}\n",
    "for s in app.____(inputs_even):\n",
    "    print(s)\n",
    "final_state_even = app.____(inputs_even)\n",
    "print(f\"Final State (Even): {final_state_even}\")\n",
    "\n",
    "print(\"\\n--- 奇数のテスト ---\")\n",
    "inputs_odd = {\"messages\": [____(content=\"77\")]}\n",
    "for s in app.____(inputs_odd):\n",
    "    print(s)\n",
    "final_state_odd = app.____(inputs_odd)\n",
    "print(f\"Final State (Odd): {final_state_odd}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答003</summary>\n",
    "\n",
    "``````python\n",
    "# 解答003\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    number: int # 新たに数値を保持する状態を追加\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def check_number(state: GraphState):\n",
    "    # 入力メッセージから数値を抽出し、状態に保存するノード\n",
    "    try:\n",
    "        num = int(state[\"messages\"][-1].content)\n",
    "        print(f\"check_number: Extracted number {num}\")\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        print(\"check_number: Invalid input, not a number.\")\n",
    "        return {\"number\": 0} # エラー時は0として扱うか、適切なエラーハンドリングを実装\n",
    "\n",
    "def even_node(state: GraphState):\n",
    "    # 偶数だった場合の処理ノード\n",
    "    print(f\"even_node: Number {state[\"number\"]} is even.\")\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is even.\")]}\n",
    "\n",
    "def odd_node(state: GraphState):\n",
    "    # 奇数だった場合の処理ノード\n",
    "    print(f\"odd_node: Number {state[\"number\"]} is odd.\")\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is odd.\")]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def route_number(state: GraphState):\n",
    "    # 数値の状態に基づいて次のノードを決定する\n",
    "    if state[\"number\"] % 2 == 0:\n",
    "        print(\"Routing to even_node\")\n",
    "        return \"even_node\"\n",
    "    else:\n",
    "        print(\"Routing to odd_node\")\n",
    "        return \"odd_node\"\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"check_number\", check_number)\n",
    "workflow.add_node(\"even_node\", even_node)\n",
    "workflow.add_node(\"odd_node\", odd_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"check_number\")\n",
    "\n",
    "# 条件付きエッジの追加\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_number\", # 遷移元のノード\n",
    "    route_number,   # ルーター関数\n",
    "    {\n",
    "        \"even_node\": \"even_node\", # ルーター関数の戻り値とノード名のマッピング\n",
    "        \"odd_node\": \"odd_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 各分岐からの終了エッジ\n",
    "workflow.add_edge(\"even_node\", END)\n",
    "workflow.add_edge(\"odd_node\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- 偶数のテスト ---\")\n",
    "inputs_even = {\"messages\": [HumanMessage(content=\"42\")]}\n",
    "for s in app.stream(inputs_even):\n",
    "    print(s)\n",
    "final_state_even = app.invoke(inputs_even)\n",
    "print(f\"Final State (Even): {final_state_even}\")\n",
    "\n",
    "print(\"\\n--- 奇数のテスト ---\")\n",
    "inputs_odd = {\"messages\": [HumanMessage(content=\"77\")]}\n",
    "for s in app.stream(inputs_odd):\n",
    "    print(s)\n",
    "final_state_odd = app.invoke(inputs_odd)\n",
    "print(f\"Final State (Odd): {final_state_odd}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説003</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** `add_conditional_edges`を使用して、グラフの実行パスを動的に制御する方法を学びます。ルーター関数がどのように次のノードを決定するのか、そして状態が分岐間でどのように共有されるかを理解します。\n",
    "*   **コード解説:**\n",
    "    *   `GraphState`に`number`という新しいキーを追加し、入力された数値を保持するようにしました。\n",
    "    *   `check_number`ノードは、入力メッセージから数値を抽出し、`number`状態を更新します。\n",
    "    *   `even_node`と`odd_node`は、それぞれ偶数と奇数だった場合の最終処理を行います。\n",
    "    *   `route_number`関数がルーターとして機能します。この関数は現在の`state`を受け取り、次に実行すべきノードの名前（文字列）を返します。LangGraphは、この戻り値に基づいて適切なエッジを辿ります。\n",
    "    *   `workflow.add_conditional_edges(\"check_number\", route_number, {\"even_node\": \"even_node\", \"odd_node\": \"odd_node\"})`は、`check_number`ノードの後に`route_number`関数を実行し、その戻り値が`\"even_node\"`なら`even_node`へ、`\"odd_node\"`なら`odd_node`へ遷移するように設定しています。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題004: グラフ内でのLLMの利用（シンプルなチャットボット）\n",
    "\n",
    "LangGraphのノード内で大規模言語モデル（LLM）を呼び出す方法を学び、シンプルなチャットボットを構築しましょう。ここでは、ユーザーからの入力に対してLLMが応答を生成し、その応答を返すグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題004: LLMに質問する\n",
    "\n",
    "# ノートブックの先頭で初期化された共通のllmクライアントを使用します。\n",
    "# LLM_PROVIDER の設定に応じて、異なるLLMが利用されます。\n",
    "\n",
    "question = \"LangGraphとは何ですか？簡単に説明してください。\"\n",
    "\n",
    "# 共通のllm変数を使ってLLMを呼び出します\n",
    "try:\n",
    "    response = llm.invoke(question)\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"LLMの呼び出し中にエラーが発生しました: {e}\")\n",
    "    print(\"ノートブック冒頭のLLMプロバイダーの設定やAPIキーが正しく行われているか確認してください。\")\n",
    "    if LLM_PROVIDER == \"google\":\n",
    "        print(\"Vertex AI をご利用の場合、Project ID と Location が正しく設定されているか、認証が完了しているか確認してください。\")\n",
    "    elif LLM_PROVIDER == \"azure\":\n",
    "        print(\"Azure OpenAI をご利用の場合、Endpoint, API Key, API Version, Deployment Name が正しく設定されているか確認してください。\")\n",
    "    elif LLM_PROVIDER == \"bedrock\":\n",
    "        print(\"Amazon Bedrock をご利用の場合、AWS認証情報（Access Key, Secret Key, Region）が正しく設定されているか確認してください。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答004</summary>\n",
    "\n",
    "``````python\n",
    "# 問題004: LLMに質問する\n",
    "\n",
    "# ノートブックの先頭で初期化された共通のllmクライアントを使用します。\n",
    "# LLM_PROVIDER の設定に応じて、異なるLLMが利用されます。\n",
    "\n",
    "question = \"LangGraphとは何ですか？簡単に説明してください。\"\n",
    "\n",
    "# 共通のllm変数を使ってLLMを呼び出します\n",
    "try:\n",
    "    response = llm.invoke(question)\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"LLMの呼び出し中にエラーが発生しました: {e}\")\n",
    "    print(\"ノートブック冒頭のLLMプロバイダーの設定やAPIキーが正しく行われているか確認してください。\")\n",
    "    if LLM_PROVIDER == \"google\":\n",
    "        print(\"Vertex AI をご利用の場合、Project ID と Location が正しく設定されているか、認証が完了しているか確認してください。\")\n",
    "    elif LLM_PROVIDER == \"azure\":\n",
    "        print(\"Azure OpenAI をご利用の場合、Endpoint, API Key, API Version, Deployment Name が正しく設定されているか確認してください。\")\n",
    "    elif LLM_PROVIDER == \"bedrock\":\n",
    "        print(\"Amazon Bedrock をご利用の場合、AWS認証情報（Access Key, Secret Key, Region）が正しく設定されているか確認してください。\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説004</summary>\n",
    "\n",
    "このノートブックでは、様々なLLMプラットフォーム（OpenAI, Azure OpenAI, Google Vertex AI, Anthropic Claude, Amazon Bedrockなど）を簡単に切り替えて試せるように設計されています。\n",
    "ノートブックの冒頭にある `LLM_PROVIDER` 変数で使用したいLLMを選択し、対応するAPIキーや環境変数を設定するだけで、この問題を含む全てのLLM呼び出し箇所で選択したLLMが利用されます。\n",
    "\n",
    "ここでは、ノートブックの先頭で設定・初期化された共通の `llm` 変数を使用して、LLMに質問をしています。\n",
    "`llm.invoke()` という統一されたインターフェースで、どのLLMプロバイダーを利用しているかに関わらず、同じようにLLMを呼び出すことができます。\n",
    "これにより、特定のLLMサービスに依存しない、より汎用的なコードを作成するメリットを手軽に体験できます。\n",
    "\n",
    "もしエラーが発生した場合は、ノートブック冒頭の `LLM_PROVIDER` の設定、および選択したプロバイダーに応じたAPIキーや環境変数の設定が正しく行われているかを確認してください。\n",
    "各プロバイダー固有の設定項目（例えばVertex AIのProject ID、AzureのDeployment Nameなど）も見直してください。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題005: グラフの可視化とデバッグ\n",
    "\n",
    "構築したLangGraphグラフの構造を視覚的に確認し、デバッグに役立てる方法を学びましょう。ここでは、これまでに作成したグラフのいずれか（例：問題003の条件分岐グラフ）を可視化し、その構造を理解します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄005\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, ____]\n",
    "    number: int\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def check_number(state: GraphState):\n",
    "    try:\n",
    "        num = int(state[\"messages\"][-1].content)\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        return {\"number\": 0}\n",
    "\n",
    "def even_node(state: GraphState):\n",
    "    return {\"messages\": [____(content=f\"The number {state[\"number\"]} is even.\")]}\n",
    "\n",
    "def odd_node(state: GraphState):\n",
    "    return {\"messages\": [____(content=f\"The number {state[\"number\"]} is odd.\")]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def route_number(state: GraphState):\n",
    "    if state[\"number\"] % 2 == 0:\n",
    "        return \"even_node\"\n",
    "    else:\n",
    "        return \"odd_node\"\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(GraphState)\n",
    "\n",
    "workflow.____(\"check_number\", check_number)\n",
    "workflow.____(\"even_node\", even_node)\n",
    "workflow.____(\"odd_node\", odd_node)\n",
    "\n",
    "workflow.____(\"check_number\")\n",
    "\n",
    "workflow.____(\n",
    "    \"check_number\",\n",
    "    ____,\n",
    "    {\n",
    "        \"even_node\": \"even_node\",\n",
    "        \"odd_node\": \"odd_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.____(\"even_node\", ____)\n",
    "workflow.____(\"odd_node\", ____)\n",
    "\n",
    "app = workflow.____()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "# グラフを画像として表示\n",
    "# graphvizがインストールされている必要があります: pip install pygraphviz pydotplus graphviz\n",
    "# また、システムにGraphvizがインストールされている必要があります。\n",
    "# Windows: https://graphviz.org/download/\n",
    "# Mac: brew install graphviz\n",
    "# Linux: sudo apt-get install graphviz\n",
    "try:\n",
    "    ____(____(app.____().____()))\n",
    "    print(\"グラフが正常に可視化されました。\")\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n",
    "\n",
    "# --- グラフの実行と結果表示 (オプション) ---\n",
    "# 可視化したグラフが正しく動作するか確認するために、再度実行してみる\n",
    "print(\"\\n--- 偶数のテスト (可視化後の確認) ---\")\n",
    "inputs_even = {\"messages\": [____(content=\"10\")]}\n",
    "for s in app.____(inputs_even):\n",
    "    print(s)\n",
    "final_state_even = app.____(inputs_even)\n",
    "print(f\"Final State: {final_state_even}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答005</summary>\n",
    "\n",
    "``````python\n",
    "# 解答005\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    number: int\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def check_number(state: GraphState):\n",
    "    try:\n",
    "        num = int(state[\"messages\"][-1].content)\n",
    "        return {\"number\": num}\n",
    "    except ValueError:\n",
    "        return {\"number\": 0}\n",
    "\n",
    "def even_node(state: GraphState):\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is even.\")]}\n",
    "\n",
    "def odd_node(state: GraphState):\n",
    "    return {\"messages\": [AIMessage(content=f\"The number {state[\"number\"]} is odd.\")]}\n",
    "\n",
    "# --- 条件付きエッジのルーター関数 ---\n",
    "def route_number(state: GraphState):\n",
    "    if state[\"number\"] % 2 == 0:\n",
    "        return \"even_node\"\n",
    "    else:\n",
    "        return \"odd_node\"\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"check_number\", check_number)\n",
    "workflow.add_node(\"even_node\", even_node)\n",
    "workflow.add_node(\"odd_node\", odd_node)\n",
    "\n",
    "workflow.set_entry_point(\"check_number\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_number\",\n",
    "    route_number,\n",
    "    {\n",
    "        \"even_node\": \"even_node\",\n",
    "        \"odd_node\": \"odd_node\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"even_node\", END)\n",
    "workflow.add_edge(\"odd_node\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "# グラフを画像として表示\n",
    "# graphvizがインストールされている必要があります: pip install pygraphviz pydotplus graphviz\n",
    "# また、システムにGraphvizがインストールされている必要があります。\n",
    "# Windows: https://graphviz.org/download/\n",
    "# Mac: brew install graphviz\n",
    "# Linux: sudo apt-get install graphviz\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_png()))\n",
    "    print(\"グラフが正常に可視化されました。\")\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n",
    "\n",
    "# --- グラフの実行と結果表示 (オプション) ---\n",
    "# 可視化したグラフが正しく動作するか確認するために、再度実行してみる\n",
    "print(\"\\n--- 偶数のテスト (可視化後の確認) ---\")\n",
    "inputs_even = {\"messages\": [HumanMessage(content=\"10\")]}\n",
    "for s in app.stream(inputs_even):\n",
    "    print(s)\n",
    "final_state_even = app.invoke(inputs_even)\n",
    "print(f\"Final State: {final_state_even}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説005</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** `app.get_graph().draw_png()`を使用してLangGraphのグラフ構造を画像として可視化する方法を学びます。これにより、複雑なグラフのデバッグや理解が容易になります。\n",
    "*   **コード解説:**\n",
    "    *   この問題では、問題003で作成した条件分岐グラフを再利用しています。これは、可視化の有用性を示すのに適した例だからです。\n",
    "    *   `app.get_graph()`は、コンパイルされたグラフの内部表現を取得します。\n",
    "    *   `.draw_png()`メソッドは、そのグラフ構造をPNG画像としてバイト列で返します。この機能を利用するには、システムにGraphvizがインストールされている必要があります。また、Pythonの`pygraphviz`や`pydotplus`といったライブラリも必要になる場合があります。\n",
    "    *   `IPython.display.Image`と`display`を使うことで、Jupyter Notebook内で直接画像をレンダリングして表示できます。\n",
    "    *   `try-except`ブロックでGraphvizのインストール状況によるエラーをハンドリングし、ユーザーに適切なメッセージを表示するようにしています。グラフが複雑になるにつれて、この可視化機能はデバッグや設計の確認に不可欠となります。\n",
    "---\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
