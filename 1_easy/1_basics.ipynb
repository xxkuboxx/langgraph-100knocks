{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: グラフの基本要素\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "\n",
    "以下のセルを順番に実行して、演習に必要な環境をセットアップします。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMプロバイダーの選択\n",
    "\n",
    "このセルでは、使用するLLMプロバイダーを選択します。\n",
    "`LLM_PROVIDER` 変数に、利用したいプロバイダー名を設定してください。\n",
    "選択可能なプロバイダー: `\"openai\"`, `\"azure\"`, `\"google\"` (Vertex AI), `\"google_genai\"` (Gemini API), `\"anthropic\"`, `\"bedrock\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLMプロバイダーの選択 ===\n",
    "# 利用したいLLMプロバイダーを以下の変数で指定してください。\n",
    "# \"openai\", \"azure\", \"google\" (Vertex AI), \"google_genai\" (Gemini API), \"anthropic\", \"bedrock\" のいずれかを選択できます。\n",
    "LLM_PROVIDER = \"openai\"  # 例: OpenAI を利用する場合\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIキー/環境変数の設定\n",
    "\n",
    "以下のセルを実行する前に、選択したLLMプロバイダーに応じたAPIキーまたは環境変数を設定する必要があります。\n",
    "\n",
    "**手順:**\n",
    "1.  `.env.sample` ファイルをコピーして `.env` ファイルを作成します。\n",
    "2.  `.env` ファイルを開き、選択したLLMプロバイダーに対応するAPIキーや必要な情報を記述します。\n",
    "    *   **OpenAI:** `OPENAI_API_KEY`\n",
    "    *   **Azure OpenAI:** `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `OPENAI_API_VERSION`, `AZURE_OPENAI_DEPLOYMENT_NAME`\n",
    "    *   **Google (Vertex AI):** `GOOGLE_CLOUD_PROJECT_ID`, `GOOGLE_CLOUD_LOCATION` (Colab環境外で実行する場合、`GOOGLE_APPLICATION_CREDENTIALS` 環境変数の設定も必要になることがあります)\n",
    "    *   **Google (Gemini API):** `GOOGLE_API_KEY`\n",
    "    *   **Anthropic:** `ANTHROPIC_API_KEY`\n",
    "    *   **AWS Bedrock:** `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION_NAME` (IAMロールを使用する場合は、これらのキー設定は不要な場合がありますが、リージョン名は必須です)\n",
    "3.  ファイルを保存します。\n",
    "\n",
    "**Google Colab を使用している場合:**\n",
    "上記の `.env` ファイルを使用する代わりに、Colabのシークレットマネージャーに必要なキーを登録してください。\n",
    "例えば、OpenAIを使用する場合は `OPENAI_API_KEY` という名前でシークレットを登録します。\n",
    "Vertex AI を利用する場合は、Colab上での認証 (`google.colab.auth.authenticate_user()`) が実行されます。\n",
    "\n",
    "このセルは、設定された情報に基づいて環境変数をロードし、LLMクライアントを初期化します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === APIキー/環境変数の設定 ===\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルから環境変数を読み込む (存在する場合)\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# --- OpenAI ---\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not OPENAI_API_KEY and IS_COLAB:\n",
    "        OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise ValueError(\"OpenAI APIキーが設定されていません。環境変数 OPENAI_API_KEY を設定するか、Colab環境の場合はシークレットに OPENAI_API_KEY を設定してください。\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# --- Azure OpenAI ---\n",
    "elif LLM_PROVIDER == \"azure\":\n",
    "    AZURE_OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "    AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "    AZURE_OPENAI_DEPLOYMENT_NAME = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "    if IS_COLAB:\n",
    "        if not AZURE_OPENAI_API_KEY: AZURE_OPENAI_API_KEY = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "        if not AZURE_OPENAI_ENDPOINT: AZURE_OPENAI_ENDPOINT = userdata.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        if not OPENAI_API_VERSION: OPENAI_API_VERSION = userdata.get(\"OPENAI_API_VERSION\") # 例: \"2023-07-01-preview\"\n",
    "        if not AZURE_OPENAI_DEPLOYMENT_NAME: AZURE_OPENAI_DEPLOYMENT_NAME = userdata.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "    if not AZURE_OPENAI_API_KEY: raise ValueError(\"Azure OpenAI APIキー (AZURE_OPENAI_API_KEY) が設定されていません。\")\n",
    "    if not AZURE_OPENAI_ENDPOINT: raise ValueError(\"Azure OpenAI エンドポイント (AZURE_OPENAI_ENDPOINT) が設定されていません。\")\n",
    "    if not OPENAI_API_VERSION: OPENAI_API_VERSION = \"2023-07-01-preview\" # デフォルトを設定することも可能\n",
    "    if not AZURE_OPENAI_DEPLOYMENT_NAME: raise ValueError(\"Azure OpenAI デプロイメント名 (AZURE_OPENAI_DEPLOYMENT_NAME) が設定されていません。\")\n",
    "\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "    os.environ[\"OPENAI_API_VERSION\"] = OPENAI_API_VERSION\n",
    "\n",
    "# --- Google Cloud Vertex AI (Gemini) ---\n",
    "elif LLM_PROVIDER == \"google\":\n",
    "    PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT_ID\") # .env 用に修正\n",
    "    LOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\")\n",
    "\n",
    "    if IS_COLAB:\n",
    "        if not PROJECT_ID: PROJECT_ID = userdata.get(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
    "        if not LOCATION: LOCATION = userdata.get(\"GOOGLE_CLOUD_LOCATION\") # 例: \"us-central1\"\n",
    "        from google.colab import auth as google_auth\n",
    "        google_auth.authenticate_user() # Vertex AI を使う場合は Colab での認証を推奨\n",
    "    else: # Colab外の場合、.envから読み込んだ値で環境変数を設定\n",
    "        if PROJECT_ID: os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID # Vertex AI SDKが参照する標準的な環境変数名\n",
    "        if LOCATION: os.environ['GOOGLE_CLOUD_LOCATION'] = LOCATION\n",
    "\n",
    "    if not PROJECT_ID: raise ValueError(\"Google Cloud Project ID が設定されていません。環境変数 GOOGLE_CLOUD_PROJECT_ID を設定するか、Colab環境の場合はシークレットに GOOGLE_CLOUD_PROJECT_ID を設定してください。\")\n",
    "    if not LOCATION: LOCATION = \"us-central1\" # デフォルトロケーション\n",
    "\n",
    "# --- Google Gemini API (langchain-google-genai) ---\n",
    "elif LLM_PROVIDER == \"google_genai\":\n",
    "    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY and IS_COLAB:\n",
    "        GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY:\n",
    "        raise ValueError(\"Google APIキーが設定されていません。環境変数 GOOGLE_API_KEY を設定するか、Colab環境の場合はシークレットに GOOGLE_API_KEY を設定してください。\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# --- Anthropic (Claude) ---\n",
    "elif LLM_PROVIDER == \"anthropic\":\n",
    "    ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    if not ANTHROPIC_API_KEY and IS_COLAB:\n",
    "        ANTHROPIC_API_KEY = userdata.get(\"ANTHROPIC_API_KEY\")\n",
    "    if not ANTHROPIC_API_KEY:\n",
    "        raise ValueError(\"Anthropic APIキーが設定されていません。環境変数 ANTHROPIC_API_KEY を設定するか、Colab環境の場合はシークレットに ANTHROPIC_API_KEY を設定してください。\")\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "\n",
    "# --- Amazon Bedrock (Claude) ---\n",
    "elif LLM_PROVIDER == \"bedrock\":\n",
    "    AWS_ACCESS_KEY_ID = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "    AWS_SECRET_ACCESS_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    AWS_REGION_NAME = os.environ.get(\"AWS_REGION_NAME\")\n",
    "\n",
    "    if IS_COLAB: \n",
    "        if not AWS_ACCESS_KEY_ID: AWS_ACCESS_KEY_ID = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
    "        if not AWS_SECRET_ACCESS_KEY: AWS_SECRET_ACCESS_KEY = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "        if not AWS_REGION_NAME: AWS_REGION_NAME = userdata.get(\"AWS_REGION_NAME\")\n",
    "\n",
    "    if not AWS_REGION_NAME:\n",
    "         raise ValueError(\"AWSリージョン名 (AWS_REGION_NAME) が設定されていません。Bedrock利用にはリージョン指定が必要です。\")\n",
    "\n",
    "    # 環境変数に設定 (boto3がこれらを自動で読み込む)\n",
    "    if AWS_ACCESS_KEY_ID: os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "    if AWS_SECRET_ACCESS_KEY: os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "    os.environ[\"AWS_DEFAULT_REGION\"] = AWS_REGION_NAME # boto3が参照する標準的なリージョン環境変数名\n",
    "    os.environ[\"AWS_REGION\"] = AWS_REGION_NAME # いくつかのライブラリはこちらを参照することもある\n",
    "\n",
    "print(f\"APIキー/環境変数の設定完了 (プロバイダー: {LLM_PROVIDER})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMクライアントの初期化\n",
    "\n",
    "このセルは、上で選択・設定したLLMプロバイダーに基づいて、対応するLLMクライアントを初期化します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLMクライアントの動的初期化 ===\n",
    "llm = None\n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "elif LLM_PROVIDER == \"azure\":\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), # 環境変数から取得\n",
    "        openai_api_version=os.environ.get(\"OPENAI_API_VERSION\"), # 環境変数から取得\n",
    "        temperature=0,\n",
    "    )\n",
    "elif LLM_PROVIDER == \"google\":\n",
    "    from langchain_google_vertexai import ChatVertexAI\n",
    "    # PROJECT_ID, LOCATION は前のセルで環境変数に設定済みか、Colabの場合は直接利用\n",
    "    llm = ChatVertexAI(model_name=\"gemini-2.0-flash\", temperature=0, project=os.environ.get(\"GOOGLE_CLOUD_PROJECT\"), location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\"))\n",
    "elif LLM_PROVIDER == \"google_genai\":\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "elif LLM_PROVIDER == \"anthropic\":\n",
    "    from langchain_anthropic import ChatAnthropic\n",
    "    llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)\n",
    "elif LLM_PROVIDER == \"bedrock\":\n",
    "    from langchain_aws import ChatBedrock # langchain_community.chat_models から langchain_aws に変更の可能性あり\n",
    "    # AWS_REGION_NAME は前のセルで環境変数 AWS_DEFAULT_REGION に設定済み\n",
    "    llm = ChatBedrock( # BedrockChat ではなく ChatBedrock が一般的\n",
    "        model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        # region_name=os.environ.get(\"AWS_DEFAULT_REGION\"), # 通常、boto3が環境変数から自動で読み込む\n",
    "        model_kwargs={\"temperature\": 0},\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Unsupported LLM_PROVIDER: {LLM_PROVIDER}. \"\n",
    "        \"Please choose from 'openai', 'azure', 'google', 'google_genai', 'anthropic', or 'bedrock'.\"\n",
    "    )\n",
    "\n",
    "print(f\"LLM Provider: {LLM_PROVIDER}\")\n",
    "if llm:\n",
    "    print(f\"LLM Client Type: {type(llm)}\")\n",
    "    # モデル名取得の試行を汎用的に\n",
    "    model_attr = (\n",
    "                 getattr(llm, 'model', None) or\n",
    "                 getattr(llm, 'model_name', None) or\n",
    "                 getattr(llm, 'model_id', None) or\n",
    "                 (hasattr(llm, 'llm') and getattr(llm.llm, 'model', None)) # 一部のLLMクライアントのネスト構造に対応\n",
    "    )\n",
    "    if hasattr(llm, 'azure_deployment') and not model_attr: # Azure特有の属性\n",
    "        model_attr = llm.azure_deployment\n",
    "        \n",
    "    if model_attr:\n",
    "        print(f\"LLM Model: {model_attr}\")\n",
    "    else:\n",
    "        print(\"LLM Model: (Could not determine model name from client attributes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題001: 最小構成のLangGraphグラフの構築\n",
    "\n",
    "LangGraphの最も基本的な構成要素である`StateGraph`と`State`を理解し、シンプルなグラフを構築してみましょう。この問題では、入力された文字列をそのまま出力するだけの、単一のノードを持つグラフを作成します。\n",
    "\n",
    "*   **学習内容:** この問題では、`StateGraph`、`TypedDict`を用いた`State`の定義、`add_node`、`set_entry_point`、`add_edge`、`END`といったLangGraphの最も基本的なAPIを学びます。また、`Annotated`と`add_messages`を使ってメッセージ履歴を管理する方法も理解します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import ____, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(____):\n",
    "    messages: ____[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(____)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"simple_node\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答001</summary>\n",
    "\n",
    "``````python\n",
    "# 解答001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    # グラフの状態を保持する辞書\n",
    "    # ここでは、入力メッセージを保持する\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # 入力されたメッセージをそのまま返すノード\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説001</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `GraphState`は、グラフ全体で共有される状態を定義します。`TypedDict`を使うことで、状態のスキーマを明確にできます。`messages: Annotated[list, add_messages]`は、LangChainのメッセージ形式のリストを状態として持ち、新しいメッセージが追加されるたびに自動的にリストの末尾に追加されるように設定しています。\n",
    "    *   `simple_node`関数は、グラフのノードとして機能します。`state`引数として現在のグラフの状態を受け取り、新しい状態を辞書として返します。ここでは、入力された最後のメッセージをそのまま返しています。\n",
    "    *   `StateGraph(GraphState)`でグラフのインスタンスを作成し、`GraphState`で定義した状態スキーマを渡します。\n",
    "    *   `workflow.add_node(\"simple_node\", simple_node)`で、`simple_node`関数を`simple_node`という名前のノードとしてグラフに追加します。\n",
    "    *   `workflow.set_entry_point(\"simple_node\")`は、グラフの実行が開始される最初のノードを指定します。\n",
    "    *   `workflow.add_edge(\"simple_node\", END)`は、`simple_node`の実行が完了したらグラフを終了することを示します。`END`はLangGraphが提供する特別な終了ノードです。\n",
    "    *   `graph = workflow.compile()`で、定義したワークフローを実行可能なアプリケーションにコンパイルします。\n",
    "    *   `graph.stream(inputs)`は、グラフの実行過程をストリーミングで受け取ることができます。`graph.invoke(inputs)`は、グラフの実行が完了した最終状態を返します。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題002: グラフの可視化\n",
    "\n",
    "問題001で構築した最小構成のグラフの構造を、視覚的に確認する方法を学びましょう。\n",
    "\n",
    "*   **学習内容:** `graph.get_graph().draw_png()` を使用して、コンパイル済みのLangGraphグラフ構造をPNG画像として描画し、Jupyter Notebook上に表示する方法を学びます。これにより、グラフのノードとエッジの接続関係を直感的に理解できるようになります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄002\n",
    "\n",
    "# 問題001のコードを再掲（このセルでグラフを定義・コンパイルします）\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(____):\n",
    "    messages: ____[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # このノードは状態を更新せず、最後のメッセージをログに出力するだけ\n",
    "    # LangGraphでは、ノードがNoneまたは空の辞書を返すと、状態は更新されない\n",
    "    return\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(GraphState)\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "workflow.set_entry_point(____)\n",
    "workflow.add_edge(\"simple_node\", ____)\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    png_data = graph.get_graph().draw_png()\n",
    "    display(Image(png_data))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの動作確認 ---\n",
    "# 可視化したグラフが問題001と同様に動作することを確認します。\n",
    "try:\n",
    "    inputs = {\"messages\": [HumanMessage(content=\"Hello, this is a test.\")]}\n",
    "    final_state = graph.invoke(inputs)\n",
    "    print(\"\\nグラフの実行が完了しました。\")\n",
    "    print(f\"最終的なmessagesの状態: {final_state['messages']}\")\n",
    "except NameError:\n",
    "    print(\"グラフが定義されていません。前のセルを先に実行してください。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答002</summary>\n",
    "\n",
    "``````python\n",
    "# 解答002\n",
    "\n",
    "# 問題001のコードを再掲（このセルでグラフを定義・コンパイルします）\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # このノードは状態を更新せず、最後のメッセージをログに出力するだけ\n",
    "    # LangGraphでは、ノードがNoneまたは空の辞書を返すと、状態は更新されない\n",
    "    return\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    png_data = graph.get_graph().draw_png()\n",
    "    display(Image(png_data))\n",
    "    print(\"グラフが正常に可視化されました。\")\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n",
    "\n",
    "# --- グラフの動作確認 ---\n",
    "# 可視化したグラフが問題001と同様に動作することを確認します。\n",
    "try:\n",
    "    inputs = {\"messages\": [HumanMessage(content=\"Hello, this is a test.\")]}\n",
    "    final_state = graph.invoke(inputs)\n",
    "    print(\"\\nグラフの実行が完了しました。\")\n",
    "    print(f\"最終的なmessagesの状態: {final_state['messages']}\")\n",
    "except NameError:\n",
    "    print(\"グラフが定義されていません。前のセルを先に実行してください。\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説002</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   この問題では、まず問題001で作成したグラフ定義のコードを再利用して、`graph`オブジェクトを準備します。\n",
    "    *   グラフを可視化するための中心的なメソッドが `graph.get_graph().draw_png()` です。\n",
    "        *   `graph.get_graph()`: コンパイル済みの`graph`オブジェクトから、可視化や解析が可能な内部グラフ表現を取得します。\n",
    "        *   `.draw_png()`: 取得したグラフ表現をPNG形式の画像データ（バイト列）として描画します。\n",
    "    *   `IPython.display.Image` は、画像データをJupyter NotebookなどのIPython環境で表示可能なオブジェクトに変換します。\n",
    "    *   `IPython.display.display()` 関数を使って、`Image`オブジェクトをセルに表示します。\n",
    "    *   **重要:** `.draw_png()` メソッドを使用するには、**Graphviz**というグラフ可視化ソフトウェアがシステムにインストールされている必要があります。また、Pythonライブラリの`pygraphviz`も必要です（これらは準備セクションでインストール済みです）。もし`ExecutableNotFound`のようなエラーが出る場合は、Graphviz本体がOSに正しくインストールされ、パスが通っているかを確認してください。\n",
    "\n",
    "*   **なぜ可視化が重要か:**\n",
    "    *   グラフが単純なうちはコードを読むだけで構造を理解できますが、ノードやエッジが増え、特に条件分岐やループが絡んでくると、全体の流れを把握するのが難しくなります。\n",
    "    *   グラフを可視化することで、設計した通りの構造になっているかを一目で確認でき、意図しない接続やループのデバッグに非常に役立ちます。\n",
    "\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題003: 複数のノードを持つシーケンシャルグラフの構築\n",
    "\n",
    "前の問題で学んだ基本的なグラフ構築に加えて、複数のノードを直列に接続し、データがノード間をどのように流れるかを理解しましょう。ここでは、入力された文字列を加工する2つのノード（例：大文字化、逆順化）を持つグラフを作成します。\n",
    "\n",
    "*   **学習内容:** 複数のノードを`add_edge`で直列に接続する方法と、ノード間で状態がどのように引き継がれるかを学びます。`HumanMessage`と`AIMessage`を使って、メッセージの送信元を明示する方法も理解します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄003\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, ____\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(____):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    return {\"messages\": [AIMessage(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    return {\"messages\": [AIMessage(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"uppercase\", uppercase_node)\n",
    "workflow.add_node(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(____)\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.add_edge(____, \"reverse\")\n",
    "workflow.add_edge(\"reverse\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello LangGraph\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答003</summary>\n",
    "\n",
    "``````python\n",
    "# 解答003\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    # 最新のメッセージを大文字に変換するノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    return {\"messages\": [AIMessage(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    # 最新のメッセージを逆順にするノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    return {\"messages\": [AIMessage(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"uppercase\", uppercase_node)\n",
    "workflow.add_node(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"uppercase\")\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.add_edge(\"uppercase\", \"reverse\")\n",
    "workflow.add_edge(\"reverse\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello LangGraph\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説003</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `uppercase_node`と`reverse_node`は、それぞれ入力メッセージを大文字化、逆順化する処理を行います。重要なのは、各ノードが新しい`AIMessage`を作成して状態に返す点です。これにより、次のノードは前のノードの処理結果を`state[\"messages\"][-1]`で取得できます。\n",
    "    *   `workflow.add_edge(\"uppercase\", \"reverse\")`は、`uppercase`ノードの実行が完了したら、次に`reverse`ノードを実行するように指示します。このようにして、処理の流れを定義します。\n",
    "    *   入力メッセージを`HumanMessage`として渡すことで、ユーザーからの入力であることを明示しています。ノードからの出力は`AIMessage`として返され、メッセージ履歴にAIの応答として記録されます。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題004: グラフ内でのLLMの利用（シンプルなチャットボット）\n",
    "\n",
    "LangGraphのノード内で大規模言語モデル（LLM）を呼び出す方法を学び、シンプルなチャットボットを構築しましょう。ここでは、ユーザーからの入力に対してLLMが応答を生成し、その応答を返すグラフを作成します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄004\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import ____, AIMessage\n",
    "import os\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "# (from langchain_openai import ChatOpenAI や llm = ChatOpenAI(...) といった行はここには不要)\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(____):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def llm_node(state: GraphState):\n",
    "    # LLMを呼び出し、応答を生成するノード\n",
    "    # ノートブック冒頭で初期化された共通の `llm` 変数を使用します。\n",
    "    response = ____.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]} # responseはAIMessageオブジェクトを期待 (ここは歯抜けにしない)\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"llm_responder\", llm_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.____(\"llm_responder\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"llm_responder\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- チャットボットのテスト ---\")\n",
    "# 最初のメッセージはHumanMessageであると想定\n",
    "inputs = {\"messages\": [HumanMessage(content=\"こんにちは、あなたの名前は何ですか？\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- 別の質問 ---\")\n",
    "inputs2 = {\"messages\": [HumanMessage(content=\"今日の天気は？\")]}\n",
    "\n",
    "final_state2 = graph.invoke(inputs2)\n",
    "print(f\"最終的な応答: {final_state2['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答004</summary>\n",
    "\n",
    "``````python\n",
    "# 解答004\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import os # osはAPIキー設定のコメントアウト部分で使われているので残しても良いが、直接は不要になる\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def llm_node(state: GraphState):\n",
    "    # LLMを呼び出し、応答を生成するノード\n",
    "    # ノートブック冒頭で初期化された共通の `llm` 変数を使用します。\n",
    "    response = llm.invoke(state[\"messages\"]) # 共通llmを使用\n",
    "    return {\"messages\": [response]} # responseはAIMessageオブジェクトを期待\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"llm_responder\", llm_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"llm_responder\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"llm_responder\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- チャットボットのテスト ---\")\n",
    "# 最初のメッセージはHumanMessageであると想定\n",
    "inputs = {\"messages\": [HumanMessage(content=\"こんにちは、あなたの名前は何ですか？\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- 別の質問 ---\")\n",
    "inputs2 = {\"messages\": [HumanMessage(content=\"今日の天気は？\")]}\n",
    "\n",
    "final_state2 = graph.invoke(inputs2)\n",
    "print(f\"最終的な応答: {final_state2['messages'][-1].content}\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説004</summary>\n",
    "\n",
    "このノートブックでは、様々なLLMプラットフォーム（OpenAI, Azure OpenAI, Google Cloud Vertex AI, Google Gemini (Gemini API), Anthropic Claude, Amazon Bedrockなど）を簡単に切り替えて試せるように設計されています。\n",
    "ノートブックの冒頭にある `LLM_PROVIDER` 変数で使用したいLLMを選択し、対応するAPIキーや環境変数を設定するだけで、この問題を含む全てのLLM呼び出し箇所で選択したLLMが利用されます。\n",
    "選択した `LLM_PROVIDER` に応じて、必要なAPIキーが設定されているか（環境変数またはGoogle Colabのシークレット経由）、ノートブック起動時にチェックされます。\n",
    "\n",
    "ここでは、ノートブックの先頭で設定・初期化された共通の `llm` 変数を使用して、LLMに質問をしています。\n",
    "`llm.invoke()` という統一されたインターフェースで、どのLLMプロバイダーを利用しているかに関わらず、同じようにLLMを呼び出すことができます。\n",
    "これにより、特定のLLMサービスに依存しない、より汎用的なコードを作成するメリットを手軽に体験できます。\n",
    "\n",
    "もしエラーが発生した場合は、ノートブック冒頭の `LLM_PROVIDER` の設定、および選択したプロバイダーに応じたAPIキーや環境変数の設定（例: `OPENAI_API_KEY`, `GOOGLE_API_KEY`, `AZURE_OPENAI_ENDPOINT`など）が正しく行われているかを確認してください。\n",
    "各プロバイダー固有の設定項目（例えばVertex AIのProject ID、AzureのDeployment Name、Bedrockのリージョンなど）も見直してください。\n",
    "プロバイダーによっては、`pip install` コマンドで対応するライブラリ (例: `langchain-google-genai`) がインストールされているかも確認点です。\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題005: 状態の更新 - 特定キーの値を上書きする\n",
    "\n",
    "`add_messages` によるメッセージ履歴の追加だけでなく、グラフの状態(`State`)内の特定のキーの値を直接更新する方法を学びましょう。ここでは、カウンター値を保持する状態キーを定義し、ノードでその値をインクリメントするグラフを作成します。\n",
    "\n",
    "*   **学習内容:** `TypedDict`で定義する状態クラスに、`messages`以外のカスタムキー（ここでは`counter: int`）を追加し、ノード関数内でその値を直接読み書きする方法を学びます。これにより、メッセージ履歴だけでなく、数値や文字列、ブール値など、より多様なデータをグラフ全体で管理できるようになります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄005\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, ____\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class CounterState(____):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    counter: ____ \n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def increment_counter(state: CounterState):\n",
    "    # counterの値を1増やすノード\n",
    "    current_count = state.get(\"counter\", 0) # stateからcounterの値を取得、なければ0\n",
    "    new_count = current_count + 1\n",
    "    return {____: new_count, \"messages\": [HumanMessage(content=f\"Counter incremented to {new_count}\")]}\n",
    "\n",
    "def display_count(state: CounterState):\n",
    "    # counterの最終値を表示するノード (実際にはmessagesに追加されたもので確認)\n",
    "    # このノードは状態を更新しないが、メッセージを追加しても良い\n",
    "    return {\"messages\": [HumanMessage(content=f\"Final count: {state['counter']}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(CounterState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"increment\", increment_counter)\n",
    "workflow.add_node(\"display\", display_count)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"increment\")\n",
    "\n",
    "# エッジの追加\n",
    "workflow.add_edge(\"increment\", \"display\")\n",
    "workflow.add_edge(\"display\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- カウンターテスト (初期値0から) ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Start counting\")], \"counter\": 0} # 初期カウンター値を設定\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- カウンターテスト (初期値5から) ---\")\n",
    "inputs_2 = {\"messages\": [HumanMessage(content=\"Start counting from 5\")], \"counter\": 5} # 初期カウンター値を設定\n",
    "\n",
    "final_state_2 = graph.invoke(inputs_2)\n",
    "print(f\"最終的な応答: {final_state_2['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答005</summary>\n",
    "\n",
    "``````python\n",
    "# 解答005\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class CounterState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    counter: int # 新しくカウンター用の状態キーを定義\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def increment_counter(state: CounterState):\n",
    "    # counterの値を1増やすノード\n",
    "    current_count = state.get(\"counter\", 0) # stateからcounterの値を取得、なければ0\n",
    "    new_count = current_count + 1\n",
    "    return {\"counter\": new_count, \"messages\": [HumanMessage(content=f\"Counter incremented to {new_count}\")]}\n",
    "\n",
    "def display_count(state: CounterState):\n",
    "    # counterの最終値を表示するノード (実際にはmessagesに追加されたもので確認)\n",
    "    # このノードは状態を更新しないが、メッセージを追加しても良い\n",
    "    return {\"messages\": [HumanMessage(content=f\"Final count: {state['counter']}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(CounterState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"increment\", increment_counter)\n",
    "workflow.add_node(\"display\", display_count)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"increment\")\n",
    "\n",
    "# エッジの追加\n",
    "workflow.add_edge(\"increment\", \"display\")\n",
    "workflow.add_edge(\"display\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- カウンターテスト (初期値0から) ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Start counting\")], \"counter\": 0} # 初期カウンター値を設定\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- カウンターテスト (初期値5から) ---\")\n",
    "inputs_2 = {\"messages\": [HumanMessage(content=\"Start counting from 5\")], \"counter\": 5} # 初期カウンター値を設定\n",
    "\n",
    "final_state_2 = graph.invoke(inputs_2)\n",
    "print(f\"最終的な応答: {final_state_2['messages'][-1].content}\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説005</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `CounterState`に`counter: int`を追加しました。これにより、グラフの状態はメッセージリストと整数型のカウンターを持つことになります。\n",
    "    *   `increment_counter`ノードでは、`state.get(\"counter\", 0)`を使って現在のカウンター値を取得しています。`.get()`メソッドを使うことで、キーが存在しない場合のデフォルト値を指定できます（ここでは初回実行時を想定して0）。その後、値をインクリメントし、更新後の値を`{\"counter\": new_count}`という辞書形式で返しています。LangGraphは、ノードが返す辞書のキーに基づいて対応する状態を更新します。\n",
    "    *   `messages`キーも同時に返すことで、状態更新のログや情報をメッセージ履歴に残すことができます。\n",
    "    *   グラフ実行時 (`graph.invoke`や`graph.stream`) に、`inputs`辞書に`\"counter\": 0`（または任意の値）を含めることで、`counter`キーの初期値を設定できます。\n",
    "    *   このように、ノードは状態の一部または全部を更新する辞書を返すことで、グラフの状態を変化させます。`add_messages`はメッセージリストの更新に特化した便利な方法ですが、他のキーは直接値を指定して更新します。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題006: 状態の更新 - 複数のキーを一度に更新する\n",
    "\n",
    "一つのノードから、状態(`State`)の複数のキーを同時に更新する方法を学びましょう。ここでは、ユーザーからのメッセージ内容に応じて、応答メッセージと共に「応答タイプ」という別の状態キーも更新するグラフを作成します。\n",
    "\n",
    "*   **学習内容:** 一つのノード関数から返す辞書に複数のキーと値のペアを含めることで、グラフの状態(`State`)の複数の属性を一度に更新する方法を学びます。また、`typing.Literal`を使って、状態キーが取りうる値を制限する方法も示します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄006\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, ____\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, ____\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "ResponseType = Literal[\"greeting\", \"question\", \"other\", \"unknown\"]\n",
    "\n",
    "class MultiUpdateState(____):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    response_type: ____\n",
    "    last_user_message: str # 最後に入力されたユーザーメッセージ\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def process_input(state: MultiUpdateState):\n",
    "    user_message = state[\"messages\"][-1].content.lower()\n",
    "    response_text = \"\"\n",
    "    resp_type: ResponseType = \"unknown\"\n",
    "\n",
    "    if \"こんにちは\" in user_message or \"こんばんは\" in user_message:\n",
    "        response_text = \"こんにちは！何かお手伝いできますか？\"\n",
    "        resp_type = \"greeting\" \n",
    "    elif \"?\" in user_message or \"教えて\" in user_message:\n",
    "        response_text = \"ご質問ありがとうございます。それについては現在調べています。\"\n",
    "        resp_type = \"question\" \n",
    "    else:\n",
    "        response_text = \"メッセージありがとうございます。\"\n",
    "        resp_type = \"other\" \n",
    "    \n",
    "    # 複数のキーを同時に更新して返す\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response_text)],\n",
    "        \"response_type\": resp_type,\n",
    "        ____: user_message\n",
    "    }\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(MultiUpdateState)\n",
    "\n",
    "workflow.add_node(\"processor\", process_input)\n",
    "workflow.set_entry_point(\"processor\")\n",
    "workflow.add_edge(\"processor\", ____)\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "test_inputs = [\n",
    "    {\"messages\": [HumanMessage(content=\"こんにちは\")]},\n",
    "    {\"messages\": [HumanMessage(content=\"LangGraphについて教えてください\")]},\n",
    "    {\"messages\": [HumanMessage(content=\"今日の天気は晴れですね\")]}\n",
    "]\n",
    "\n",
    "for i, inputs in enumerate(test_inputs):\n",
    "    print(f\"\\n--- テスト実行 {i+1} ---\")\n",
    "\n",
    "    final_state = graph.invoke(inputs, {\"recursion_limit\": 3})\n",
    "    print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "    assert \"response_type\" in final_state\n",
    "    assert \"last_user_message\" in final_state\n",
    "    print(f\"Response Type: {final_state['response_type']}\")\n",
    "    print(f\"Last User Message: {final_state['last_user_message']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答006</summary>\n",
    "\n",
    "``````python\n",
    "# 解答006\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "ResponseType = Literal[\"greeting\", \"question\", \"other\", \"unknown\"]\n",
    "\n",
    "class MultiUpdateState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    response_type: ResponseType # 応答の種類を保持するキー\n",
    "    last_user_message: str # 最後に入力されたユーザーメッセージ\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def process_input(state: MultiUpdateState):\n",
    "    user_message = state[\"messages\"][-1].content.lower()\n",
    "    response_text = \"\"\n",
    "    resp_type: ResponseType = \"unknown\"\n",
    "\n",
    "    if \"こんにちは\" in user_message or \"こんばんは\" in user_message:\n",
    "        response_text = \"こんにちは！何かお手伝いできますか？\"\n",
    "        resp_type = \"greeting\"\n",
    "    elif \"?\" in user_message or \"教えて\" in user_message:\n",
    "        response_text = \"ご質問ありがとうございます。それについては現在調べています。\"\n",
    "        resp_type = \"question\"\n",
    "    else:\n",
    "        response_text = \"メッセージありがとうございます。\"\n",
    "        resp_type = \"other\"\n",
    "    \n",
    "    # 複数のキーを同時に更新して返す\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response_text)],\n",
    "        \"response_type\": resp_type,\n",
    "        \"last_user_message\": user_message # 元のユーザーメッセージを保存\n",
    "    }\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(MultiUpdateState)\n",
    "\n",
    "workflow.add_node(\"processor\", process_input)\n",
    "workflow.set_entry_point(\"processor\")\n",
    "workflow.add_edge(\"processor\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "test_inputs = [\n",
    "    {\"messages\": [HumanMessage(content=\"こんにちは\")]},\n",
    "    {\"messages\": [HumanMessage(content=\"LangGraphについて教えてください\")]},\n",
    "    {\"messages\": [HumanMessage(content=\"今日の天気は晴れですね\")]}\n",
    "]\n",
    "\n",
    "for i, inputs in enumerate(test_inputs):\n",
    "    print(f\"\\n--- テスト実行 {i+1} ---\")\n",
    "    # 初期状態としてresponse_typeやlast_user_messageを渡すことも可能だが、\n",
    "    # この問題ではノード内でこれらが設定されることを確認する\n",
    "    initial_state = inputs.copy()\n",
    "    # 必要であれば、初期値を設定\n",
    "    # initial_state.setdefault(\"response_type\", \"unknown\") \n",
    "    # initial_state.setdefault(\"last_user_message\", \"\")\n",
    "\n",
    "    final_state = graph.invoke(initial_state, {\"recursion_limit\": 3})\n",
    "    print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "    assert \"response_type\" in final_state\n",
    "    assert \"last_user_message\" in final_state\n",
    "    print(f\"Response Type: {final_state['response_type']}\")\n",
    "    print(f\"Last User Message: {final_state['last_user_message']}\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説006</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `MultiUpdateState`に、`response_type: ResponseType` と `last_user_message: str` という2つの新しいキーを追加しました。`ResponseType`は`Literal[\"greeting\", \"question\", \"other\", \"unknown\"]`で定義され、`response_type`キーがこれらの文字列のうちのいずれかの値を取ることを示します（型ヒントであり、実行時の厳密な強制ではありませんが、開発時の可読性や静的解析に役立ちます）。\n",
    "    *   `process_input`ノードは、ユーザーのメッセージ内容に基づいて応答メッセージを生成し、それと同時に`response_type`（挨拶、質問、その他など）と`last_user_message`（処理対象となった元のユーザーメッセージ）も決定します。\n",
    "    *   ノードが返す辞書は `{\"messages\": ..., \"response_type\": ..., \"last_user_message\": ...}` のようになります。LangGraphは、この辞書に含まれる各キーに対応する状態を更新します。\n",
    "    *   実行時には、`messages`キーだけでなく、`response_type`と`last_user_message`も最終状態に含まれていることを確認できます。\n",
    "    *   このように、ノードはグラフの状態を柔軟に更新する役割を担います。返す辞書に含めるキーと値によって、どの状態属性をどのように変更するかを制御できます。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題007: `END` 以外の終了ノードの指定（概念理解）\n",
    "\n",
    "LangGraphでは、グラフの終点は通常、特別な `END` ノードに接続することで示されます。しかし、概念的には、あるノードが処理の最終ステップであり、それ以上後続のノードが存在しない場合、そのノードが事実上の「終了ノード」として機能すると考えることもできます。この問題では、特定のノードを実行した後、明示的に `END` に接続せず、グラフがそこで停止することを確認します。ただし、LangGraphのベストプラクティスとしては、可能な限り `END` を使用することが推奨されます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄007\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, ____\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class FinalNodeState(____):\n",
    "    messages: ____[list, add_messages]\n",
    "    status: str\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def start_process(state: FinalNodeState):\n",
    "    return {\"status\": \"Processing\", \"messages\": [AIMessage(content=\"Process initiated.\")]}\n",
    "\n",
    "def final_processing_node(state: FinalNodeState):\n",
    "    # このノードが処理の最後とする\n",
    "    final_message = \"Process completed at final_processing_node.\"\n",
    "    return {\"status\": \"Completed\", \"messages\": [AIMessage(content=final_message)]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(FinalNodeState)\n",
    "\n",
    "workflow.add_node(\"start\", start_process)\n",
    "workflow.add_node(\"final_step\", final_processing_node)\n",
    "\n",
    "workflow.set_entry_point(\"start\")\n",
    "\n",
    "# startノードからfinal_stepノードへのエッジ\n",
    "workflow.add_edge(\"start\", ____)\n",
    "\n",
    "# final_stepノードからENDへのエッジを意図的に作成しない\n",
    "# workflow.____(\"final_step\", END) # ← これをコメントアウトまたは削除\n",
    "\n",
    "# グラフのコンパイル\n",
    "# check_interruptions=True をつけると、ENDに到達しない場合にエラーになるため、\n",
    "# この例では明示的にENDに繋がないことを示すために compile() の引数なし、\n",
    "# または check_interruptions=False (デフォルト) を利用します。\n",
    "# Langfuseなどのトレーシングツールと連携する場合、ENDに到達しないとトレースが終了しないことがあるため注意。\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- 最終ノードテスト ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Begin process\")], \"status\": \"Initial\"}\n",
    "final_state_from_stream = None\n",
    "\n",
    "print(\"Streaming execution:\")\n",
    "for chunk in graph.stream(inputs, {\"recursion_limit\": 5}):\n",
    "    print(f\"  Stream chunk: {chunk}\")\n",
    "    final_state_from_stream = chunk # Capture the last chunk which contains the state of the last executed node\n",
    "\n",
    "print(f\"Final State from stream: {final_state_from_stream}\")\n",
    "\n",
    "# invokeの挙動確認\n",
    "invoked_state = None\n",
    "try:\n",
    "    invoked_state = graph.invoke(inputs, {\"recursion_limit\": 5})\n",
    "    print(f\"最終的な応答 (invoke): {invoked_state['messages'][-1].content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Invoke call resulted in an error or unexpected behavior: {e}\")\n",
    "    print(\"This might be expected if the graph doesn't explicitly reach END.\")\n",
    "\n",
    "assert final_state_from_stream is not None, \"Final state was not captured from stream\"\n",
    "final_node_key = list(final_state_from_stream.keys())[0] # Get the key of the last node's state\n",
    "assert final_state_from_stream[final_node_key][\"status\"] == \"Completed\"\n",
    "assert \"Process completed at final_processing_node.\" in final_state_from_stream[final_node_key][\"messages\"][-1].content\n",
    "print(\"Assertion for final_state_from_stream passed.\")\n",
    "\n",
    "if invoked_state:\n",
    "    print(f\"Invoked state status: {invoked_state.get('status')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答007</summary>\n",
    "\n",
    "``````python\n",
    "# 解答007\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class FinalNodeState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    status: str\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def start_process(state: FinalNodeState):\n",
    "    return {\"status\": \"Processing\", \"messages\": [AIMessage(content=\"Process initiated.\")]}\n",
    "\n",
    "def final_processing_node(state: FinalNodeState):\n",
    "    # このノードが処理の最後とする\n",
    "    final_message = \"Process completed at final_processing_node.\"\n",
    "    return {\"status\": \"Completed\", \"messages\": [AIMessage(content=final_message)]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(FinalNodeState)\n",
    "\n",
    "workflow.add_node(\"start\", start_process)\n",
    "workflow.add_node(\"final_step\", final_processing_node)\n",
    "\n",
    "workflow.set_entry_point(\"start\")\n",
    "\n",
    "# startノードからfinal_stepノードへのエッジ\n",
    "workflow.add_edge(\"start\", \"final_step\")\n",
    "\n",
    "# final_stepノードからENDへのエッジを意図的に作成しない\n",
    "# workflow.add_edge(\"final_step\", END) # ← コメントアウトまたは削除\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- 最終ノードテスト ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Begin process\")], \"status\": \"Initial\"}\n",
    "final_state_from_stream = None\n",
    "\n",
    "print(\"Streaming execution:\")\n",
    "for chunk in graph.stream(inputs, {\"recursion_limit\": 5}):\n",
    "    print(f\"  Stream chunk: {chunk}\")\n",
    "    final_state_from_stream = chunk\n",
    "\n",
    "print(f\"Final State from stream: {final_state_from_stream}\")\n",
    "\n",
    "invoked_state = None\n",
    "try:\n",
    "    invoked_state = graph.invoke(inputs, {\"recursion_limit\": 5})\n",
    "    print(f\"最終的な応答 (invoke): {invoked_state['messages'][-1].content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Invoke call resulted in an error or unexpected behavior: {e}\")\n",
    "    print(\"This might be expected if the graph doesn't explicitly reach END.\")\n",
    "\n",
    "assert final_state_from_stream is not None, \"Final state was not captured from stream\"\n",
    "final_node_key = list(final_state_from_stream.keys())[0]\n",
    "assert final_state_from_stream[final_node_key][\"status\"] == \"Completed\"\n",
    "assert \"Process completed at final_processing_node.\" in final_state_from_stream[final_node_key][\"messages\"][-1].content\n",
    "print(\"Assertion for final_state_from_stream passed.\")\n",
    "\n",
    "if invoked_state:\n",
    "    print(f\"Invoked state status: {invoked_state.get('status')}\")\n",
    "\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説007</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "*   **学習内容:** グラフの終点として必ずしも `END` を明示的に指定する必要はなく、あるノードから先に遷移するエッジがなければ、そのノードの処理が終わった時点でグラフの実行が停止し、その時点での状態が最終状態となることを理解します。ただし、これはLangGraphの挙動の一つであり、デバッグや可視化、他のツールとの連携（例: Langfuse）を考慮すると、可能な限りグラフの終点を `END` に接続することが推奨されます。\n",
    "*   **コード解説:**\n",
    "    *   `final_processing_node`を作成し、このノードから `END` へのエッジ（`workflow.add_edge(\"final_step\", END)`）を定義していません。\n",
    "    *   `graph.stream()` を使ってグラフを実行すると、`final_processing_node` が実行された後、それ以上進むべきノードがないため、処理が停止します。`stream()` の最後の出力（この場合は `final_processing_node` の出力）が、その実行における最終的な状態を示します。\n",
    "    *   `graph.invoke()` の場合、グラフが明示的に `END` に到達しないと、バージョンや設定によってはエラーが発生したり、予期しない挙動をしたりする可能性があります。一般的に `invoke()` はグラフが `END` に到達し、完全な最終状態が確定することを期待します。この問題では、主に `stream()` での挙動を確認し、`invoke()` は参考として示しています。\n",
    "    *   可視化すると、`final_step` ノードから `END` (または他のノード) への矢印がないことが確認できます。\n",
    "*   **重要な注意点:**\n",
    "    *   **`END` の使用推奨:** LangGraphでは、グラフの論理的な終了点を明確にするために `END` を使用することが強く推奨されます。これにより、グラフの構造が理解しやすくなり、デバッグも容易になります。また、LangSmith/Langfuseのようなトレースツールは、`END` への到達をもって一連の処理の完了とみなすことが多いため、連携時にも重要です。\n",
    "    *   **`compile(check_interruptions=True)`:** グラフをコンパイルする際に `check_interruptions=True` を指定すると、中断（Interrupt）が発生しない限り、グラフが必ず `END` に到達することを強制できます。`END` に到達しないパスがある場合、コンパイル時または実行時にエラーが発生します。\n",
    "    *   この問題は、`END` を使わない場合の挙動を理解するためのものであり、実際の開発では `END` を適切に配置する設計を心がけてください。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題008: LLMノードと非LLMノードの連携強化\n",
    "\n",
    "LLM（大規模言語モデル）を組み込んだノードと、LLM以外の処理を行うノード（例: 文字列操作、データ抽出など）を連携させる方法を学びましょう。ここでは、LLMに質問を投げて得られた応答（文字列）から、特定の情報を抽出・加工して状態を更新する、より実践的なグラフを作成します。\n",
    "\n",
    "*   **学習内容:** LLMを呼び出すノードと、その出力を処理する非LLMノードを組み合わせることで、より高度な情報処理パイプラインを構築する方法を学びます。具体的には、LLMの自然言語応答から正規表現などを用いて構造化された情報を抽出し、グラフの状態を更新します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄008\n",
    "from typing import TypedDict, Annotated\n",
    "import re # 正規表現モジュールをインポート\n",
    "from langgraph.graph import StateGraph, ____\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import ____, AIMessage\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class ExtractionState(____):\n",
    "    messages: ____[list, add_messages]\n",
    "    user_question: str # ユーザーの元の質問\n",
    "    llm_response_text: str # LLMの生の応答テキスト\n",
    "    extracted_info: str | None # LLMの応答から抽出された情報\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_user_question(state: ExtractionState):\n",
    "    # ユーザーの質問を状態に保存\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    return {\"user_question\": last_message_content}\n",
    "\n",
    "def llm_responder_node(state: ExtractionState):\n",
    "    # LLMに質問を投げるノード\n",
    "    question = state[\"user_question\"]\n",
    "    # LLMに渡すメッセージは、過去の履歴全体でも、最新の質問だけでも良い\n",
    "    # ここでは簡単のため、最新の質問のみをHumanMessageとして渡す\n",
    "    response = llm.invoke([HumanMessage(content=question)])\n",
    "    response_content = response.content\n",
    "    return {\"messages\": [response], \"llm_response_text\": response_content}\n",
    "\n",
    "def data_extractor_node(state: ExtractionState):\n",
    "    # LLMの応答から情報を抽出するノード\n",
    "    raw_response = state[\"llm_response_text\"]\n",
    "    # 例: LLMが「日本の首都は東京です。」と答えたら「東京」を抽出\n",
    "    # ここでは簡単な正規表現で「XXはYYです」のYY部分を抽出試行\n",
    "    extracted = None\n",
    "    match = re.search(r\"(?:は|is)\\s*([^。.]+)[.。]?\", raw_response) # 簡易的な抽出\n",
    "    if match:\n",
    "        extracted = match.group(1).strip()\n",
    "    \n",
    "    return {____: extracted, \"messages\": [AIMessage(content=f\"Extracted: {extracted}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(ExtractionState)\n",
    "\n",
    "workflow.add_node(\"capture_question\", get_user_question)\n",
    "workflow.add_node(\"ask_llm\", llm_responder_node)\n",
    "workflow.add_node(\"extract_data\", data_extractor_node)\n",
    "\n",
    "workflow.set_entry_point(\"capture_question\")\n",
    "\n",
    "workflow.add_edge(\"capture_question\", \"ask_llm\")\n",
    "workflow.add_edge(\"ask_llm\", ____)\n",
    "workflow.add_edge(\"extract_data\", ____)\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "questions = [\n",
    "    \"日本の首都は何ですか？\",\n",
    "    \"フランスの有名な画家の名前を一人教えてください。\", # LLMの回答次第で抽出成功/失敗が変わる\n",
    "    \"1+1は何？\", # LLMが「2です」と答えれば抽出できるかも\n",
    "    \"今日の天気は？\" # 「晴れです」なら「晴れ」を抽出期待\n",
    "]\n",
    "\n",
    "for q_text in questions:\n",
    "    print(f\"\\n--- LLM連携と情報抽出テスト (質問: {q_text}) ---\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=q_text)]}\n",
    "\n",
    "    final_state_invoked = graph.invoke(inputs, {\"recursion_limit\": 5})\n",
    "    print(f\"最終的な応答: {final_state_invoked['messages'][-1].content}\")\n",
    "    print(f\"  User Question: {final_state_invoked.get('user_question')}\")\n",
    "    print(f\"  LLM Response: {final_state_invoked.get('llm_response_text')}\")\n",
    "    print(f\"  Extracted Info: {final_state_invoked.get('extracted_info')}\")\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Graph visualization failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答008</summary>\n",
    "\n",
    "``````python\n",
    "# 解答008\n",
    "from typing import TypedDict, Annotated\n",
    "import re # 正規表現モジュールをインポート\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class ExtractionState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_question: str # ユーザーの元の質問\n",
    "    llm_response_text: str # LLMの生の応答テキスト\n",
    "    extracted_info: str | None # LLMの応答から抽出された情報\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_user_question(state: ExtractionState):\n",
    "    # ユーザーの質問を状態に保存\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    return {\"user_question\": last_message_content}\n",
    "\n",
    "def llm_responder_node(state: ExtractionState):\n",
    "    # LLMに質問を投げるノード\n",
    "    question = state[\"user_question\"]\n",
    "    response = llm.invoke([HumanMessage(content=question)])\n",
    "    response_content = response.content\n",
    "    return {\"messages\": [response], \"llm_response_text\": response_content}\n",
    "\n",
    "def data_extractor_node(state: ExtractionState):\n",
    "    # LLMの応答から情報を抽出するノード\n",
    "    raw_response = state[\"llm_response_text\"]\n",
    "    extracted = None\n",
    "    # 改善された正規表現: 「XXはYYです」「XX is YY」のようなパターンや、単に「YYです」のような応答にも対応試行\n",
    "    # 質問が「日本の首都は何ですか？」で応答が「東京です。」の場合「東京」を抽出\n",
    "    # 質問が「日本の首都は？」で応答が「東京」の場合「東京」を抽出\n",
    "    patterns = [\n",
    "        r\"(?:.+は|.+\\s*is)\\s*(.+?)(?:です|。|\\.|\\s*for|$)\", #「～はXです」「～ is X」\n",
    "        r\"^([^。.]+?)(?:です|。|\\.|\\s*for|$)\" # 文頭から「Xです」\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, raw_response)\n",
    "        if match:\n",
    "            extracted = match.group(1).strip()\n",
    "            if extracted.lower() == state[\"user_question\"].lower().replace(\"何ですか\",\"\").replace(\"何\",\"зиру\").strip(\"?？\") : # 質問自体が答えになるような場合を除外\n",
    "                 extracted = None # 例：「天気は？」->「晴れです」はOKだが、「天気は？」->「天気」はNG\n",
    "                 continue\n",
    "            break\n",
    "    \n",
    "    # もし上記で抽出できなかった場合、LLMの応答が単語やフレーズそのものである可能性を考慮\n",
    "    if not extracted and len(raw_response.split()) < 5 and not state[\"user_question\"].startswith(raw_response): # 短い応答で、質問の繰り返しでない場合\n",
    "        extracted = raw_response.strip()\n",
    "\n",
    "    return {\"extracted_info\": extracted, \"messages\": [AIMessage(content=f\"Extracted info: {extracted if extracted else 'N/A'}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(ExtractionState)\n",
    "\n",
    "workflow.add_node(\"capture_question\", get_user_question)\n",
    "workflow.add_node(\"ask_llm\", llm_responder_node)\n",
    "workflow.add_node(\"extract_data\", data_extractor_node)\n",
    "\n",
    "workflow.set_entry_point(\"capture_question\")\n",
    "\n",
    "workflow.add_edge(\"capture_question\", \"ask_llm\")\n",
    "workflow.add_edge(\"ask_llm\", \"extract_data\")\n",
    "workflow.add_edge(\"extract_data\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "questions = [\n",
    "    \"日本の首都は何ですか？\",\n",
    "    \"フランスの有名な画家の名前を一人教えてください。\", # LLMの回答次第で抽出成功/失敗が変わる\n",
    "    \"1+1は何？\", # LLMが「2です」と答えれば抽出できるかも\n",
    "    \"今日の天気は？\" # 「晴れです」なら「晴れ」を抽出期待\n",
    "]\n",
    "\n",
    "for q_text in questions:\n",
    "    print(f\"\\n--- LLM連携と情報抽出テスト (質問: {q_text}) ---\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=q_text)], \"llm_response_text\": \"\", \"extracted_info\": None} # 初期値を設定\n",
    "    \n",
    "    final_state_data = graph.invoke(inputs, {\"recursion_limit\": 5})\n",
    "\n",
    "    if final_state_data:\n",
    "        print(f\"最終的な応答: {final_state_data['messages'][-1].content}\")\n",
    "        print(f\"  User Question: {final_state_data.get('user_question')}\")\n",
    "        print(f\"  LLM Response: {final_state_data.get('llm_response_text')}\")\n",
    "        print(f\"  Extracted Info: {final_state_data.get('extracted_info')}\")\n",
    "    else:\n",
    "        print(\"Could not retrieve final state.\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説008</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `ExtractionState`には、ユーザーの質問 (`user_question`)、LLMの生の応答テキスト (`llm_response_text`)、そして抽出された情報 (`extracted_info`) を保持するためのキーが定義されています。\n",
    "    *   `get_user_question`ノード: ユーザーからの最初のメッセージを `user_question` として状態に保存します。\n",
    "    *   `llm_responder_node`: 保存された `user_question` を使ってLLMに問い合わせを行い、得られた応答を `messages` (AIMessageとして) と `llm_response_text` (生の文字列として) 状態に保存します。\n",
    "    *   `data_extractor_node`: `llm_response_text` から情報を抽出します。この例では、簡単な正規表現 `re.search(r\"(?:は|is)\\s*([^。.]+)[.。]?\", raw_response)` を使用して、「AはBです」や「A is B」といった形式の文からBの部分を抽出しようと試みています。抽出結果は `extracted_info` として状態に保存されます。正規表現は完璧ではなく、LLMの応答形式によってはうまく抽出できない場合もありますが、ここではLLMの出力後処理の一例として示しています。\n",
    "    *   グラフは `capture_question` -> `ask_llm` -> `extract_data` -> `END` というシーケンシャルな流れで定義されています。\n",
    "    *   実行時には、異なる質問を投げ、LLMの応答とそこから抽出された情報（または抽出できなかった場合は `None` や `N/A`）が最終状態に含まれることを確認します。\n",
    "*   **発展:**\n",
    "    *   情報抽出の方法は正規表現に限らず、より高度なNLPライブラリ（例: spaCy）や、LangChainが提供するOutput Parsers、あるいは別のLLMコール（Function Calling/Tool Calling対応モデルならより高精度）を使って行うことも考えられます。\n",
    "    *   抽出に失敗した場合のフォールバック処理（例: ユーザーに再確認を求める、デフォルト値を設定するなど）をグラフに追加することもできます。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題009: グラフの入力と出力のカスタマイズと明確化\n",
    "\n",
    "LangGraphのグラフを実行する際、invoke() メソッドに渡す初期状態の構造と、グラフ全体の最終的な出力状態の構造を意識することが重要です。StateGraph に渡す状態クラス（例: TypedDict）の定義が、実質的にグラフの入力と出力のスキーマ（型定義）となります。この問題では、入力として複数の情報を受け取り、それらを複数のノードで段階的に処理して特定の構造で出力するグラフを作成し、入出力の対応関係を明確に意識します。\n",
    "\n",
    "*   **学習内容:** `TypedDict` を使ってグラフの状態スキーマを定義する際、どのキーがグラフへの「入力」として期待され、どのキーが処理の「中間状態」として使われ、どのキーが最終的な「出力」として扱われるのかを明確に意識することを学びます。また、直線的なグラフ構造で状態がどのように更新されていくかを確認します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄009\n",
    "from typing import TypedDict, Annotated, List, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (入力、中間、出力のスキーマを兼ねる) ---\n",
    "class ProcessedData(TypedDict):\n",
    "    item_id: str\n",
    "    description: str\n",
    "    is_processed: bool\n",
    "\n",
    "class ComplexIOState(____):\n",
    "    # 入力として期待されるキー\n",
    "    raw_item_name: str\n",
    "    raw_item_details: List[str]\n",
    "\n",
    "    # 処理中に使われるキー (中間状態)\n",
    "    messages: Annotated[list, add_messages]\n",
    "    enriched_description: Optional[str]\n",
    "\n",
    "    # 出力として期待される主要なキー\n",
    "    processed_data: Optional[____] # 処理結果\n",
    "    error_message: Optional[str] # エラー発生時のメッセージ\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def initialize_state(state: ComplexIOState):\n",
    "    \"\"\"入力値を元に、中間状態と出力状態を初期化するノード\"\"\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Initializing for {state['raw_item_name']}\")],\n",
    "        \"enriched_description\": None,\n",
    "        \"processed_data\": None,\n",
    "        \"error_message\": None\n",
    "    }\n",
    "\n",
    "def enrich_description_node(state: ComplexIOState):\n",
    "    \"\"\"入力の詳細情報から、説明文を生成して状態を更新するノード\"\"\"\n",
    "    details_text = \", \".join(state[\"raw_item_details\"])\n",
    "    if not details_text:\n",
    "        # この時点ではエラーとせず、後続のノードで判断させる\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"No details provided to enrich.\")],\n",
    "        }\n",
    "    \n",
    "    description = f\"This item has the following details: {details_text}.\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Description enriched.\")],\n",
    "        \"enriched_description\": description\n",
    "    }\n",
    "\n",
    "def finalize_processing_node(state: ComplexIOState):\n",
    "    \"\"\"最終的な処理を行い、出力キーを確定させるノード\"\"\"\n",
    "    name = state[\"raw_item_name\"]\n",
    "    \n",
    "    # 前のノードで生成された説明文があるかチェック\n",
    "    if not state.get(\"enriched_description\"):\n",
    "        err_msg = f\"Failed to process {name}: No description was generated.\"\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"Error: {err_msg}\")],\n",
    "            \"error_message\": err_msg\n",
    "        }\n",
    "\n",
    "    # 成功した場合の処理\n",
    "    processed_item = ProcessedData(\n",
    "        item_id=f\"PROC_{name.upper()}\",\n",
    "        description=state[\"enriched_description\"],\n",
    "        is_processed=True\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Successfully processed {name}\")],\n",
    "        \"processed_data\": processed_item\n",
    "    }\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(ComplexIOState)\n",
    "\n",
    "# ノードをグラフに追加\n",
    "workflow.add_node(\"initializer\", initialize_state)\n",
    "workflow.add_node(\"enricher\", enrich_description_node)\n",
    "workflow.add_node(\"finalizer\", ____)\n",
    "\n",
    "# ノードをエッジでつなぐ\n",
    "workflow.set_entry_point(\"initializer\")\n",
    "workflow.add_edge(\"initializer\", \"enricher\")\n",
    "workflow.add_edge(____, \"finalizer\")\n",
    "\n",
    "# finalizerノードを終点として設定\n",
    "workflow.add_edge(\"finalizer\", ____)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "inputs_success = {\n",
    "    \"raw_item_name\": \"Laptop\",\n",
    "    \"raw_item_details\": [\"16GB RAM\", \"512GB SSD\", \"M3 Chip\"],\n",
    "}\n",
    "\n",
    "inputs_fail_no_details = {\n",
    "    \"raw_item_name\": \"EmptyItem\",\n",
    "    \"raw_item_details\": [], \n",
    "}\n",
    "\n",
    "test_cases = {\n",
    "    \"Success Case\": inputs_success, \n",
    "    \"Failure Case (No Details)\": inputs_fail_no_details,\n",
    "}\n",
    "\n",
    "for case_name, inputs_data in test_cases.items():\n",
    "    print(f\"\\n--- I/Oカスタマイズテスト: {case_name} ---\")\n",
    "    \n",
    "    # グラフ実行時の入力は、状態スキーマに定義したキーを持つ辞書\n",
    "    final_output_state = graph.invoke(inputs_data)\n",
    "    \n",
    "    print(f\"最終的な応答: {final_output_state['messages'][-1].content}\")\n",
    "\n",
    "    # 最終状態から、出力として定義したキーを取り出して結果を確認\n",
    "    if final_output_state.get(\"processed_data\"):\n",
    "        print(f\"  Processed Item ID: {final_output_state['processed_data']['item_id']}\")\n",
    "        print(f\"  Description: {final_output_state['processed_data']['description']}\")\n",
    "        print(f\"  Processed: {final_output_state['processed_data']['is_processed']}\")\n",
    "    if final_output_state.get(\"error_message\"):\n",
    "        print(f\"  Error: {final_output_state['error_message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答009</summary>\n",
    "\n",
    "``````python\n",
    "# 解答009\n",
    "from typing import TypedDict, Annotated, List, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- 状態定義 (入力、中間、出力のスキーマを兼ねる) ---\n",
    "class ProcessedData(TypedDict):\n",
    "    item_id: str\n",
    "    description: str\n",
    "    is_processed: bool\n",
    "\n",
    "class ComplexIOState(TypedDict):\n",
    "    # 入力として期待されるキー\n",
    "    raw_item_name: str\n",
    "    raw_item_details: List[str]\n",
    "\n",
    "    # 処理中に使われるキー (中間状態)\n",
    "    messages: Annotated[list, add_messages]\n",
    "    enriched_description: Optional[str]\n",
    "\n",
    "    # 出力として期待される主要なキー\n",
    "    processed_data: Optional[ProcessedData] # 処理結果\n",
    "    error_message: Optional[str] # エラー発生時のメッセージ\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def initialize_state(state: ComplexIOState):\n",
    "    \"\"\"入力値を元に、中間状態と出力状態を初期化するノード\"\"\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Initializing for {state['raw_item_name']}\")],\n",
    "        \"enriched_description\": None,\n",
    "        \"processed_data\": None,\n",
    "        \"error_message\": None\n",
    "    }\n",
    "\n",
    "def enrich_description_node(state: ComplexIOState):\n",
    "    \"\"\"入力の詳細情報から、説明文を生成して状態を更新するノード\"\"\"\n",
    "    details_text = \", \".join(state[\"raw_item_details\"])\n",
    "    if not details_text:\n",
    "        # この時点ではエラーとせず、後続のノードで判断させる\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=\"No details provided to enrich.\")],\n",
    "        }\n",
    "    \n",
    "    description = f\"This item has the following details: {details_text}.\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Description enriched.\")],\n",
    "        \"enriched_description\": description\n",
    "    }\n",
    "\n",
    "def finalize_processing_node(state: ComplexIOState):\n",
    "    \"\"\"最終的な処理を行い、出力キーを確定させるノード\"\"\"\n",
    "    name = state[\"raw_item_name\"]\n",
    "    \n",
    "    # 前のノードで生成された説明文があるかチェック\n",
    "    if not state.get(\"enriched_description\"):\n",
    "        err_msg = f\"Failed to process {name}: No description was generated.\"\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"Error: {err_msg}\")],\n",
    "            \"error_message\": err_msg\n",
    "        }\n",
    "\n",
    "    # 成功した場合の処理\n",
    "    processed_item = ProcessedData(\n",
    "        item_id=f\"PROC_{name.upper()}\",\n",
    "        description=state[\"enriched_description\"],\n",
    "        is_processed=True\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Successfully processed {name}\")],\n",
    "        \"processed_data\": processed_item\n",
    "    }\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(ComplexIOState)\n",
    "\n",
    "# ノードをグラフに追加\n",
    "workflow.add_node(\"initializer\", initialize_state)\n",
    "workflow.add_node(\"enricher\", enrich_description_node)\n",
    "workflow.add_node(\"finalizer\", finalize_processing_node)\n",
    "\n",
    "# ノードをエッジでつなぐ\n",
    "workflow.set_entry_point(\"initializer\")\n",
    "workflow.add_edge(\"initializer\", \"enricher\")\n",
    "workflow.add_edge(\"enricher\", \"finalizer\")\n",
    "\n",
    "# finalizerノードを終点として設定\n",
    "workflow.add_edge(\"finalizer\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs_success = {\n",
    "    \"raw_item_name\": \"Laptop\",\n",
    "    \"raw_item_details\": [\"16GB RAM\", \"512GB SSD\", \"M3 Chip\"],\n",
    "}\n",
    "\n",
    "inputs_fail_no_details = {\n",
    "    \"raw_item_name\": \"EmptyItem\",\n",
    "    \"raw_item_details\": [], \n",
    "}\n",
    "\n",
    "test_cases = {\n",
    "    \"Success Case\": inputs_success, \n",
    "    \"Failure Case (No Details)\": inputs_fail_no_details,\n",
    "}\n",
    "\n",
    "for case_name, inputs_data in test_cases.items():\n",
    "    print(f\"\\n--- I/Oカスタマイズテスト: {case_name} ---\")\n",
    "    \n",
    "    # グラフ実行時の入力は、状態スキーマに定義したキーを持つ辞書\n",
    "    final_output_state = graph.invoke(inputs_data)\n",
    "    \n",
    "    print(f\"最終的な応答: {final_output_state['messages'][-1].content}\")\n",
    "\n",
    "    # 最終状態から、出力として定義したキーを取り出して結果を確認\n",
    "    if final_output_state.get(\"processed_data\"):\n",
    "        print(f\"  Processed Item ID: {final_output_state['processed_data']['item_id']}\")\n",
    "        print(f\"  Description: {final_output_state['processed_data']['description']}\")\n",
    "        print(f\"  Processed: {final_output_state['processed_data']['is_processed']}\")\n",
    "    if final_output_state.get(\"error_message\"):\n",
    "        print(f\"  Error: {final_output_state['error_message']}\")\n",
    "\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説009</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   **`ComplexIOState` (状態スキーマ):**\n",
    "        *   **入力想定キー:** `raw_item_name`, `raw_item_details`。これらはグラフ実行時に `invoke` の `inputs` 引数で渡されることが期待される、グラフの「入力」です。\n",
    "        *   **中間状態キー:** `messages`, `enriched_description`。これらはグラフ内部の処理で使われます。`enrich_description_node` が `enriched_description` を書き込み、`finalize_processing_node` がそれを読み取ります。このように、ノード間でデータを渡すために使われます。\n",
    "        *   **出力想定キー:** `processed_data` (処理成功時の結果), `error_message` (エラー発生時の情報)。これらのキーの値が、グラフ実行後の最終的な成果物、つまりグラフの「出力」となります。\n",
    "    *   **ノードの役割分担:**\n",
    "        *   `initialize_state`: グラフの実行開始時に呼ばれ、中間状態や出力用のキーを `None` などで初期化します。\n",
    "        *   `enrich_description_node`: 「入力」である `raw_item_details` を使って中間データ `enriched_description` を生成します。\n",
    "        *   `finalize_processing_node`: 中間データ `enriched_description` を受け取り、それを元に最終的な「出力」である `processed_data` または `error_message` を生成します。\n",
    "    *   **グラフの構造:**\n",
    "        *   `set_entry_point()` で開始ノード (`initializer`) を指定します。\n",
    "        *   `add_edge()` を使って、`initializer` → `enricher` → `finalizer` という直線的な処理の流れを定義します。\n",
    "        *   最後の `workflow.add_edge(\"finalizer\", END)` で、`finalizer` ノードの実行後にグラフが終了することを明示しています。(`END` は LangGraph からインポートした特別な定数です)\n",
    "*   **重要な点:**\n",
    "    *   状態スキーマ（`TypedDict`）は、グラフのインターフェース（入力と出力の形式）と、グラフ内部でのデータの受け渡し方法を定義する、中心的な役割を果たします。\n",
    "    *   処理を複数のノードに分割し、それぞれが一つの責任を持つように設計することで、グラフの見通しが良くなります。\n",
    "    *   ノードからノードへは、状態オブジェクト（この例では `ComplexIOState` のインスタンスである辞書）を介してデータが引き継がれます。前のノードが状態を更新し、次のノードがその更新された状態を読み取って処理を進めます。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題010: 複数のLLM呼び出しを含むグラフ\n",
    "\n",
    "一つのグラフ内で、異なる役割やプロンプトを持つ複数のLLM呼び出しノードを組み込む方法を学びましょう。例えば、最初のLLMがアイデアを生成し、次のLLMがそのアイデアを評価・洗練する、といった連携が考えられます。この問題では、簡単な役割分担を持つ2つのLLMノードを直列に接続します。\n",
    "\n",
    "*   **学習内容:** 一つのグラフ内に、それぞれ異なるプロンプトや役割を持つ複数のLLM呼び出しノードを配置し、それらを連携させる方法を学びます。これにより、より複雑で多段階の思考や処理を行うエージェントやパイプラインを構築できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄010\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, ____\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, ____\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class MultiLLMState(____):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    original_topic: str # ユーザーからの最初のトピック\n",
    "    generated_idea: str | None # アイデア生成LLMの出力\n",
    "    evaluated_idea: str | None # アイデア評価LLMの出力\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_topic(state: MultiLLMState):\n",
    "    topic = state[\"messages\"][-1].content\n",
    "    return {\"original_topic\": topic, \"messages\": [AIMessage(content=f\"Topic received: {topic}\")]}\n",
    "\n",
    "def idea_generation_node(state: MultiLLMState):\n",
    "    topic = state[\"original_topic\"]\n",
    "    \n",
    "    prompt_template_idea = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたは新しいアイデアを生み出すのが得意なAIです。与えられたトピックに関して、ユニークで面白いアイデアを一つ提案してください。アイデアは簡潔に一行で述べてください。\"),\n",
    "        (\"human\", \"トピック: {topic}\")\n",
    "    ])\n",
    "    \n",
    "    chain = ____ | llm\n",
    "    response = chain.invoke({\"topic\": topic})\n",
    "    idea = response.content.strip()\n",
    "    \n",
    "    return {\"generated_idea\": idea, \"messages\": [AIMessage(content=f\"Generated Idea: {idea}\")]}\n",
    "\n",
    "def idea_evaluation_node(state: MultiLLMState):\n",
    "    idea = state[\"generated_idea\"]\n",
    "    if not idea:\n",
    "        return {\"messages\": [AIMessage(content=\"No idea to evaluate.\")], \"evaluated_idea\": \"N/A\"}\n",
    "        \n",
    "    \n",
    "    prompt_template_eval = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたはアイデアを客観的に評価するのが得意なAIです。与えられたアイデアについて、その実現可能性と面白さを評価し、短いコメントを述べてください。\"),\n",
    "        (\"human\", \"評価対象のアイデア: {idea}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt_template_eval | llm\n",
    "    response = chain.invoke({\"idea\": idea})\n",
    "    evaluation = response.content.strip()\n",
    "    \n",
    "    return {\"evaluated_idea\": evaluation, \"messages\": [AIMessage(content=f\"Evaluation: {evaluation}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(MultiLLMState)\n",
    "\n",
    "workflow.add_node(\"capture_topic\", get_topic)\n",
    "workflow.add_node(\"generate_idea\", idea_generation_node)\n",
    "workflow.add_node(\"evaluate_idea\", idea_evaluation_node)\n",
    "\n",
    "workflow.set_entry_point(\"capture_topic\")\n",
    "\n",
    "workflow.add_edge(\"capture_topic\", \"generate_idea\")\n",
    "workflow.add_edge(____, \"evaluate_idea\")\n",
    "workflow.add_edge(\"evaluate_idea\", ____)\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "topics_to_test = [\n",
    "    \"新しい料理のレシピ\",\n",
    "    \"未来の交通手段\",\n",
    "    \"週末の過ごし方\"\n",
    "]\n",
    "\n",
    "for topic_text in topics_to_test:\n",
    "    print(f\"\\n--- 複数LLM連携テスト (トピック: {topic_text}) ---\")\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=topic_text)],\n",
    "        \"original_topic\": \"\", \n",
    "        \"generated_idea\": None,\n",
    "        \"evaluated_idea\": None\n",
    "    }\n",
    "    final_state = graph.invoke(inputs, {\"recursion_limit\": 5})\n",
    "    print(f\"Original Topic: {final_state.get('original_topic')}\")\n",
    "    print(f\"Generated Idea: {final_state.get('generated_idea')}\")\n",
    "    print(f\"Evaluated Idea: \\n{final_state.get('evaluated_idea')}\")\n",
    "    print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答010</summary>\n",
    "\n",
    "``````python\n",
    "# 解答010\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class MultiLLMState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    original_topic: str # ユーザーからの最初のトピック\n",
    "    generated_idea: str | None # アイデア生成LLMの出力\n",
    "    evaluated_idea: str | None # アイデア評価LLMの出力\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def get_topic(state: MultiLLMState):\n",
    "    topic = state[\"messages\"][-1].content\n",
    "    return {\"original_topic\": topic, \"messages\": [AIMessage(content=f\"Topic received: {topic}\")]}\n",
    "\n",
    "def idea_generation_node(state: MultiLLMState):\n",
    "    topic = state[\"original_topic\"]\n",
    "    \n",
    "    prompt_template_idea = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたは新しいアイデアを生み出すのが得意なAIです。与えられたトピックに関して、ユニークで面白いアイデアを一つ提案してください。アイデアは簡潔に一行で述べてください。\"),\n",
    "        (\"human\", \"トピック: {topic}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt_template_idea | llm \n",
    "    response = chain.invoke({\"topic\": topic})\n",
    "    idea = response.content.strip()\n",
    "    \n",
    "    return {\"generated_idea\": idea, \"messages\": [AIMessage(content=f\"Generated Idea: {idea}\")]}\n",
    "\n",
    "def idea_evaluation_node(state: MultiLLMState):\n",
    "    idea = state[\"generated_idea\"]\n",
    "    if not idea:\n",
    "        return {\"messages\": [AIMessage(content=\"No idea to evaluate.\")], \"evaluated_idea\": \"N/A\"}\n",
    "        \n",
    "    \n",
    "    prompt_template_eval = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたはアイデアを客観的に評価するのが得意なAIです。与えられたアイデアについて、その実現可能性と面白さを評価し、短いコメントを述べてください。\"),\n",
    "        (\"human\", \"評価対象のアイデア: {idea}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt_template_eval | llm \n",
    "    response = chain.invoke({\"idea\": idea})\n",
    "    evaluation = response.content.strip()\n",
    "    \n",
    "    return {\"evaluated_idea\": evaluation, \"messages\": [AIMessage(content=f\"Evaluation: {evaluation}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(MultiLLMState)\n",
    "\n",
    "workflow.add_node(\"capture_topic\", get_topic)\n",
    "workflow.add_node(\"generate_idea\", idea_generation_node)\n",
    "workflow.add_node(\"evaluate_idea\", idea_evaluation_node)\n",
    "\n",
    "workflow.set_entry_point(\"capture_topic\")\n",
    "\n",
    "workflow.add_edge(\"capture_topic\", \"generate_idea\")\n",
    "workflow.add_edge(\"generate_idea\", \"evaluate_idea\")\n",
    "workflow.add_edge(\"evaluate_idea\", END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "topics_to_test = [\n",
    "    \"新しい料理のレシピ\",\n",
    "    \"未来の交通手段\",\n",
    "    \"週末の過ごし方\"\n",
    "]\n",
    "\n",
    "for topic_text in topics_to_test:\n",
    "    print(f\"\\n--- 複数LLM連携テスト (トピック: {topic_text}) ---\")\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=topic_text)],\n",
    "        \"original_topic\": \"\", \n",
    "        \"generated_idea\": None,\n",
    "        \"evaluated_idea\": None\n",
    "    }\n",
    "    final_state = graph.invoke(inputs, {\"recursion_limit\": 5})\n",
    "    print(f\"Original Topic: {final_state.get('original_topic')}\")\n",
    "    print(f\"Generated Idea: {final_state.get('generated_idea')}\")\n",
    "    print(f\"Evaluated Idea: \\n{final_state.get('evaluated_idea')}\")\n",
    "    print(\"\\n\\n\\n\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説010</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `MultiLLMState`には、ユーザーからの最初のトピック (`original_topic`)、最初のLLMが生成したアイデア (`generated_idea`)、そして二番目のLLMが評価した結果 (`evaluated_idea`) を保持するキーが定義されています。\n",
    "    *   `get_topic`ノード: ユーザーの入力を `original_topic` として状態に保存します。\n",
    "    *   `idea_generation_node`: `original_topic` に基づいて、アイデア生成用のプロンプト (`prompt_template_idea`) を使用してLLMを呼び出し、結果を `generated_idea` に保存します。\n",
    "    *   `idea_evaluation_node`: `generated_idea` に基づいて、アイデア評価用のプロンプト (`prompt_template_eval`) を使用してLLMを呼び出し（ここでも同じ `llm` インスタンスを使用していますが、プロンプトが異なるため役割が変わります）、結果を `evaluated_idea` に保存します。\n",
    "    *   グラフは `capture_topic` -> `generate_idea` -> `evaluate_idea` -> `END` という直列な流れで、各ステップで状態が更新されていきます。\n",
    "    *   各LLM呼び出しノード内では、`langchain_core.prompts.ChatPromptTemplate` を使ってそのノード専用のプロンプトを定義し、共通の `llm` インスタンスと組み合わせて (例: `chain = prompt_template | llm`) LLM呼び出しを行っています。これにより、同じLLMモデルでも異なる指示を与えることで、多様な処理を実現できます。\n",
    "*   **応用例:**\n",
    "    *   リサーチアシスタント: 質問受け付け -> 情報検索プロンプトでLLM -> 要約プロンプトでLLM -> 報告書作成プロンプトでLLM。\n",
    "    *   コード生成・レビュー: 要件定義 -> コード生成LLM -> 生成コード評価LLM -> 修正指示LLM。\n",
    "    *   このように、タスクを細分化し、各サブタスクに特化したプロンプトを持つLLMノードを連携させることで、より高品質な結果を得ることが期待できます。\n",
    "---\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題011: 第1章のまとめ - 直列LLMパイプラインの構築\n",
    "\n",
    "第1章で学んだ様々な要素（状態管理、複数のノード、LLM連携）を組み合わせて、一つの完結した処理パイプラインを構築してみましょう。この問題では、ユーザーからの質問を「分析」「調査」「要約」という3つのステップで処理する、直列（シーケンシャル）なグラフを作成します。\n",
    "\n",
    "*   **学習内容:** これまで学んだ `StateGraph` の定義、`TypedDict` による状態管理、`add_node` と `add_edge` による直列なグラフ構築、そして各ノードでのLLM呼び出しを統合します。状態が各ノードを通過するたびに段階的に更新され、最終的な成果物が作られていく様子を通じて、LangGraphの基本的なパイプライン構築方法を総復習します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄011\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import StateGraph, ____\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, ____\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "# パイプライン全体で引き継がれる情報の器を定義\n",
    "class PipelineState(____):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_question: str          # ユーザーの元の質問\n",
    "    analysis_result: str | None # 質問の分析結果\n",
    "    research_result: str | None # 調査結果\n",
    "    final_summary: str | None   # 最終的な要約\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def capture_question_node(state: PipelineState):\n",
    "    \"\"\"最初のノード。ユーザーの質問を状態に保存する。\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    return {\"user_question\": user_message}\n",
    "\n",
    "def analyze_question_node(state: PipelineState):\n",
    "    \"\"\"LLMを使って、質問の主要なトピックや意図を分析するノード。\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたはユーザーの質問を分析する専門家です。質問の主要なトピックやキーワードを簡潔に抜き出してください。\"),\n",
    "        (\"human\", \"質問: {question}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"question\": state[\"user_question\"]})\n",
    "    return {\"analysis_result\": response.content}\n",
    "\n",
    "def researcher_node(state: PipelineState):\n",
    "    \"\"\"分析結果を基に、LLMが情報を調査・詳述するノード。\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたは優秀なリサーチャーです。以下のトピックについて、重要なポイントを箇条書きで詳しく説明してください。\"),\n",
    "        (\"human\", \"トピック: {topic}\")\n",
    "    ])\n",
    "    chain = ____ | llm\n",
    "    response = chain.invoke({\"topic\": state[\"analysis_result\"]})\n",
    "    return {\"research_result\": response.content}\n",
    "\n",
    "def summarizer_node(state: PipelineState):\n",
    "    \"\"\"調査結果を基に、LLMが最終的な回答を要約するノード。\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたは情報を分かりやすく要約する専門家です。以下の調査結果を、初心者にも理解できるように丁寧な言葉で要約してください。\"),\n",
    "        (\"human\", \"調査結果:\\n{research_info}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"research_info\": state[\"research_result\"]})\n",
    "    summary = response.content\n",
    "    # 最終的な要約を状態に保存し、メッセージ履歴にも追加する\n",
    "    return {\"final_summary\": summary, \"messages\": [AIMessage(content=summary)]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(____)\n",
    "\n",
    "# ノードをグラフに追加\n",
    "workflow.add_node(\"capture_question\", capture_question_node)\n",
    "workflow.add_node(\"analyzer\", analyze_question_node)\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"summarizer\", summarizer_node)\n",
    "\n",
    "# ノードをエッジで直列につなぐ\n",
    "workflow.set_entry_point(\"capture_question\")\n",
    "workflow.add_edge(\"capture_question\", \"analyzer\")\n",
    "workflow.add_edge(\"analyzer\", ____)\n",
    "workflow.add_edge(\"researcher\", \"summarizer\")\n",
    "workflow.add_edge(____, END)\n",
    "\n",
    "# グラフをコンパイル\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "question = \"LangGraphの基本的な仕組みについて、主要な構成要素を挙げて説明してください。\"\n",
    "inputs = {\"messages\": [HumanMessage(content=question)]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "\n",
    "print(f\"--- 最終的な実行結果 ---\")\n",
    "print(f\"■ ユーザーの質問:\\n{final_state.get('user_question')}\\n\")\n",
    "print(f\"■ 質問の分析結果:\\n{final_state.get('analysis_result')}\\n\")\n",
    "print(f\"■ 調査結果:\\n{final_state.get('research_result')}\\n\")\n",
    "print(f\"■ 最終的な要約:\\n{final_state.get('final_summary')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答011</summary>\n",
    "\n",
    "``````python\n",
    "# 解答011\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "# パイプライン全体で引き継がれる情報の器を定義\n",
    "class PipelineState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_question: str          # ユーザーの元の質問\n",
    "    analysis_result: str | None # 質問の分析結果\n",
    "    research_result: str | None # 調査結果\n",
    "    final_summary: str | None   # 最終的な要約\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def capture_question_node(state: PipelineState):\n",
    "    \"\"\"最初のノード。ユーザーの質問を状態に保存する。\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    return {\"user_question\": user_message}\n",
    "\n",
    "def analyze_question_node(state: PipelineState):\n",
    "    \"\"\"LLMを使って、質問の主要なトピックや意図を分析するノード。\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたはユーザーの質問を分析する専門家です。質問の主要なトピックやキーワードを簡潔に抜き出してください。\"),\n",
    "        (\"human\", \"質問: {question}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"question\": state[\"user_question\"]})\n",
    "    return {\"analysis_result\": response.content}\n",
    "\n",
    "def researcher_node(state: PipelineState):\n",
    "    \"\"\"分析結果を基に、LLMが情報を調査・詳述するノード。\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたは優秀なリサーチャーです。以下のトピックについて、重要なポイントを箇条書きで詳しく説明してください。\"),\n",
    "        (\"human\", \"トピック: {topic}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"topic\": state[\"analysis_result\"]})\n",
    "    return {\"research_result\": response.content}\n",
    "\n",
    "def summarizer_node(state: PipelineState):\n",
    "    \"\"\"調査結果を基に、LLMが最終的な回答を要約するノード。\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"あなたは情報を分かりやすく要約する専門家です。以下の調査結果を、初心者にも理解できるように丁寧な言葉で要約してください。\"),\n",
    "        (\"human\", \"調査結果:\\n{research_info}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"research_info\": state[\"research_result\"]})\n",
    "    summary = response.content\n",
    "    # 最終的な要約を状態に保存し、メッセージ履歴にも追加する\n",
    "    return {\"final_summary\": summary, \"messages\": [AIMessage(content=summary)]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(PipelineState)\n",
    "\n",
    "# ノードをグラフに追加\n",
    "workflow.add_node(\"capture_question\", capture_question_node)\n",
    "workflow.add_node(\"analyzer\", analyze_question_node)\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"summarizer\", summarizer_node)\n",
    "\n",
    "# ノードをエッジで直列につなぐ\n",
    "workflow.set_entry_point(\"capture_question\")\n",
    "workflow.add_edge(\"capture_question\", \"analyzer\")\n",
    "workflow.add_edge(\"analyzer\", \"researcher\")\n",
    "workflow.add_edge(\"researcher\", \"summarizer\")\n",
    "workflow.add_edge(\"summarizer\", END)\n",
    "\n",
    "# グラフをコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "question = \"LangGraphの基本的な仕組みについて、主要な構成要素を挙げて説明してください。\"\n",
    "inputs = {\"messages\": [HumanMessage(content=question)]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "\n",
    "print(f\"--- 最終的な実行結果 ---\")\n",
    "print(f\"■ ユーザーの質問:\\n{final_state.get('user_question')}\\n\")\n",
    "print(f\"■ 質問の分析結果:\\n{final_state.get('analysis_result')}\\n\")\n",
    "print(f\"■ 調査結果:\\n{final_state.get('research_result')}\\n\")\n",
    "print(f\"■ 最終的な要約:\\n{final_state.get('final_summary')}\")\n",
    "``````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説011</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "この問題は、第1章で学んだ知識の総仕上げです。条件分岐のような複雑な制御は使わず、LangGraphの最も基本的かつ強力な機能である**「状態（State）を介した直列（シーケンシャル）な処理パイプライン」**を構築します。\n",
    "\n",
    "*   **段階的な状態の更新:**\n",
    "    グラフは `capture_question` -> `analyzer` -> `researcher` -> `summarizer` の順に実行されます。`PipelineState`で定義された状態オブジェクト（辞書）が、ノードからノードへとバケツリレーのように渡されていきます。各ノードは、前のノードから渡された状態を読み取り、自身の処理結果を状態に書き加えて次のノードに渡します。\n",
    "    1.  最初は `user_question` しかありません。\n",
    "    2.  `analyzer` が `analysis_result` を追加します。\n",
    "    3.  `researcher` が `research_result` を追加します。\n",
    "    4.  `summarizer` が `final_summary` と最終的な `messages` を追加して完了です。\n",
    "    このように、状態が徐々に豊かになっていく様子が、パイプライン処理の本質です。\n",
    "\n",
    "*   **各ノードの役割分担:**\n",
    "    このグラフでは、4つのノードがそれぞれ明確な役割を持っています。特に、`analyzer`、`researcher`、`summarizer` の3つのノードは、同じ `llm` インスタンスを使いながらも、`ChatPromptTemplate` を用いてそれぞれ異なる指示（役割）を与えられています。これにより、一つのタスクを複数の専門家（LLM）が連携して解決するような、高度な処理を実現できます。\n",
    "\n",
    "*   **第1章の総括:**\n",
    "    この問題を通じて、`StateGraph` と `TypedDict` を使って処理の「状態」を定義し、`add_node` と `add_edge` で処理の「流れ」を組み立てるという、LangGraphの基本的な開発サイクルを体験できました。この直列パイプラインは、LangGraphでアプリケーションを構築する際の最も基本的なパターンであり、今後のより複雑なグラフを設計する上での確かな土台となります。\n",
    "---\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
