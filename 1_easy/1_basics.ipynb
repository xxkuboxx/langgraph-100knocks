{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: グラフの基本要素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備\n",
    "\n",
    "以下のセルを順番に実行して、演習に必要な環境をセットアップします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMプロバイダーの選択\n",
    "\n",
    "このセルでは、使用するLLMプロバイダーを選択します。\n",
    "`LLM_PROVIDER` 変数に、利用したいプロバイダー名を設定してください。\n",
    "選択可能なプロバイダー: `\"openai\"`, `\"azure\"`, `\"google\"` (Vertex AI), `\"google_genai\"` (Gemini API), `\"anthropic\"`, `\"bedrock\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLMプロバイダーの選択 ===\n",
    "# 利用したいLLMプロバイダーを以下の変数で指定してください。\n",
    "# \"openai\", \"azure\", \"google\" (Vertex AI), \"google_genai\" (Gemini API), \"anthropic\", \"bedrock\" のいずれかを選択できます。\n",
    "LLM_PROVIDER = \"openai\"  # 例: OpenAI を利用する場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIキー/環境変数の設定\n",
    "\n",
    "以下のセルを実行する前に、選択したLLMプロバイダーに応じたAPIキーまたは環境変数を設定する必要があります。\n",
    "\n",
    "**手順:**\n",
    "1.  `.env.sample` ファイルをコピーして `.env` ファイルを作成します。\n",
    "2.  `.env` ファイルを開き、選択したLLMプロバイダーに対応するAPIキーや必要な情報を記述します。\n",
    "    *   **OpenAI:** `OPENAI_API_KEY`\n",
    "    *   **Azure OpenAI:** `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `OPENAI_API_VERSION`, `AZURE_OPENAI_DEPLOYMENT_NAME`\n",
    "    *   **Google (Vertex AI):** `GOOGLE_CLOUD_PROJECT_ID`, `GOOGLE_CLOUD_LOCATION` (Colab環境外で実行する場合、`GOOGLE_APPLICATION_CREDENTIALS` 環境変数の設定も必要になることがあります)\n",
    "    *   **Google (Gemini API):** `GOOGLE_API_KEY`\n",
    "    *   **Anthropic:** `ANTHROPIC_API_KEY`\n",
    "    *   **AWS Bedrock:** `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION_NAME` (IAMロールを使用する場合は、これらのキー設定は不要な場合がありますが、リージョン名は必須です)\n",
    "3.  ファイルを保存します。\n",
    "\n",
    "**Google Colab を使用している場合:**\n",
    "上記の `.env` ファイルを使用する代わりに、Colabのシークレットマネージャーに必要なキーを登録してください。\n",
    "例えば、OpenAIを使用する場合は `OPENAI_API_KEY` という名前でシークレットを登録します。\n",
    "Vertex AI を利用する場合は、Colab上での認証 (`google.colab.auth.authenticate_user()`) が実行されます。\n",
    "\n",
    "このセルは、設定された情報に基づいて環境変数をロードし、LLMクライアントを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === APIキー/環境変数の設定 ===\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルから環境変数を読み込む (存在する場合)\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    IS_COLAB = True\n",
    "except ImportError:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# --- OpenAI ---\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    if not OPENAI_API_KEY and IS_COLAB:\n",
    "        OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise ValueError(\"OpenAI APIキーが設定されていません。環境変数 OPENAI_API_KEY を設定するか、Colab環境の場合はシークレットに OPENAI_API_KEY を設定してください。\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# --- Azure OpenAI ---\n",
    "elif LLM_PROVIDER == \"azure\":\n",
    "    AZURE_OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "    AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "    AZURE_OPENAI_DEPLOYMENT_NAME = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "    if IS_COLAB:\n",
    "        if not AZURE_OPENAI_API_KEY: AZURE_OPENAI_API_KEY = userdata.get(\"AZURE_OPENAI_API_KEY\")\n",
    "        if not AZURE_OPENAI_ENDPOINT: AZURE_OPENAI_ENDPOINT = userdata.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        if not OPENAI_API_VERSION: OPENAI_API_VERSION = userdata.get(\"OPENAI_API_VERSION\") # 例: \"2023-07-01-preview\"\n",
    "        if not AZURE_OPENAI_DEPLOYMENT_NAME: AZURE_OPENAI_DEPLOYMENT_NAME = userdata.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "    if not AZURE_OPENAI_API_KEY: raise ValueError(\"Azure OpenAI APIキー (AZURE_OPENAI_API_KEY) が設定されていません。\")\n",
    "    if not AZURE_OPENAI_ENDPOINT: raise ValueError(\"Azure OpenAI エンドポイント (AZURE_OPENAI_ENDPOINT) が設定されていません。\")\n",
    "    if not OPENAI_API_VERSION: OPENAI_API_VERSION = \"2023-07-01-preview\" # デフォルトを設定することも可能\n",
    "    if not AZURE_OPENAI_DEPLOYMENT_NAME: raise ValueError(\"Azure OpenAI デプロイメント名 (AZURE_OPENAI_DEPLOYMENT_NAME) が設定されていません。\")\n",
    "\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "    os.environ[\"OPENAI_API_VERSION\"] = OPENAI_API_VERSION\n",
    "\n",
    "# --- Google Cloud Vertex AI (Gemini) ---\n",
    "elif LLM_PROVIDER == \"google\":\n",
    "    PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT_ID\") # .env 用に修正\n",
    "    LOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\")\n",
    "\n",
    "    if IS_COLAB:\n",
    "        if not PROJECT_ID: PROJECT_ID = userdata.get(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
    "        if not LOCATION: LOCATION = userdata.get(\"GOOGLE_CLOUD_LOCATION\") # 例: \"us-central1\"\n",
    "        from google.colab import auth as google_auth\n",
    "        google_auth.authenticate_user() # Vertex AI を使う場合は Colab での認証を推奨\n",
    "    else: # Colab外の場合、.envから読み込んだ値で環境変数を設定\n",
    "        if PROJECT_ID: os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID # Vertex AI SDKが参照する標準的な環境変数名\n",
    "        if LOCATION: os.environ['GOOGLE_CLOUD_LOCATION'] = LOCATION\n",
    "\n",
    "    if not PROJECT_ID: raise ValueError(\"Google Cloud Project ID が設定されていません。環境変数 GOOGLE_CLOUD_PROJECT_ID を設定するか、Colab環境の場合はシークレットに GOOGLE_CLOUD_PROJECT_ID を設定してください。\")\n",
    "    if not LOCATION: LOCATION = \"us-central1\" # デフォルトロケーション\n",
    "\n",
    "# --- Google Gemini API (langchain-google-genai) ---\n",
    "elif LLM_PROVIDER == \"google_genai\":\n",
    "    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY and IS_COLAB:\n",
    "        GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY:\n",
    "        raise ValueError(\"Google APIキーが設定されていません。環境変数 GOOGLE_API_KEY を設定するか、Colab環境の場合はシークレットに GOOGLE_API_KEY を設定してください。\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# --- Anthropic (Claude) ---\n",
    "elif LLM_PROVIDER == \"anthropic\":\n",
    "    ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    if not ANTHROPIC_API_KEY and IS_COLAB:\n",
    "        ANTHROPIC_API_KEY = userdata.get(\"ANTHROPIC_API_KEY\")\n",
    "    if not ANTHROPIC_API_KEY:\n",
    "        raise ValueError(\"Anthropic APIキーが設定されていません。環境変数 ANTHROPIC_API_KEY を設定するか、Colab環境の場合はシークレットに ANTHROPIC_API_KEY を設定してください。\")\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "\n",
    "# --- Amazon Bedrock (Claude) ---\n",
    "elif LLM_PROVIDER == \"bedrock\":\n",
    "    AWS_ACCESS_KEY_ID = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "    AWS_SECRET_ACCESS_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    AWS_REGION_NAME = os.environ.get(\"AWS_REGION_NAME\")\n",
    "\n",
    "    if IS_COLAB: \n",
    "        if not AWS_ACCESS_KEY_ID: AWS_ACCESS_KEY_ID = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
    "        if not AWS_SECRET_ACCESS_KEY: AWS_SECRET_ACCESS_KEY = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "        if not AWS_REGION_NAME: AWS_REGION_NAME = userdata.get(\"AWS_REGION_NAME\")\n",
    "\n",
    "    if not AWS_REGION_NAME:\n",
    "         raise ValueError(\"AWSリージョン名 (AWS_REGION_NAME) が設定されていません。Bedrock利用にはリージョン指定が必要です。\")\n",
    "\n",
    "    # 環境変数に設定 (boto3がこれらを自動で読み込む)\n",
    "    if AWS_ACCESS_KEY_ID: os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "    if AWS_SECRET_ACCESS_KEY: os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "    os.environ[\"AWS_DEFAULT_REGION\"] = AWS_REGION_NAME # boto3が参照する標準的なリージョン環境変数名\n",
    "    os.environ[\"AWS_REGION\"] = AWS_REGION_NAME # いくつかのライブラリはこちらを参照することもある\n",
    "\n",
    "print(f\"APIキー/環境変数の設定完了 (プロバイダー: {LLM_PROVIDER})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMクライアントの初期化\n",
    "\n",
    "このセルは、上で選択・設定したLLMプロバイダーに基づいて、対応するLLMクライアントを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLMクライアントの動的初期化 ===\n",
    "llm = None\n",
    "\n",
    "if LLM_PROVIDER == \"openai\":\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "elif LLM_PROVIDER == \"azure\":\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"), # 環境変数から取得\n",
    "        openai_api_version=os.environ.get(\"OPENAI_API_VERSION\"), # 環境変数から取得\n",
    "        temperature=0,\n",
    "    )\n",
    "elif LLM_PROVIDER == \"google\":\n",
    "    from langchain_google_vertexai import ChatVertexAI\n",
    "    # PROJECT_ID, LOCATION は前のセルで環境変数に設定済みか、Colabの場合は直接利用\n",
    "    llm = ChatVertexAI(model_name=\"gemini-2.0-flash\", temperature=0, project=os.environ.get(\"GOOGLE_CLOUD_PROJECT\"), location=os.environ.get(\"GOOGLE_CLOUD_LOCATION\"))\n",
    "elif LLM_PROVIDER == \"google_genai\":\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "elif LLM_PROVIDER == \"anthropic\":\n",
    "    from langchain_anthropic import ChatAnthropic\n",
    "    llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)\n",
    "elif LLM_PROVIDER == \"bedrock\":\n",
    "    from langchain_aws import ChatBedrock # langchain_community.chat_models から langchain_aws に変更の可能性あり\n",
    "    # AWS_REGION_NAME は前のセルで環境変数 AWS_DEFAULT_REGION に設定済み\n",
    "    llm = ChatBedrock( # BedrockChat ではなく ChatBedrock が一般的\n",
    "        model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        # region_name=os.environ.get(\"AWS_DEFAULT_REGION\"), # 通常、boto3が環境変数から自動で読み込む\n",
    "        model_kwargs={\"temperature\": 0},\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Unsupported LLM_PROVIDER: {LLM_PROVIDER}. \"\n",
    "        \"Please choose from 'openai', 'azure', 'google', 'google_genai', 'anthropic', or 'bedrock'.\"\n",
    "    )\n",
    "\n",
    "print(f\"LLM Provider: {LLM_PROVIDER}\")\n",
    "if llm:\n",
    "    print(f\"LLM Client Type: {type(llm)}\")\n",
    "    # モデル名取得の試行を汎用的に\n",
    "    model_attr = (\n",
    "                 getattr(llm, 'model', None) or\n",
    "                 getattr(llm, 'model_name', None) or\n",
    "                 getattr(llm, 'model_id', None) or\n",
    "                 (hasattr(llm, 'llm') and getattr(llm.llm, 'model', None)) # 一部のLLMクライアントのネスト構造に対応\n",
    "    )\n",
    "    if hasattr(llm, 'azure_deployment') and not model_attr: # Azure特有の属性\n",
    "        model_attr = llm.azure_deployment\n",
    "        \n",
    "    if model_attr:\n",
    "        print(f\"LLM Model: {model_attr}\")\n",
    "    else:\n",
    "        print(\"LLM Model: (Could not determine model name from client attributes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題001: 最小構成のLangGraphグラフの構築\n",
    "\n",
    "LangGraphの最も基本的な構成要素である`StateGraph`と`State`を理解し、シンプルなグラフを構築してみましょう。この問題では、入力された文字列をそのまま出力するだけの、単一のノードを持つグラフを作成します。\n",
    "\n",
    "*   **学習内容:** この問題では、`StateGraph`、`TypedDict`を用いた`State`の定義、`add_node`、`set_entry_point`、`add_edge`、`END`といったLangGraphの最も基本的なAPIを学びます。また、`Annotated`と`add_messages`を使ってメッセージ履歴を管理する方法も理解します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    print(f'simple_node: {state[\"messages\"][-1].content}')\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(____)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.____(\"simple_node\", ____)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"simple_node\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答001</summary>\n",
    "\n",
    "``````python\n",
    "# 解答001\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    # グラフの状態を保持する辞書\n",
    "    # ここでは、入力メッセージを保持する\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # 入力されたメッセージをそのまま返すノード\n",
    "    print(f'simple_node: {state[\"messages\"][-1].content}')\n",
    "    return {\"messages\": [state[\"messages\"][-1]]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [(\"user\", \"Hello, LangGraph!\")]}\n",
    "\n",
    "# 最終結果の確認\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説001</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `GraphState`は、グラフ全体で共有される状態を定義します。`TypedDict`を使うことで、状態のスキーマを明確にできます。`messages: Annotated[list, add_messages]`は、LangChainのメッセージ形式のリストを状態として持ち、新しいメッセージが追加されるたびに自動的にリストの末尾に追加されるように設定しています。\n",
    "    *   `simple_node`関数は、グラフのノードとして機能します。`state`引数として現在のグラフの状態を受け取り、新しい状態を辞書として返します。ここでは、入力された最後のメッセージをそのまま返しています。\n",
    "    *   `StateGraph(GraphState)`でグラフのインスタンスを作成し、`GraphState`で定義した状態スキーマを渡します。\n",
    "    *   `workflow.add_node(\"simple_node\", simple_node)`で、`simple_node`関数を`simple_node`という名前のノードとしてグラフに追加します。\n",
    "    *   `workflow.set_entry_point(\"simple_node\")`は、グラフの実行が開始される最初のノードを指定します。\n",
    "    *   `workflow.add_edge(\"simple_node\", END)`は、`simple_node`の実行が完了したらグラフを終了することを示します。`END`はLangGraphが提供する特別な終了ノードです。\n",
    "    *   `graph = workflow.compile()`で、定義したワークフローを実行可能なアプリケーションにコンパイルします。\n",
    "    *   `graph.stream(inputs)`は、グラフの実行過程をストリーミングで受け取ることができます。`graph.invoke(inputs)`は、グラフの実行が完了した最終状態を返します。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題002: グラフの可視化\n",
    "\n",
    "問題001で構築した最小構成のグラフの構造を、視覚的に確認する方法を学びましょう。\n",
    "\n",
    "*   **学習内容:** `graph.get_graph().draw_png()` を使用して、コンパイル済みのLangGraphグラフ構造をPNG画像として描画し、Jupyter Notebook上に表示する方法を学びます。これにより、グラフのノードとエッジの接続関係を直感的に理解できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄002\n",
    "\n",
    "# 問題001のコードを再掲（このセルでグラフを定義・コンパイルします）\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # このノードは状態を更新せず、最後のメッセージをログに出力するだけ\n",
    "    print(f\"simple_node: Received message -> {state['messages'][-1].content}\")\n",
    "    # LangGraphでは、ノードがNoneまたは空の辞書を返すと、状態は更新されない\n",
    "    return\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    png_data = graph.____().____() # get_graph, draw_png\n",
    "    display(____(png_data)) # Image\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの動作確認 ---\n",
    "# 可視化したグラフが問題001と同様に動作することを確認します。\n",
    "try:\n",
    "    inputs = {\"messages\": [HumanMessage(content=\"Hello, this is a test.\")]}\n",
    "    final_state = graph.invoke(inputs)\n",
    "    print(\"\\nグラフの実行が完了しました。\")\n",
    "    print(f\"最終的なmessagesの状態: {final_state['messages']}\")\n",
    "except NameError:\n",
    "    print(\"グラフが定義されていません。前のセルを先に実行してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答002</summary>\n",
    "\n",
    "``````python\n",
    "# 解答002\n",
    "\n",
    "# 問題001のコードを再掲（このセルでグラフを定義・コンパイルします）\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def simple_node(state: GraphState):\n",
    "    # このノードは状態を更新せず、最後のメッセージをログに出力するだけ\n",
    "    print(f\"simple_node: Received message -> {state['messages'][-1].content}\")\n",
    "    # LangGraphでは、ノードがNoneまたは空の辞書を返すと、状態は更新されない\n",
    "    return\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"simple_node\", simple_node)\n",
    "workflow.set_entry_point(\"simple_node\")\n",
    "workflow.add_edge(\"simple_node\", END)\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    png_data = graph.get_graph().draw_png()\n",
    "    display(Image(png_data))\n",
    "    print(\"グラフが正常に可視化されました。\")\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")\n",
    "\n",
    "# --- グラフの動作確認 ---\n",
    "# 可視化したグラフが問題001と同様に動作することを確認します。\n",
    "try:\n",
    "    inputs = {\"messages\": [HumanMessage(content=\"Hello, this is a test.\")]}\n",
    "    final_state = graph.invoke(inputs)\n",
    "    print(\"\\nグラフの実行が完了しました。\")\n",
    "    print(f\"最終的なmessagesの状態: {final_state['messages']}\")\n",
    "except NameError:\n",
    "    print(\"グラフが定義されていません。前のセルを先に実行してください。\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説002</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   この問題では、まず問題001で作成したグラフ定義のコードを再利用して、`graph`オブジェクトを準備します。\n",
    "    *   グラフを可視化するための中心的なメソッドが `graph.get_graph().draw_png()` です。\n",
    "        *   `graph.get_graph()`: コンパイル済みの`graph`オブジェクトから、可視化や解析が可能な内部グラフ表現を取得します。\n",
    "        *   `.draw_png()`: 取得したグラフ表現をPNG形式の画像データ（バイト列）として描画します。\n",
    "    *   `IPython.display.Image` は、画像データをJupyter NotebookなどのIPython環境で表示可能なオブジェクトに変換します。\n",
    "    *   `IPython.display.display()` 関数を使って、`Image`オブジェクトをセルに表示します。\n",
    "    *   **重要:** `.draw_png()` メソッドを使用するには、**Graphviz**というグラフ可視化ソフトウェアがシステムにインストールされている必要があります。また、Pythonライブラリの`pygraphviz`も必要です（これらは準備セクションでインストール済みです）。もし`ExecutableNotFound`のようなエラーが出る場合は、Graphviz本体がOSに正しくインストールされ、パスが通っているかを確認してください。\n",
    "\n",
    "*   **なぜ可視化が重要か:**\n",
    "    *   グラフが単純なうちはコードを読むだけで構造を理解できますが、ノードやエッジが増え、特に条件分岐やループが絡んでくると、全体の流れを把握するのが難しくなります。\n",
    "    *   グラフを可視化することで、設計した通りの構造になっているかを一目で確認でき、意図しない接続やループのデバッグに非常に役立ちます。\n",
    "\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題003: 複数のノードを持つシーケンシャルグラフの構築\n",
    "\n",
    "前の問題で学んだ基本的なグラフ構築に加えて、複数のノードを直列に接続し、データがノード間をどのように流れるかを理解しましょう。ここでは、入力された文字列を加工する2つのノード（例：大文字化、逆順化）を持つグラフを作成します。\n",
    "\n",
    "*   **学習内容:** 複数のノードを`add_edge`で直列に接続する方法と、ノード間で状態がどのように引き継がれるかを学びます。`HumanMessage`と`AIMessage`を使って、メッセージの送信元を明示する方法も理解します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄003\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import ____, ____\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"uppercase_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"reverse_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(____)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"uppercase\", uppercase_node)\n",
    "workflow.add_node(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.____(\"uppercase\")\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.add_edge(\"uppercase\", \"reverse\")\n",
    "workflow.add_edge(\"reverse\", ____)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello LangGraph\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答003</summary>\n",
    "\n",
    "``````python\n",
    "# 解答003\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def uppercase_node(state: GraphState):\n",
    "    # 最新のメッセージを大文字に変換するノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"uppercase_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content.upper())]}\n",
    "\n",
    "def reverse_node(state: GraphState):\n",
    "    # 最新のメッセージを逆順にするノード\n",
    "    last_message_content = state[\"messages\"][-1].content\n",
    "    print(f\"reverse_node: {last_message_content}\")\n",
    "    return {\"messages\": [AIMessage(content=last_message_content[::-1])]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"uppercase\", uppercase_node)\n",
    "workflow.add_node(\"reverse\", reverse_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"uppercase\")\n",
    "\n",
    "# エッジの追加 (直列接続)\n",
    "workflow.add_edge(\"uppercase\", \"reverse\")\n",
    "workflow.add_edge(\"reverse\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Hello LangGraph\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説003</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `uppercase_node`と`reverse_node`は、それぞれ入力メッセージを大文字化、逆順化する処理を行います。重要なのは、各ノードが新しい`AIMessage`を作成して状態に返す点です。これにより、次のノードは前のノードの処理結果を`state[\"messages\"][-1]`で取得できます。\n",
    "    *   `workflow.add_edge(\"uppercase\", \"reverse\")`は、`uppercase`ノードの実行が完了したら、次に`reverse`ノードを実行するように指示します。このようにして、処理の流れを定義します。\n",
    "    *   入力メッセージを`HumanMessage`として渡すことで、ユーザーからの入力であることを明示しています。ノードからの出力は`AIMessage`として返され、メッセージ履歴にAIの応答として記録されます。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題004: グラフ内でのLLMの利用（シンプルなチャットボット）\n",
    "\n",
    "LangGraphのノード内で大規模言語モデル（LLM）を呼び出す方法を学び、シンプルなチャットボットを構築しましょう。ここでは、ユーザーからの入力に対してLLMが応答を生成し、その応答を返すグラフを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄004\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import ____, ____\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import os\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "# (from langchain_openai import ChatOpenAI や llm = ChatOpenAI(...) といった行はここには不要)\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def llm_node(state: GraphState):\n",
    "    # LLMを呼び出し、応答を生成するノード\n",
    "    # ノートブック冒頭で初期化された共通の `llm` 変数を使用します。\n",
    "    print(f\"llm_node: Calling LLM with messages: {state['messages']}\")\n",
    "    response = llm.____(state[\"messages\"]) \n",
    "    print(f\"llm_node: LLM response: {response.content}\")\n",
    "    return {\"messages\": [response]} # responseはAIMessageオブジェクトを期待 (ここは歯抜けにしない)\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"llm_responder\", llm_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"llm_responder\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"llm_responder\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- チャットボットのテスト ---\")\n",
    "# 最初のメッセージはHumanMessageであると想定\n",
    "inputs = {\"messages\": [HumanMessage(content=\"こんにちは、あなたの名前は何ですか？\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- 別の質問 ---\")\n",
    "inputs2 = {\"messages\": [HumanMessage(content=\"今日の天気は？\")]}\n",
    "\n",
    "final_state2 = graph.invoke(inputs2)\n",
    "print(f\"最終的な応答: {final_state2['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答004</summary>\n",
    "\n",
    "``````python\n",
    "# 解答004\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import os # osはAPIキー設定のコメントアウト部分で使われているので残しても良いが、直接は不要になる\n",
    "\n",
    "# ノートブック冒頭で`llm`変数が初期化されている前提\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def llm_node(state: GraphState):\n",
    "    # LLMを呼び出し、応答を生成するノード\n",
    "    # ノートブック冒頭で初期化された共通の `llm` 変数を使用します。\n",
    "    print(f\"llm_node: Calling LLM with messages: {state['messages']}\")\n",
    "    response = llm.invoke(state[\"messages\"]) # 共通llmを使用\n",
    "    print(f\"llm_node: LLM response: {response.content}\")\n",
    "    return {\"messages\": [response]} # responseはAIMessageオブジェクトを期待\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"llm_responder\", llm_node)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"llm_responder\")\n",
    "\n",
    "# 終了ポイントの設定\n",
    "workflow.add_edge(\"llm_responder\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- チャットボットのテスト ---\")\n",
    "# 最初のメッセージはHumanMessageであると想定\n",
    "inputs = {\"messages\": [HumanMessage(content=\"こんにちは、あなたの名前は何ですか？\")]}\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- 別の質問 ---\")\n",
    "inputs2 = {\"messages\": [HumanMessage(content=\"今日の天気は？\")]}\n",
    "\n",
    "final_state2 = graph.invoke(inputs2)\n",
    "print(f\"最終的な応答: {final_state2['messages'][-1].content}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説004</summary>\n",
    "\n",
    "このノートブックでは、様々なLLMプラットフォーム（OpenAI, Azure OpenAI, Google Cloud Vertex AI, Google Gemini (Gemini API), Anthropic Claude, Amazon Bedrockなど）を簡単に切り替えて試せるように設計されています。\n",
    "ノートブックの冒頭にある `LLM_PROVIDER` 変数で使用したいLLMを選択し、対応するAPIキーや環境変数を設定するだけで、この問題を含む全てのLLM呼び出し箇所で選択したLLMが利用されます。\n",
    "選択した `LLM_PROVIDER` に応じて、必要なAPIキーが設定されているか（環境変数またはGoogle Colabのシークレット経由）、ノートブック起動時にチェックされます。\n",
    "\n",
    "ここでは、ノートブックの先頭で設定・初期化された共通の `llm` 変数を使用して、LLMに質問をしています。\n",
    "`llm.invoke()` という統一されたインターフェースで、どのLLMプロバイダーを利用しているかに関わらず、同じようにLLMを呼び出すことができます。\n",
    "これにより、特定のLLMサービスに依存しない、より汎用的なコードを作成するメリットを手軽に体験できます。\n",
    "\n",
    "もしエラーが発生した場合は、ノートブック冒頭の `LLM_PROVIDER` の設定、および選択したプロバイダーに応じたAPIキーや環境変数の設定（例: `OPENAI_API_KEY`, `GOOGLE_API_KEY`, `AZURE_OPENAI_ENDPOINT`など）が正しく行われているかを確認してください。\n",
    "各プロバイダー固有の設定項目（例えばVertex AIのProject ID、AzureのDeployment Name、Bedrockのリージョンなど）も見直してください。\n",
    "プロバイダーによっては、`pip install` コマンドで対応するライブラリ (例: `langchain-google-genai`) がインストールされているかも確認点です。\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題005: 状態の更新 - 特定キーの値を上書きする\n",
    "\n",
    "`add_messages` によるメッセージ履歴の追加だけでなく、グラフの状態(`State`)内の特定のキーの値を直接更新する方法を学びましょう。ここでは、カウンター値を保持する状態キーを定義し、ノードでその値をインクリメントするグラフを作成します。\n",
    "\n",
    "*   **学習内容:** `TypedDict`で定義する状態クラスに、`messages`以外のカスタムキー（ここでは`counter: int`）を追加し、ノード関数内でその値を直接読み書きする方法を学びます。これにより、メッセージ履歴だけでなく、数値や文字列、ブール値など、より多様なデータをグラフ全体で管理できるようになります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄005\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import ____\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class CounterState(____):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    ____: int \n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def increment_counter(state: CounterState):\n",
    "    # counterの値を1増やすノード\n",
    "    current_count = state.get(\"counter\", 0) # stateからcounterの値を取得、なければ0\n",
    "    new_count = current_count + 1\n",
    "    print(f\"increment_counter: Current count: {current_count}, New count: {new_count}\")\n",
    "    return {\"counter\": new_count, \"messages\": [HumanMessage(content=f\"Counter incremented to {new_count}\")]}\n",
    "\n",
    "def display_count(state: CounterState):\n",
    "    # counterの最終値を表示するノード (実際にはmessagesに追加されたもので確認)\n",
    "    print(f\"display_count: Final counter value is {state['counter']}\")\n",
    "    # このノードは状態を更新しないが、メッセージを追加しても良い\n",
    "    return {\"messages\": [HumanMessage(content=f\"Final count: {state['counter']}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(CounterState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"increment\", increment_counter)\n",
    "workflow.add_node(\"display\", display_count)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"increment\")\n",
    "\n",
    "# エッジの追加\n",
    "workflow.add_edge(\"increment\", \"display\")\n",
    "workflow.____(\"display\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- カウンターテスト (初期値0から) ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Start counting\")], \"counter\": 0} # 初期カウンター値を設定\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- カウンターテスト (初期値5から) ---\")\n",
    "inputs_2 = {\"messages\": [HumanMessage(content=\"Start counting from 5\")], \"counter\": 5} # 初期カウンター値を設定\n",
    "\n",
    "final_state_2 = graph.invoke(inputs_2)\n",
    "print(f\"最終的な応答: {final_state_2['messages'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答005</summary>\n",
    "\n",
    "``````python\n",
    "# 解答005\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "class CounterState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    counter: int # 新しくカウンター用の状態キーを定義\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def increment_counter(state: CounterState):\n",
    "    # counterの値を1増やすノード\n",
    "    current_count = state.get(\"counter\", 0) # stateからcounterの値を取得、なければ0\n",
    "    new_count = current_count + 1\n",
    "    print(f\"increment_counter: Current count: {current_count}, New count: {new_count}\")\n",
    "    return {\"counter\": new_count, \"messages\": [HumanMessage(content=f\"Counter incremented to {new_count}\")]}\n",
    "\n",
    "def display_count(state: CounterState):\n",
    "    # counterの最終値を表示するノード (実際にはmessagesに追加されたもので確認)\n",
    "    print(f\"display_count: Final counter value is {state['counter']}\")\n",
    "    # このノードは状態を更新しないが、メッセージを追加しても良い\n",
    "    return {\"messages\": [HumanMessage(content=f\"Final count: {state['counter']}\")]}\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = StateGraph(CounterState)\n",
    "\n",
    "# ノードの追加\n",
    "workflow.add_node(\"increment\", increment_counter)\n",
    "workflow.add_node(\"display\", display_count)\n",
    "\n",
    "# エントリポイントの設定\n",
    "workflow.set_entry_point(\"increment\")\n",
    "\n",
    "# エッジの追加\n",
    "workflow.add_edge(\"increment\", \"display\")\n",
    "workflow.add_edge(\"display\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "graph = workflow.compile()\n",
    "\n",
    "# --- グラフの実行と結果表示 ---\n",
    "print(\"\\n--- カウンターテスト (初期値0から) ---\")\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Start counting\")], \"counter\": 0} # 初期カウンター値を設定\n",
    "\n",
    "final_state = graph.invoke(inputs)\n",
    "print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n--- カウンターテスト (初期値5から) ---\")\n",
    "inputs_2 = {\"messages\": [HumanMessage(content=\"Start counting from 5\")], \"counter\": 5} # 初期カウンター値を設定\n",
    "\n",
    "final_state_2 = graph.invoke(inputs_2)\n",
    "print(f\"最終的な応答: {final_state_2['messages'][-1].content}\")\n",
    "``````\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解説005</summary>\n",
    "\n",
    "#### この問題のポイント\n",
    "\n",
    "*   **コード解説:**\n",
    "    *   `CounterState`に`counter: int`を追加しました。これにより、グラフの状態はメッセージリストと整数型のカウンターを持つことになります。\n",
    "    *   `increment_counter`ノードでは、`state.get(\"counter\", 0)`を使って現在のカウンター値を取得しています。`.get()`メソッドを使うことで、キーが存在しない場合のデフォルト値を指定できます（ここでは初回実行時を想定して0）。その後、値をインクリメントし、更新後の値を`{\"counter\": new_count}`という辞書形式で返しています。LangGraphは、ノードが返す辞書のキーに基づいて対応する状態を更新します。\n",
    "    *   `messages`キーも同時に返すことで、状態更新のログや情報をメッセージ履歴に残すことができます。\n",
    "    *   グラフ実行時 (`graph.invoke`や`graph.stream`) に、`inputs`辞書に`\"counter\": 0`（または任意の値）を含めることで、`counter`キーの初期値を設定できます。\n",
    "    *   このように、ノードは状態の一部または全部を更新する辞書を返すことで、グラフの状態を変化させます。`add_messages`はメッセージリストの更新に特化した便利な方法ですが、他のキーは直接値を指定して更新します。\n",
    "---\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 問題006: 状態の更新 - 複数のキーを一度に更新する\n",
    "\n",
    "一つのノードから、状態(`State`)の複数のキーを同時に更新する方法を学びましょう。ここでは、ユーザーからのメッセージ内容に応じて、応答メッセージと共に「応答タイプ」という別の状態キーも更新するグラフを作成します。\n",
    "\n",
    "*   **学習内容:** 一つのノード関数から返す辞書に複数のキーと値のペアを含めることで、グラフの状態(`State`)の複数の属性を一度に更新する方法を学びます。また、`typing.Literal`を使って、状態キーが取りうる値を制限する方法も示します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答欄006\n",
    "from typing import TypedDict, Annotated, ____\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "ResponseType = Literal[\"greeting\", \"question\", \"other\", \"unknown\"]\n",
    "\n",
    "class MultiUpdateState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    response_type: ResponseType\n",
    "    last_user_message: str # 最後に入力されたユーザーメッセージ\n",
    "\n",
    "# --- ノード定義 (Nodes) ---\n",
    "def process_input(state: MultiUpdateState):\n",
    "    user_message = state[\"messages\"][-1].content.lower()\n",
    "    response_text = \"\"\n",
    "    resp_type: ResponseType = \"unknown\"\n",
    "\n",
    "    if \"こんにちは\" in user_message or \"こんばんは\" in user_message:\n",
    "        response_text = \"こんにちは！何かお手伝いできますか？\"\n",
    "        resp_type = \"greeting\" \n",
    "    elif \"?\" in user_message or \"教えて\" in user_message:\n",
    "        response_text = \"ご質問ありがとうございます。それについては現在調べています。\"\n",
    "        resp_type = \"question\" \n",
    "    else:\n",
    "        response_text = \"メッセージありがとうございます。\"\n",
    "        resp_type = \"other\" \n",
    "    \n",
    "    print(f\"process_input: User: '{user_message}', AI: '{response_text}', Type: '{resp_type}'\")\n",
    "    # 複数のキーを同時に更新して返す\n",
    "    return { # このreturnブロック全体が一つの穴埋め候補 (Hard)\n",
    "        \"messages\": [AIMessage(content=response_text)],\n",
    "        \"response_type\": resp_type,\n",
    "        \"last_user_message\": user_message\n",
    "    }\n",
    "\n",
    "# --- グラフ構築 (Graph) ---\n",
    "workflow = ____(MultiUpdateState)\n",
    "\n",
    "workflow.____(\"processor\", process_input)\n",
    "workflow.set_entry_point(\"processor\")\n",
    "workflow.add_edge(\"processor\", ____)\n",
    "\n",
    "graph = workflow.____()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの可視化 ---\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"グラフの可視化に失敗しました。Graphvizが正しくインストールされているか確認してください。エラー: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- グラフの実行と結果表示 ---\n",
    "test_inputs = [\n",
    "    {\"messages\": [HumanMessage(content=\"こんにちは\")]},\n",
    "    {\"messages\": [HumanMessage(content=\"LangGraphについて教えてください\")]},\n",
    "    {\"messages\": [HumanMessage(content=\"今日の天気は晴れですね\")]}\n",
    "]\n",
    "\n",
    "for i, inputs in enumerate(test_inputs):\n",
    "    print(f\"\\n--- テスト実行 {i+1} ---\")\n",
    "\n",
    "    final_state = graph.invoke(inputs, {\"recursion_limit\": 3})\n",
    "    print(f\"最終的な応答: {final_state['messages'][-1].content}\")\n",
    "    assert \"response_type\" in final_state\n",
    "    assert \"last_user_message\" in final_state\n",
    "    print(f\"Response Type: {final_state['response_type']}\")\n",
    "    print(f\"Last User Message: {final_state['last_user_message']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>解答006</summary>\n",
    "\n",
    "``````python\n",
    "# 解答006\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# --- 状態定義 (State) ---\n",
    "ResponseType = Literal[\"greeting\", \"question\", \"other\", \"unknown\"]\n",
    "\n",
    "class MultiUpdateState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    response_type: ResponseType # 応答の種類を保持するキー\n",
    "    last_user_message
